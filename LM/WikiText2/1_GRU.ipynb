{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GRU_torchtext.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMuo0OLw5T0LsqrfxsVUuZs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6v8IlwXVDWoo","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592820309677,"user_tz":-120,"elapsed":7627,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["import torch\n","from torchtext import data\n","import spacy\n","from spacy.symbols import ORTH\n","from torchtext.datasets import WikiText2\n","\n","\n","my_tok = spacy.load('en')\n"," \n","def spacy_tok(x):\n","    return [tok.text for tok in my_tok.tokenizer(x)]\n"," \n","TEXT = data.Field(lower=True, tokenize=spacy_tok)\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"BWxgIq15DbZV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592820314355,"user_tz":-120,"elapsed":665,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["my_tok.tokenizer.add_special_case(\"don't\", [{ORTH: \"do\"}, {ORTH: \"n't\"}])"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"hjHPhcK4DdW_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1592820336829,"user_tz":-120,"elapsed":21817,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"outputId":"ae073549-2f59-4045-f690-592ad76c04b6"},"source":["train, valid, test = WikiText2.splits(TEXT) "],"execution_count":3,"outputs":[{"output_type":"stream","text":["downloading wikitext-2-v1.zip\n"],"name":"stdout"},{"output_type":"stream","text":["wikitext-2-v1.zip: 100%|██████████| 4.48M/4.48M [00:00<00:00, 6.52MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["extracting\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mbcs30HNDgW5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592820337173,"user_tz":-120,"elapsed":8206,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["TEXT.build_vocab(train)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"20lNWfbbDiq_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592820337175,"user_tz":-120,"elapsed":6327,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["batch_size = 50\n","bptt = 200"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"_gXyEk5IED9o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592820337176,"user_tz":-120,"elapsed":5824,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"outputId":"3cf47644-d580-4cb4-e866-3279fd6714f6"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-gRH0qG2D7eY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592820339085,"user_tz":-120,"elapsed":862,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["train_iter, valid_iter, test_iter = data.BPTTIterator.splits(\n","    (train, valid, test),\n","    batch_size=batch_size,\n","    bptt_len=bptt, \n","    device=device,\n","    repeat=False)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"nAVzAOR5ENC5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592820339954,"user_tz":-120,"elapsed":759,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class RNNModel(nn.Module):\n","    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n","\n","    def __init__(self, input_dim, embed_dim, hid_dim, n_layers, dropout=0.5):\n","        super(RNNModel, self).__init__()\n","        \n","        self.input_dim = input_dim\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        \n","        self.encoder = nn.Embedding(input_dim, embed_dim)\n","    \n","        self.rnn = nn.GRU(embed_dim,\n","                          hid_dim,\n","                          n_layers,\n","                          dropout = 0 if n_layers < 2 else dropout)\n","        \n","        self.decoder = nn.Linear(hid_dim, input_dim)\n","\n","        self.drop = nn.Dropout(dropout)\n","        self.init_weights()\n","\n","\n","    def init_weights(self):\n","        initrange = 0.1\n","        self.encoder.weight.data.uniform_(-initrange, initrange)\n","        self.decoder.bias.data.zero_()\n","        self.decoder.weight.data.uniform_(-initrange, initrange)\n","\n","    def forward(self, inputs, hidden):\n","        \n","        #inputs = [seq len, batch size]\n","        #hidden = [num layers * num directions, batch size, hid dim]\n","        \n","        emb = self.drop(self.encoder(inputs))\n","        \n","        #emb = [seq len, batch size, emb dim]\n","        \n","        output, hidden = self.rnn(emb, hidden)\n","        output = self.drop(output)\n","        \n","        #output = [seq len, batch size, hid dim * num directions]\n","        #hidden = [num layers * num directions, batch size, hid dim]\n","        \n","        decoded = self.decoder(output)\n","        \n","        #decoded = [seq len, batch size, vocab size]\n","        \n","        decoded = decoded.view(-1, self.input_dim)\n","        \n","        #decoded = [seq len * batch size, vocab size]\n","\n","        return F.log_softmax(decoded, dim=1), hidden\n","\n","    def init_hidden(self, bsz):\n","        weight = next(self.parameters())\n","\n","        return weight.new_zeros(self.n_layers, bsz, self.hid_dim)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pjs5l5adEboy","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592820341755,"user_tz":-120,"elapsed":1628,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["vocab_size = len(TEXT.vocab)\n","emb_dim = 512\n","hid_dim = 256\n","n_layers = 5\n","dropout = 0.2\n","eval_batch_size = 10\n","lr = 4\n","log_interval = 20\n","\n","model = RNNModel(vocab_size, emb_dim, hid_dim, n_layers, dropout)\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"wCugAfj6Ee0G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592820344331,"user_tz":-120,"elapsed":854,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"outputId":"77e3abfd-e7af-4ee8-eced-e7987bdae25e"},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["The model has 24,371,398 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IDQBveFjFeQi","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592820345856,"user_tz":-120,"elapsed":866,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["import torch.optim as optim\n","\n","criterion = nn.NLLLoss()"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"mzgN-wm0FseZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592820364455,"user_tz":-120,"elapsed":18476,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["model=model.to(device)\n","criterion=criterion.to(device)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"F9fd0AsRFuGX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592820364457,"user_tz":-120,"elapsed":17766,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["def train(model, iterator, criterion):\n","    clip = 0.25\n","    total_loss = 0\n","    \n","    model.train()\n","    \n","    hidden = model.init_hidden(batch_size)\n","        \n","    for k, batch in enumerate(iterator):\n","        data = batch.text\n","        targets = batch.target.view(-1)\n","\n","        data = data.to(device)\n","        targets = targets.to(device)\n","\n","        model.zero_grad()\n","        hidden = hidden.detach()\n","      \n","        output, hidden = model(data, hidden)    \n","        \n","        loss = criterion(output, targets)\n","                \n","        loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        for p in model.parameters():\n","            p.data.add_(-lr, p.grad.data)\n","        \n","        total_loss += loss.item()\n","        \n","        if k % log_interval == 0 and k > 0:\n","            cur_loss = total_loss / log_interval\n","            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {} | '\n","                    'loss {:5.2f} | ppl {:8.2f}'.format(epoch, k, len(iterator), lr, cur_loss, math.exp(cur_loss)))\n","            total_loss = 0\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZY5_rEeEGtmY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592820364458,"user_tz":-120,"elapsed":16879,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["def evaluate(model, iterator, criterion):\n","    \n","    total_loss = 0\n","    \n","    model.eval()\n","    \n","    hidden = model.init_hidden(batch_size)\n","    \n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","            data = batch.text\n","            targets = batch.target.view(-1)\n","\n","            data = data.to(device)\n","            targets = targets.to(device)\n","\n","            output, hidden = model(data, hidden)\n","            hidden = hidden.detach()\n","            \n","            loss = criterion(output, targets).item()\n","\n","            total_loss += len(data) * loss\n","\n","        \n","    return total_loss / (len(iterator)*bptt - 1)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"SV9C2TlMG9Ya","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592820364458,"user_tz":-120,"elapsed":16117,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tu99h31gHA1R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592831263640,"user_tz":-120,"elapsed":10897325,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"outputId":"73be3f05-9dba-4d17-9dd5-5bc4fca3c8b7"},"source":["N_EPOCHS = 100\n","\n","best_valid_loss = float('inf')\n","counter = 0\n","patience = 5\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","    \n","    train(model, train_iter, criterion)\n","    valid_loss = evaluate(model, valid_iter, criterion)\n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):.2f}')\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        #torch.save(model.state_dict(), 'tut2-model.pt')\n","        counter = 0 \n","    else:\n","        lr /= 4.0\n","        counter += 1\n","        if counter >= patience:\n","            break\n","\n","    "],"execution_count":16,"outputs":[{"output_type":"stream","text":["/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha)\n"],"name":"stderr"},{"output_type":"stream","text":["| epoch   0 |    20/  224 batches | lr 4 | loss  8.96 | ppl  7758.80\n","| epoch   0 |    40/  224 batches | lr 4 | loss  7.70 | ppl  2209.14\n","| epoch   0 |    60/  224 batches | lr 4 | loss  7.65 | ppl  2100.38\n","| epoch   0 |    80/  224 batches | lr 4 | loss  7.49 | ppl  1793.73\n","| epoch   0 |   100/  224 batches | lr 4 | loss  7.37 | ppl  1591.25\n","| epoch   0 |   120/  224 batches | lr 4 | loss  7.36 | ppl  1578.57\n","| epoch   0 |   140/  224 batches | lr 4 | loss  7.27 | ppl  1443.26\n","| epoch   0 |   160/  224 batches | lr 4 | loss  7.28 | ppl  1448.60\n","| epoch   0 |   180/  224 batches | lr 4 | loss  7.24 | ppl  1393.33\n","| epoch   0 |   200/  224 batches | lr 4 | loss  7.13 | ppl  1247.50\n","| epoch   0 |   220/  224 batches | lr 4 | loss  7.12 | ppl  1231.92\n","Epoch: 01 | Epoch Time: 2m 36s\n","\t Val. Loss: 6.427 |  Val. PPL: 618.27\n","| epoch   1 |    20/  224 batches | lr 4 | loss  7.44 | ppl  1696.79\n","| epoch   1 |    40/  224 batches | lr 4 | loss  7.00 | ppl  1101.59\n","| epoch   1 |    60/  224 batches | lr 4 | loss  7.00 | ppl  1091.85\n","| epoch   1 |    80/  224 batches | lr 4 | loss  6.88 | ppl   970.40\n","| epoch   1 |   100/  224 batches | lr 4 | loss  6.79 | ppl   890.26\n","| epoch   1 |   120/  224 batches | lr 4 | loss  6.76 | ppl   859.73\n","| epoch   1 |   140/  224 batches | lr 4 | loss  6.67 | ppl   788.33\n","| epoch   1 |   160/  224 batches | lr 4 | loss  6.63 | ppl   760.71\n","| epoch   1 |   180/  224 batches | lr 4 | loss  6.60 | ppl   737.09\n","| epoch   1 |   200/  224 batches | lr 4 | loss  6.54 | ppl   690.51\n","| epoch   1 |   220/  224 batches | lr 4 | loss  6.57 | ppl   713.16\n","Epoch: 02 | Epoch Time: 2m 35s\n","\t Val. Loss: 5.963 |  Val. PPL: 388.62\n","| epoch   2 |    20/  224 batches | lr 4 | loss  6.85 | ppl   940.76\n","| epoch   2 |    40/  224 batches | lr 4 | loss  6.45 | ppl   631.40\n","| epoch   2 |    60/  224 batches | lr 4 | loss  6.49 | ppl   659.39\n","| epoch   2 |    80/  224 batches | lr 4 | loss  6.44 | ppl   627.03\n","| epoch   2 |   100/  224 batches | lr 4 | loss  6.42 | ppl   614.27\n","| epoch   2 |   120/  224 batches | lr 4 | loss  6.44 | ppl   623.60\n","| epoch   2 |   140/  224 batches | lr 4 | loss  6.38 | ppl   591.86\n","| epoch   2 |   160/  224 batches | lr 4 | loss  6.37 | ppl   586.44\n","| epoch   2 |   180/  224 batches | lr 4 | loss  6.35 | ppl   570.94\n","| epoch   2 |   200/  224 batches | lr 4 | loss  6.33 | ppl   560.51\n","| epoch   2 |   220/  224 batches | lr 4 | loss  6.35 | ppl   573.32\n","Epoch: 03 | Epoch Time: 2m 36s\n","\t Val. Loss: 5.640 |  Val. PPL: 281.35\n","| epoch   3 |    20/  224 batches | lr 4 | loss  6.62 | ppl   749.55\n","| epoch   3 |    40/  224 batches | lr 4 | loss  6.26 | ppl   523.80\n","| epoch   3 |    60/  224 batches | lr 4 | loss  6.30 | ppl   545.05\n","| epoch   3 |    80/  224 batches | lr 4 | loss  6.26 | ppl   521.47\n","| epoch   3 |   100/  224 batches | lr 4 | loss  6.24 | ppl   513.97\n","| epoch   3 |   120/  224 batches | lr 4 | loss  6.27 | ppl   526.86\n","| epoch   3 |   140/  224 batches | lr 4 | loss  6.21 | ppl   495.48\n","| epoch   3 |   160/  224 batches | lr 4 | loss  6.21 | ppl   495.98\n","| epoch   3 |   180/  224 batches | lr 4 | loss  6.18 | ppl   482.62\n","| epoch   3 |   200/  224 batches | lr 4 | loss  6.15 | ppl   468.24\n","| epoch   3 |   220/  224 batches | lr 4 | loss  6.18 | ppl   485.37\n","Epoch: 04 | Epoch Time: 2m 36s\n","\t Val. Loss: 5.496 |  Val. PPL: 243.68\n","| epoch   4 |    20/  224 batches | lr 4 | loss  6.44 | ppl   628.48\n","| epoch   4 |    40/  224 batches | lr 4 | loss  6.09 | ppl   442.26\n","| epoch   4 |    60/  224 batches | lr 4 | loss  6.14 | ppl   461.91\n","| epoch   4 |    80/  224 batches | lr 4 | loss  6.10 | ppl   447.98\n","| epoch   4 |   100/  224 batches | lr 4 | loss  6.08 | ppl   438.16\n","| epoch   4 |   120/  224 batches | lr 4 | loss  6.13 | ppl   458.09\n","| epoch   4 |   140/  224 batches | lr 4 | loss  6.07 | ppl   434.14\n","| epoch   4 |   160/  224 batches | lr 4 | loss  6.08 | ppl   437.32\n","| epoch   4 |   180/  224 batches | lr 4 | loss  6.05 | ppl   426.11\n","| epoch   4 |   200/  224 batches | lr 4 | loss  6.03 | ppl   415.48\n","| epoch   4 |   220/  224 batches | lr 4 | loss  6.06 | ppl   426.27\n","Epoch: 05 | Epoch Time: 2m 36s\n","\t Val. Loss: 5.457 |  Val. PPL: 234.34\n","| epoch   5 |    20/  224 batches | lr 4 | loss  6.33 | ppl   558.62\n","| epoch   5 |    40/  224 batches | lr 4 | loss  5.98 | ppl   393.58\n","| epoch   5 |    60/  224 batches | lr 4 | loss  6.03 | ppl   415.57\n","| epoch   5 |    80/  224 batches | lr 4 | loss  5.99 | ppl   401.40\n","| epoch   5 |   100/  224 batches | lr 4 | loss  5.98 | ppl   395.51\n","| epoch   5 |   120/  224 batches | lr 4 | loss  6.03 | ppl   414.61\n","| epoch   5 |   140/  224 batches | lr 4 | loss  5.98 | ppl   395.74\n","| epoch   5 |   160/  224 batches | lr 4 | loss  5.99 | ppl   397.72\n","| epoch   5 |   180/  224 batches | lr 4 | loss  5.96 | ppl   388.24\n","| epoch   5 |   200/  224 batches | lr 4 | loss  5.93 | ppl   377.64\n","| epoch   5 |   220/  224 batches | lr 4 | loss  5.97 | ppl   389.83\n","Epoch: 06 | Epoch Time: 2m 36s\n","\t Val. Loss: 5.377 |  Val. PPL: 216.48\n","| epoch   6 |    20/  224 batches | lr 4 | loss  6.24 | ppl   510.50\n","| epoch   6 |    40/  224 batches | lr 4 | loss  5.89 | ppl   361.36\n","| epoch   6 |    60/  224 batches | lr 4 | loss  5.94 | ppl   381.24\n","| epoch   6 |    80/  224 batches | lr 4 | loss  5.92 | ppl   370.67\n","| epoch   6 |   100/  224 batches | lr 4 | loss  5.90 | ppl   365.49\n","| epoch   6 |   120/  224 batches | lr 4 | loss  5.95 | ppl   382.76\n","| epoch   6 |   140/  224 batches | lr 4 | loss  5.90 | ppl   365.44\n","| epoch   6 |   160/  224 batches | lr 4 | loss  5.91 | ppl   369.33\n","| epoch   6 |   180/  224 batches | lr 4 | loss  5.88 | ppl   358.71\n","| epoch   6 |   200/  224 batches | lr 4 | loss  5.86 | ppl   351.34\n","| epoch   6 |   220/  224 batches | lr 4 | loss  5.89 | ppl   361.41\n","Epoch: 07 | Epoch Time: 2m 36s\n","\t Val. Loss: 5.295 |  Val. PPL: 199.24\n","| epoch   7 |    20/  224 batches | lr 4 | loss  6.16 | ppl   472.35\n","| epoch   7 |    40/  224 batches | lr 4 | loss  5.81 | ppl   334.28\n","| epoch   7 |    60/  224 batches | lr 4 | loss  5.87 | ppl   353.32\n","| epoch   7 |    80/  224 batches | lr 4 | loss  5.84 | ppl   345.30\n","| epoch   7 |   100/  224 batches | lr 4 | loss  5.83 | ppl   339.19\n","| epoch   7 |   120/  224 batches | lr 4 | loss  5.87 | ppl   355.57\n","| epoch   7 |   140/  224 batches | lr 4 | loss  5.83 | ppl   340.16\n","| epoch   7 |   160/  224 batches | lr 4 | loss  5.84 | ppl   343.16\n","| epoch   7 |   180/  224 batches | lr 4 | loss  5.81 | ppl   334.46\n","| epoch   7 |   200/  224 batches | lr 4 | loss  5.79 | ppl   326.78\n","| epoch   7 |   220/  224 batches | lr 4 | loss  5.82 | ppl   337.37\n","Epoch: 08 | Epoch Time: 2m 35s\n","\t Val. Loss: 5.184 |  Val. PPL: 178.36\n","| epoch   8 |    20/  224 batches | lr 4 | loss  6.09 | ppl   440.32\n","| epoch   8 |    40/  224 batches | lr 4 | loss  5.75 | ppl   312.76\n","| epoch   8 |    60/  224 batches | lr 4 | loss  5.80 | ppl   329.50\n","| epoch   8 |    80/  224 batches | lr 4 | loss  5.78 | ppl   323.14\n","| epoch   8 |   100/  224 batches | lr 4 | loss  5.75 | ppl   315.75\n","| epoch   8 |   120/  224 batches | lr 4 | loss  5.80 | ppl   331.44\n","| epoch   8 |   140/  224 batches | lr 4 | loss  5.76 | ppl   316.97\n","| epoch   8 |   160/  224 batches | lr 4 | loss  5.77 | ppl   320.72\n","| epoch   8 |   180/  224 batches | lr 4 | loss  5.74 | ppl   311.98\n","| epoch   8 |   200/  224 batches | lr 4 | loss  5.72 | ppl   305.09\n","| epoch   8 |   220/  224 batches | lr 4 | loss  5.75 | ppl   313.34\n","Epoch: 09 | Epoch Time: 2m 35s\n","\t Val. Loss: 5.166 |  Val. PPL: 175.16\n","| epoch   9 |    20/  224 batches | lr 4 | loss  6.01 | ppl   409.48\n","| epoch   9 |    40/  224 batches | lr 4 | loss  5.67 | ppl   290.00\n","| epoch   9 |    60/  224 batches | lr 4 | loss  5.72 | ppl   306.08\n","| epoch   9 |    80/  224 batches | lr 4 | loss  5.70 | ppl   299.32\n","| epoch   9 |   100/  224 batches | lr 4 | loss  5.69 | ppl   294.67\n","| epoch   9 |   120/  224 batches | lr 4 | loss  5.73 | ppl   308.55\n","| epoch   9 |   140/  224 batches | lr 4 | loss  5.69 | ppl   295.54\n","| epoch   9 |   160/  224 batches | lr 4 | loss  5.70 | ppl   300.10\n","| epoch   9 |   180/  224 batches | lr 4 | loss  5.67 | ppl   290.92\n","| epoch   9 |   200/  224 batches | lr 4 | loss  5.65 | ppl   284.65\n","| epoch   9 |   220/  224 batches | lr 4 | loss  5.68 | ppl   294.37\n","Epoch: 10 | Epoch Time: 2m 35s\n","\t Val. Loss: 5.064 |  Val. PPL: 158.22\n","| epoch  10 |    20/  224 batches | lr 4 | loss  5.94 | ppl   379.10\n","| epoch  10 |    40/  224 batches | lr 4 | loss  5.60 | ppl   269.84\n","| epoch  10 |    60/  224 batches | lr 4 | loss  5.65 | ppl   283.95\n","| epoch  10 |    80/  224 batches | lr 4 | loss  5.63 | ppl   278.70\n","| epoch  10 |   100/  224 batches | lr 4 | loss  5.61 | ppl   274.39\n","| epoch  10 |   120/  224 batches | lr 4 | loss  5.65 | ppl   284.94\n","| epoch  10 |   140/  224 batches | lr 4 | loss  5.61 | ppl   273.15\n","| epoch  10 |   160/  224 batches | lr 4 | loss  5.63 | ppl   278.99\n","| epoch  10 |   180/  224 batches | lr 4 | loss  5.60 | ppl   270.73\n","| epoch  10 |   200/  224 batches | lr 4 | loss  5.58 | ppl   264.11\n","| epoch  10 |   220/  224 batches | lr 4 | loss  5.61 | ppl   273.54\n","Epoch: 11 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.998 |  Val. PPL: 148.10\n","| epoch  11 |    20/  224 batches | lr 4 | loss  5.86 | ppl   351.68\n","| epoch  11 |    40/  224 batches | lr 4 | loss  5.52 | ppl   250.85\n","| epoch  11 |    60/  224 batches | lr 4 | loss  5.58 | ppl   264.75\n","| epoch  11 |    80/  224 batches | lr 4 | loss  5.56 | ppl   259.29\n","| epoch  11 |   100/  224 batches | lr 4 | loss  5.54 | ppl   254.83\n","| epoch  11 |   120/  224 batches | lr 4 | loss  5.58 | ppl   265.39\n","| epoch  11 |   140/  224 batches | lr 4 | loss  5.54 | ppl   254.25\n","| epoch  11 |   160/  224 batches | lr 4 | loss  5.56 | ppl   260.72\n","| epoch  11 |   180/  224 batches | lr 4 | loss  5.53 | ppl   251.81\n","| epoch  11 |   200/  224 batches | lr 4 | loss  5.51 | ppl   245.93\n","| epoch  11 |   220/  224 batches | lr 4 | loss  5.54 | ppl   255.71\n","Epoch: 12 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.960 |  Val. PPL: 142.63\n","| epoch  12 |    20/  224 batches | lr 4 | loss  5.79 | ppl   328.07\n","| epoch  12 |    40/  224 batches | lr 4 | loss  5.46 | ppl   235.29\n","| epoch  12 |    60/  224 batches | lr 4 | loss  5.51 | ppl   247.25\n","| epoch  12 |    80/  224 batches | lr 4 | loss  5.49 | ppl   242.83\n","| epoch  12 |   100/  224 batches | lr 4 | loss  5.48 | ppl   238.83\n","| epoch  12 |   120/  224 batches | lr 4 | loss  5.51 | ppl   248.03\n","| epoch  12 |   140/  224 batches | lr 4 | loss  5.47 | ppl   238.31\n","| epoch  12 |   160/  224 batches | lr 4 | loss  5.50 | ppl   244.73\n","| epoch  12 |   180/  224 batches | lr 4 | loss  5.47 | ppl   237.20\n","| epoch  12 |   200/  224 batches | lr 4 | loss  5.44 | ppl   230.36\n","| epoch  12 |   220/  224 batches | lr 4 | loss  5.48 | ppl   239.00\n","Epoch: 13 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.915 |  Val. PPL: 136.30\n","| epoch  13 |    20/  224 batches | lr 4 | loss  5.73 | ppl   306.61\n","| epoch  13 |    40/  224 batches | lr 4 | loss  5.39 | ppl   219.59\n","| epoch  13 |    60/  224 batches | lr 4 | loss  5.44 | ppl   231.59\n","| epoch  13 |    80/  224 batches | lr 4 | loss  5.43 | ppl   228.31\n","| epoch  13 |   100/  224 batches | lr 4 | loss  5.41 | ppl   223.80\n","| epoch  13 |   120/  224 batches | lr 4 | loss  5.44 | ppl   231.25\n","| epoch  13 |   140/  224 batches | lr 4 | loss  5.41 | ppl   224.26\n","| epoch  13 |   160/  224 batches | lr 4 | loss  5.44 | ppl   229.56\n","| epoch  13 |   180/  224 batches | lr 4 | loss  5.41 | ppl   222.82\n","| epoch  13 |   200/  224 batches | lr 4 | loss  5.38 | ppl   216.64\n","| epoch  13 |   220/  224 batches | lr 4 | loss  5.41 | ppl   224.04\n","Epoch: 14 | Epoch Time: 2m 36s\n","\t Val. Loss: 4.859 |  Val. PPL: 128.95\n","| epoch  14 |    20/  224 batches | lr 4 | loss  5.66 | ppl   287.53\n","| epoch  14 |    40/  224 batches | lr 4 | loss  5.33 | ppl   207.31\n","| epoch  14 |    60/  224 batches | lr 4 | loss  5.38 | ppl   217.78\n","| epoch  14 |    80/  224 batches | lr 4 | loss  5.37 | ppl   215.42\n","| epoch  14 |   100/  224 batches | lr 4 | loss  5.35 | ppl   210.56\n","| epoch  14 |   120/  224 batches | lr 4 | loss  5.38 | ppl   216.91\n","| epoch  14 |   140/  224 batches | lr 4 | loss  5.35 | ppl   211.43\n","| epoch  14 |   160/  224 batches | lr 4 | loss  5.38 | ppl   216.88\n","| epoch  14 |   180/  224 batches | lr 4 | loss  5.35 | ppl   209.97\n","| epoch  14 |   200/  224 batches | lr 4 | loss  5.32 | ppl   203.67\n","| epoch  14 |   220/  224 batches | lr 4 | loss  5.35 | ppl   210.50\n","Epoch: 15 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.844 |  Val. PPL: 127.03\n","| epoch  15 |    20/  224 batches | lr 4 | loss  5.60 | ppl   269.48\n","| epoch  15 |    40/  224 batches | lr 4 | loss  5.28 | ppl   195.78\n","| epoch  15 |    60/  224 batches | lr 4 | loss  5.32 | ppl   205.32\n","| epoch  15 |    80/  224 batches | lr 4 | loss  5.31 | ppl   203.26\n","| epoch  15 |   100/  224 batches | lr 4 | loss  5.29 | ppl   198.18\n","| epoch  15 |   120/  224 batches | lr 4 | loss  5.32 | ppl   204.07\n","| epoch  15 |   140/  224 batches | lr 4 | loss  5.30 | ppl   199.84\n","| epoch  15 |   160/  224 batches | lr 4 | loss  5.32 | ppl   204.65\n","| epoch  15 |   180/  224 batches | lr 4 | loss  5.29 | ppl   198.54\n","| epoch  15 |   200/  224 batches | lr 4 | loss  5.26 | ppl   191.99\n","| epoch  15 |   220/  224 batches | lr 4 | loss  5.29 | ppl   197.74\n","Epoch: 16 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.785 |  Val. PPL: 119.67\n","| epoch  16 |    20/  224 batches | lr 4 | loss  5.54 | ppl   255.49\n","| epoch  16 |    40/  224 batches | lr 4 | loss  5.22 | ppl   185.00\n","| epoch  16 |    60/  224 batches | lr 4 | loss  5.27 | ppl   193.64\n","| epoch  16 |    80/  224 batches | lr 4 | loss  5.26 | ppl   192.28\n","| epoch  16 |   100/  224 batches | lr 4 | loss  5.24 | ppl   188.37\n","| epoch  16 |   120/  224 batches | lr 4 | loss  5.26 | ppl   193.09\n","| epoch  16 |   140/  224 batches | lr 4 | loss  5.25 | ppl   189.63\n","| epoch  16 |   160/  224 batches | lr 4 | loss  5.27 | ppl   194.02\n","| epoch  16 |   180/  224 batches | lr 4 | loss  5.24 | ppl   188.48\n","| epoch  16 |   200/  224 batches | lr 4 | loss  5.21 | ppl   182.20\n","| epoch  16 |   220/  224 batches | lr 4 | loss  5.23 | ppl   187.18\n","Epoch: 17 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.776 |  Val. PPL: 118.66\n","| epoch  17 |    20/  224 batches | lr 4 | loss  5.49 | ppl   241.83\n","| epoch  17 |    40/  224 batches | lr 4 | loss  5.17 | ppl   175.59\n","| epoch  17 |    60/  224 batches | lr 4 | loss  5.21 | ppl   183.96\n","| epoch  17 |    80/  224 batches | lr 4 | loss  5.20 | ppl   182.03\n","| epoch  17 |   100/  224 batches | lr 4 | loss  5.19 | ppl   178.61\n","| epoch  17 |   120/  224 batches | lr 4 | loss  5.21 | ppl   183.29\n","| epoch  17 |   140/  224 batches | lr 4 | loss  5.20 | ppl   180.59\n","| epoch  17 |   160/  224 batches | lr 4 | loss  5.22 | ppl   184.89\n","| epoch  17 |   180/  224 batches | lr 4 | loss  5.19 | ppl   179.77\n","| epoch  17 |   200/  224 batches | lr 4 | loss  5.15 | ppl   173.09\n","| epoch  17 |   220/  224 batches | lr 4 | loss  5.18 | ppl   178.42\n","Epoch: 18 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.719 |  Val. PPL: 112.09\n","| epoch  18 |    20/  224 batches | lr 4 | loss  5.43 | ppl   228.78\n","| epoch  18 |    40/  224 batches | lr 4 | loss  5.12 | ppl   167.31\n","| epoch  18 |    60/  224 batches | lr 4 | loss  5.17 | ppl   175.25\n","| epoch  18 |    80/  224 batches | lr 4 | loss  5.16 | ppl   173.47\n","| epoch  18 |   100/  224 batches | lr 4 | loss  5.13 | ppl   169.52\n","| epoch  18 |   120/  224 batches | lr 4 | loss  5.16 | ppl   174.27\n","| epoch  18 |   140/  224 batches | lr 4 | loss  5.15 | ppl   172.21\n","| epoch  18 |   160/  224 batches | lr 4 | loss  5.18 | ppl   177.14\n","| epoch  18 |   180/  224 batches | lr 4 | loss  5.15 | ppl   171.61\n","| epoch  18 |   200/  224 batches | lr 4 | loss  5.11 | ppl   165.46\n","| epoch  18 |   220/  224 batches | lr 4 | loss  5.13 | ppl   169.81\n","Epoch: 19 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.693 |  Val. PPL: 109.23\n","| epoch  19 |    20/  224 batches | lr 4 | loss  5.39 | ppl   218.44\n","| epoch  19 |    40/  224 batches | lr 4 | loss  5.08 | ppl   160.07\n","| epoch  19 |    60/  224 batches | lr 4 | loss  5.12 | ppl   167.75\n","| epoch  19 |    80/  224 batches | lr 4 | loss  5.11 | ppl   165.78\n","| epoch  19 |   100/  224 batches | lr 4 | loss  5.09 | ppl   162.72\n","| epoch  19 |   120/  224 batches | lr 4 | loss  5.11 | ppl   166.48\n","| epoch  19 |   140/  224 batches | lr 4 | loss  5.10 | ppl   164.84\n","| epoch  19 |   160/  224 batches | lr 4 | loss  5.13 | ppl   169.67\n","| epoch  19 |   180/  224 batches | lr 4 | loss  5.10 | ppl   164.42\n","| epoch  19 |   200/  224 batches | lr 4 | loss  5.06 | ppl   157.97\n","| epoch  19 |   220/  224 batches | lr 4 | loss  5.09 | ppl   162.59\n","Epoch: 20 | Epoch Time: 2m 36s\n","\t Val. Loss: 4.649 |  Val. PPL: 104.48\n","| epoch  20 |    20/  224 batches | lr 4 | loss  5.34 | ppl   207.98\n","| epoch  20 |    40/  224 batches | lr 4 | loss  5.03 | ppl   152.86\n","| epoch  20 |    60/  224 batches | lr 4 | loss  5.08 | ppl   160.80\n","| epoch  20 |    80/  224 batches | lr 4 | loss  5.07 | ppl   159.05\n","| epoch  20 |   100/  224 batches | lr 4 | loss  5.05 | ppl   155.74\n","| epoch  20 |   120/  224 batches | lr 4 | loss  5.07 | ppl   159.50\n","| epoch  20 |   140/  224 batches | lr 4 | loss  5.07 | ppl   158.63\n","| epoch  20 |   160/  224 batches | lr 4 | loss  5.09 | ppl   163.05\n","| epoch  20 |   180/  224 batches | lr 4 | loss  5.06 | ppl   158.28\n","| epoch  20 |   200/  224 batches | lr 4 | loss  5.02 | ppl   151.61\n","| epoch  20 |   220/  224 batches | lr 4 | loss  5.05 | ppl   156.34\n","Epoch: 21 | Epoch Time: 2m 36s\n","\t Val. Loss: 4.620 |  Val. PPL: 101.47\n","| epoch  21 |    20/  224 batches | lr 4 | loss  5.30 | ppl   199.85\n","| epoch  21 |    40/  224 batches | lr 4 | loss  4.99 | ppl   147.12\n","| epoch  21 |    60/  224 batches | lr 4 | loss  5.04 | ppl   154.69\n","| epoch  21 |    80/  224 batches | lr 4 | loss  5.03 | ppl   152.68\n","| epoch  21 |   100/  224 batches | lr 4 | loss  5.01 | ppl   149.64\n","| epoch  21 |   120/  224 batches | lr 4 | loss  5.03 | ppl   153.05\n","| epoch  21 |   140/  224 batches | lr 4 | loss  5.03 | ppl   152.64\n","| epoch  21 |   160/  224 batches | lr 4 | loss  5.06 | ppl   157.17\n","| epoch  21 |   180/  224 batches | lr 4 | loss  5.03 | ppl   152.20\n","| epoch  21 |   200/  224 batches | lr 4 | loss  4.98 | ppl   145.90\n","| epoch  21 |   220/  224 batches | lr 4 | loss  5.02 | ppl   150.80\n","Epoch: 22 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.601 |  Val. PPL: 99.54\n","| epoch  22 |    20/  224 batches | lr 4 | loss  5.26 | ppl   192.53\n","| epoch  22 |    40/  224 batches | lr 4 | loss  4.95 | ppl   141.80\n","| epoch  22 |    60/  224 batches | lr 4 | loss  5.00 | ppl   148.88\n","| epoch  22 |    80/  224 batches | lr 4 | loss  4.99 | ppl   147.40\n","| epoch  22 |   100/  224 batches | lr 4 | loss  4.97 | ppl   144.27\n","| epoch  22 |   120/  224 batches | lr 4 | loss  4.99 | ppl   147.44\n","| epoch  22 |   140/  224 batches | lr 4 | loss  4.99 | ppl   147.27\n","| epoch  22 |   160/  224 batches | lr 4 | loss  5.02 | ppl   151.84\n","| epoch  22 |   180/  224 batches | lr 4 | loss  4.99 | ppl   146.84\n","| epoch  22 |   200/  224 batches | lr 4 | loss  4.95 | ppl   141.01\n","| epoch  22 |   220/  224 batches | lr 4 | loss  4.98 | ppl   145.27\n","Epoch: 23 | Epoch Time: 2m 36s\n","\t Val. Loss: 4.573 |  Val. PPL: 96.83\n","| epoch  23 |    20/  224 batches | lr 4 | loss  5.22 | ppl   184.88\n","| epoch  23 |    40/  224 batches | lr 4 | loss  4.92 | ppl   136.76\n","| epoch  23 |    60/  224 batches | lr 4 | loss  4.97 | ppl   143.56\n","| epoch  23 |    80/  224 batches | lr 4 | loss  4.96 | ppl   142.03\n","| epoch  23 |   100/  224 batches | lr 4 | loss  4.94 | ppl   139.36\n","| epoch  23 |   120/  224 batches | lr 4 | loss  4.96 | ppl   142.31\n","| epoch  23 |   140/  224 batches | lr 4 | loss  4.96 | ppl   142.15\n","| epoch  23 |   160/  224 batches | lr 4 | loss  4.99 | ppl   146.68\n","| epoch  23 |   180/  224 batches | lr 4 | loss  4.96 | ppl   142.24\n","| epoch  23 |   200/  224 batches | lr 4 | loss  4.91 | ppl   136.00\n","| epoch  23 |   220/  224 batches | lr 4 | loss  4.94 | ppl   140.18\n","Epoch: 24 | Epoch Time: 2m 36s\n","\t Val. Loss: 4.550 |  Val. PPL: 94.66\n","| epoch  24 |    20/  224 batches | lr 4 | loss  5.19 | ppl   178.59\n","| epoch  24 |    40/  224 batches | lr 4 | loss  4.88 | ppl   132.00\n","| epoch  24 |    60/  224 batches | lr 4 | loss  4.94 | ppl   139.08\n","| epoch  24 |    80/  224 batches | lr 4 | loss  4.92 | ppl   137.05\n","| epoch  24 |   100/  224 batches | lr 4 | loss  4.90 | ppl   134.80\n","| epoch  24 |   120/  224 batches | lr 4 | loss  4.92 | ppl   137.55\n","| epoch  24 |   140/  224 batches | lr 4 | loss  4.92 | ppl   137.38\n","| epoch  24 |   160/  224 batches | lr 4 | loss  4.96 | ppl   142.49\n","| epoch  24 |   180/  224 batches | lr 4 | loss  4.92 | ppl   137.39\n","| epoch  24 |   200/  224 batches | lr 4 | loss  4.88 | ppl   131.59\n","| epoch  24 |   220/  224 batches | lr 4 | loss  4.91 | ppl   135.54\n","Epoch: 25 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.540 |  Val. PPL: 93.69\n","| epoch  25 |    20/  224 batches | lr 4 | loss  5.15 | ppl   173.04\n","| epoch  25 |    40/  224 batches | lr 4 | loss  4.85 | ppl   127.72\n","| epoch  25 |    60/  224 batches | lr 4 | loss  4.90 | ppl   134.46\n","| epoch  25 |    80/  224 batches | lr 4 | loss  4.89 | ppl   132.88\n","| epoch  25 |   100/  224 batches | lr 4 | loss  4.87 | ppl   130.46\n","| epoch  25 |   120/  224 batches | lr 4 | loss  4.89 | ppl   133.29\n","| epoch  25 |   140/  224 batches | lr 4 | loss  4.89 | ppl   133.30\n","| epoch  25 |   160/  224 batches | lr 4 | loss  4.93 | ppl   138.05\n","| epoch  25 |   180/  224 batches | lr 4 | loss  4.90 | ppl   133.90\n","| epoch  25 |   200/  224 batches | lr 4 | loss  4.85 | ppl   127.76\n","| epoch  25 |   220/  224 batches | lr 4 | loss  4.88 | ppl   131.29\n","Epoch: 26 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.518 |  Val. PPL: 91.65\n","| epoch  26 |    20/  224 batches | lr 4 | loss  5.12 | ppl   167.15\n","| epoch  26 |    40/  224 batches | lr 4 | loss  4.82 | ppl   124.09\n","| epoch  26 |    60/  224 batches | lr 4 | loss  4.87 | ppl   130.50\n","| epoch  26 |    80/  224 batches | lr 4 | loss  4.86 | ppl   129.09\n","| epoch  26 |   100/  224 batches | lr 4 | loss  4.84 | ppl   126.44\n","| epoch  26 |   120/  224 batches | lr 4 | loss  4.86 | ppl   129.33\n","| epoch  26 |   140/  224 batches | lr 4 | loss  4.87 | ppl   129.93\n","| epoch  26 |   160/  224 batches | lr 4 | loss  4.90 | ppl   134.11\n","| epoch  26 |   180/  224 batches | lr 4 | loss  4.87 | ppl   129.83\n","| epoch  26 |   200/  224 batches | lr 4 | loss  4.82 | ppl   123.75\n","| epoch  26 |   220/  224 batches | lr 4 | loss  4.85 | ppl   127.55\n","Epoch: 27 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.509 |  Val. PPL: 90.83\n","| epoch  27 |    20/  224 batches | lr 4 | loss  5.09 | ppl   162.25\n","| epoch  27 |    40/  224 batches | lr 4 | loss  4.79 | ppl   120.30\n","| epoch  27 |    60/  224 batches | lr 4 | loss  4.84 | ppl   126.95\n","| epoch  27 |    80/  224 batches | lr 4 | loss  4.83 | ppl   125.42\n","| epoch  27 |   100/  224 batches | lr 4 | loss  4.81 | ppl   123.02\n","| epoch  27 |   120/  224 batches | lr 4 | loss  4.84 | ppl   125.98\n","| epoch  27 |   140/  224 batches | lr 4 | loss  4.84 | ppl   125.93\n","| epoch  27 |   160/  224 batches | lr 4 | loss  4.87 | ppl   130.76\n","| epoch  27 |   180/  224 batches | lr 4 | loss  4.84 | ppl   126.83\n","| epoch  27 |   200/  224 batches | lr 4 | loss  4.79 | ppl   120.64\n","| epoch  27 |   220/  224 batches | lr 4 | loss  4.82 | ppl   124.41\n","Epoch: 28 | Epoch Time: 2m 36s\n","\t Val. Loss: 4.484 |  Val. PPL: 88.61\n","| epoch  28 |    20/  224 batches | lr 4 | loss  5.06 | ppl   157.27\n","| epoch  28 |    40/  224 batches | lr 4 | loss  4.76 | ppl   116.81\n","| epoch  28 |    60/  224 batches | lr 4 | loss  4.81 | ppl   123.21\n","| epoch  28 |    80/  224 batches | lr 4 | loss  4.80 | ppl   121.81\n","| epoch  28 |   100/  224 batches | lr 4 | loss  4.78 | ppl   119.53\n","| epoch  28 |   120/  224 batches | lr 4 | loss  4.81 | ppl   122.39\n","| epoch  28 |   140/  224 batches | lr 4 | loss  4.81 | ppl   122.70\n","| epoch  28 |   160/  224 batches | lr 4 | loss  4.84 | ppl   127.06\n","| epoch  28 |   180/  224 batches | lr 4 | loss  4.81 | ppl   123.19\n","| epoch  28 |   200/  224 batches | lr 4 | loss  4.76 | ppl   117.27\n","| epoch  28 |   220/  224 batches | lr 4 | loss  4.80 | ppl   121.12\n","Epoch: 29 | Epoch Time: 2m 37s\n","\t Val. Loss: 4.466 |  Val. PPL: 87.04\n","| epoch  29 |    20/  224 batches | lr 4 | loss  5.03 | ppl   152.47\n","| epoch  29 |    40/  224 batches | lr 4 | loss  4.74 | ppl   113.96\n","| epoch  29 |    60/  224 batches | lr 4 | loss  4.79 | ppl   119.90\n","| epoch  29 |    80/  224 batches | lr 4 | loss  4.78 | ppl   118.90\n","| epoch  29 |   100/  224 batches | lr 4 | loss  4.76 | ppl   116.65\n","| epoch  29 |   120/  224 batches | lr 4 | loss  4.78 | ppl   119.60\n","| epoch  29 |   140/  224 batches | lr 4 | loss  4.79 | ppl   119.82\n","| epoch  29 |   160/  224 batches | lr 4 | loss  4.82 | ppl   124.50\n","| epoch  29 |   180/  224 batches | lr 4 | loss  4.79 | ppl   120.68\n","| epoch  29 |   200/  224 batches | lr 4 | loss  4.74 | ppl   114.36\n","| epoch  29 |   220/  224 batches | lr 4 | loss  4.77 | ppl   117.95\n","Epoch: 30 | Epoch Time: 2m 37s\n","\t Val. Loss: 4.459 |  Val. PPL: 86.42\n","| epoch  30 |    20/  224 batches | lr 4 | loss  5.00 | ppl   149.09\n","| epoch  30 |    40/  224 batches | lr 4 | loss  4.72 | ppl   111.78\n","| epoch  30 |    60/  224 batches | lr 4 | loss  4.77 | ppl   117.36\n","| epoch  30 |    80/  224 batches | lr 4 | loss  4.76 | ppl   116.38\n","| epoch  30 |   100/  224 batches | lr 4 | loss  4.73 | ppl   113.50\n","| epoch  30 |   120/  224 batches | lr 4 | loss  4.76 | ppl   116.46\n","| epoch  30 |   140/  224 batches | lr 4 | loss  4.76 | ppl   116.64\n","| epoch  30 |   160/  224 batches | lr 4 | loss  4.80 | ppl   121.41\n","| epoch  30 |   180/  224 batches | lr 4 | loss  4.77 | ppl   117.76\n","| epoch  30 |   200/  224 batches | lr 4 | loss  4.72 | ppl   112.41\n","| epoch  30 |   220/  224 batches | lr 4 | loss  4.75 | ppl   115.58\n","Epoch: 31 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.445 |  Val. PPL: 85.19\n","| epoch  31 |    20/  224 batches | lr 4 | loss  4.98 | ppl   145.53\n","| epoch  31 |    40/  224 batches | lr 4 | loss  4.69 | ppl   108.85\n","| epoch  31 |    60/  224 batches | lr 4 | loss  4.74 | ppl   114.84\n","| epoch  31 |    80/  224 batches | lr 4 | loss  4.73 | ppl   113.01\n","| epoch  31 |   100/  224 batches | lr 4 | loss  4.71 | ppl   110.90\n","| epoch  31 |   120/  224 batches | lr 4 | loss  4.73 | ppl   113.30\n","| epoch  31 |   140/  224 batches | lr 4 | loss  4.74 | ppl   114.07\n","| epoch  31 |   160/  224 batches | lr 4 | loss  4.78 | ppl   119.02\n","| epoch  31 |   180/  224 batches | lr 4 | loss  4.75 | ppl   115.04\n","| epoch  31 |   200/  224 batches | lr 4 | loss  4.70 | ppl   109.48\n","| epoch  31 |   220/  224 batches | lr 4 | loss  4.72 | ppl   112.41\n","Epoch: 32 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.431 |  Val. PPL: 84.05\n","| epoch  32 |    20/  224 batches | lr 4 | loss  4.95 | ppl   141.63\n","| epoch  32 |    40/  224 batches | lr 4 | loss  4.66 | ppl   106.05\n","| epoch  32 |    60/  224 batches | lr 4 | loss  4.72 | ppl   112.29\n","| epoch  32 |    80/  224 batches | lr 4 | loss  4.71 | ppl   110.62\n","| epoch  32 |   100/  224 batches | lr 4 | loss  4.69 | ppl   108.67\n","| epoch  32 |   120/  224 batches | lr 4 | loss  4.71 | ppl   110.85\n","| epoch  32 |   140/  224 batches | lr 4 | loss  4.71 | ppl   111.38\n","| epoch  32 |   160/  224 batches | lr 4 | loss  4.76 | ppl   116.24\n","| epoch  32 |   180/  224 batches | lr 4 | loss  4.72 | ppl   112.56\n","| epoch  32 |   200/  224 batches | lr 4 | loss  4.68 | ppl   107.39\n","| epoch  32 |   220/  224 batches | lr 4 | loss  4.70 | ppl   110.48\n","Epoch: 33 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.418 |  Val. PPL: 82.92\n","| epoch  33 |    20/  224 batches | lr 4 | loss  4.94 | ppl   139.20\n","| epoch  33 |    40/  224 batches | lr 4 | loss  4.65 | ppl   104.08\n","| epoch  33 |    60/  224 batches | lr 4 | loss  4.70 | ppl   109.48\n","| epoch  33 |    80/  224 batches | lr 4 | loss  4.68 | ppl   108.23\n","| epoch  33 |   100/  224 batches | lr 4 | loss  4.67 | ppl   106.20\n","| epoch  33 |   120/  224 batches | lr 4 | loss  4.69 | ppl   108.37\n","| epoch  33 |   140/  224 batches | lr 4 | loss  4.69 | ppl   109.01\n","| epoch  33 |   160/  224 batches | lr 4 | loss  4.73 | ppl   113.84\n","| epoch  33 |   180/  224 batches | lr 4 | loss  4.70 | ppl   110.41\n","| epoch  33 |   200/  224 batches | lr 4 | loss  4.65 | ppl   104.99\n","| epoch  33 |   220/  224 batches | lr 4 | loss  4.68 | ppl   108.14\n","Epoch: 34 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.407 |  Val. PPL: 81.99\n","| epoch  34 |    20/  224 batches | lr 4 | loss  4.91 | ppl   135.55\n","| epoch  34 |    40/  224 batches | lr 4 | loss  4.63 | ppl   102.02\n","| epoch  34 |    60/  224 batches | lr 4 | loss  4.68 | ppl   107.48\n","| epoch  34 |    80/  224 batches | lr 4 | loss  4.66 | ppl   105.81\n","| epoch  34 |   100/  224 batches | lr 4 | loss  4.64 | ppl   103.94\n","| epoch  34 |   120/  224 batches | lr 4 | loss  4.66 | ppl   105.96\n","| epoch  34 |   140/  224 batches | lr 4 | loss  4.67 | ppl   106.63\n","| epoch  34 |   160/  224 batches | lr 4 | loss  4.71 | ppl   111.49\n","| epoch  34 |   180/  224 batches | lr 4 | loss  4.68 | ppl   108.24\n","| epoch  34 |   200/  224 batches | lr 4 | loss  4.63 | ppl   102.71\n","| epoch  34 |   220/  224 batches | lr 4 | loss  4.66 | ppl   106.06\n","Epoch: 35 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.402 |  Val. PPL: 81.62\n","| epoch  35 |    20/  224 batches | lr 4 | loss  4.89 | ppl   132.87\n","| epoch  35 |    40/  224 batches | lr 4 | loss  4.60 | ppl    99.90\n","| epoch  35 |    60/  224 batches | lr 4 | loss  4.65 | ppl   105.00\n","| epoch  35 |    80/  224 batches | lr 4 | loss  4.64 | ppl   103.77\n","| epoch  35 |   100/  224 batches | lr 4 | loss  4.62 | ppl   101.79\n","| epoch  35 |   120/  224 batches | lr 4 | loss  4.65 | ppl   104.28\n","| epoch  35 |   140/  224 batches | lr 4 | loss  4.65 | ppl   104.91\n","| epoch  35 |   160/  224 batches | lr 4 | loss  4.70 | ppl   109.55\n","| epoch  35 |   180/  224 batches | lr 4 | loss  4.66 | ppl   106.14\n","| epoch  35 |   200/  224 batches | lr 4 | loss  4.61 | ppl   100.70\n","| epoch  35 |   220/  224 batches | lr 4 | loss  4.64 | ppl   103.83\n","Epoch: 36 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.404 |  Val. PPL: 81.79\n","| epoch  36 |    20/  224 batches | lr 1.0 | loss  4.85 | ppl   127.34\n","| epoch  36 |    40/  224 batches | lr 1.0 | loss  4.56 | ppl    95.61\n","| epoch  36 |    60/  224 batches | lr 1.0 | loss  4.61 | ppl   100.29\n","| epoch  36 |    80/  224 batches | lr 1.0 | loss  4.59 | ppl    98.07\n","| epoch  36 |   100/  224 batches | lr 1.0 | loss  4.56 | ppl    96.04\n","| epoch  36 |   120/  224 batches | lr 1.0 | loss  4.59 | ppl    98.22\n","| epoch  36 |   140/  224 batches | lr 1.0 | loss  4.59 | ppl    98.70\n","| epoch  36 |   160/  224 batches | lr 1.0 | loss  4.63 | ppl   102.25\n","| epoch  36 |   180/  224 batches | lr 1.0 | loss  4.59 | ppl    98.53\n","| epoch  36 |   200/  224 batches | lr 1.0 | loss  4.54 | ppl    93.24\n","| epoch  36 |   220/  224 batches | lr 1.0 | loss  4.56 | ppl    95.72\n","Epoch: 37 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.365 |  Val. PPL: 78.64\n","| epoch  37 |    20/  224 batches | lr 1.0 | loss  4.82 | ppl   124.42\n","| epoch  37 |    40/  224 batches | lr 1.0 | loss  4.54 | ppl    94.01\n","| epoch  37 |    60/  224 batches | lr 1.0 | loss  4.59 | ppl    98.71\n","| epoch  37 |    80/  224 batches | lr 1.0 | loss  4.57 | ppl    96.66\n","| epoch  37 |   100/  224 batches | lr 1.0 | loss  4.55 | ppl    94.95\n","| epoch  37 |   120/  224 batches | lr 1.0 | loss  4.58 | ppl    97.18\n","| epoch  37 |   140/  224 batches | lr 1.0 | loss  4.58 | ppl    97.70\n","| epoch  37 |   160/  224 batches | lr 1.0 | loss  4.62 | ppl   101.41\n","| epoch  37 |   180/  224 batches | lr 1.0 | loss  4.59 | ppl    98.07\n","| epoch  37 |   200/  224 batches | lr 1.0 | loss  4.53 | ppl    93.19\n","| epoch  37 |   220/  224 batches | lr 1.0 | loss  4.56 | ppl    95.43\n","Epoch: 38 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.357 |  Val. PPL: 78.03\n","| epoch  38 |    20/  224 batches | lr 1.0 | loss  4.81 | ppl   123.16\n","| epoch  38 |    40/  224 batches | lr 1.0 | loss  4.53 | ppl    92.83\n","| epoch  38 |    60/  224 batches | lr 1.0 | loss  4.58 | ppl    97.79\n","| epoch  38 |    80/  224 batches | lr 1.0 | loss  4.57 | ppl    96.06\n","| epoch  38 |   100/  224 batches | lr 1.0 | loss  4.55 | ppl    94.27\n","| epoch  38 |   120/  224 batches | lr 1.0 | loss  4.57 | ppl    96.43\n","| epoch  38 |   140/  224 batches | lr 1.0 | loss  4.58 | ppl    97.46\n","| epoch  38 |   160/  224 batches | lr 1.0 | loss  4.61 | ppl   100.65\n","| epoch  38 |   180/  224 batches | lr 1.0 | loss  4.58 | ppl    97.55\n","| epoch  38 |   200/  224 batches | lr 1.0 | loss  4.53 | ppl    92.58\n","| epoch  38 |   220/  224 batches | lr 1.0 | loss  4.55 | ppl    95.00\n","Epoch: 39 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.357 |  Val. PPL: 78.01\n","| epoch  39 |    20/  224 batches | lr 1.0 | loss  4.80 | ppl   121.91\n","| epoch  39 |    40/  224 batches | lr 1.0 | loss  4.52 | ppl    92.09\n","| epoch  39 |    60/  224 batches | lr 1.0 | loss  4.58 | ppl    97.09\n","| epoch  39 |    80/  224 batches | lr 1.0 | loss  4.56 | ppl    95.30\n","| epoch  39 |   100/  224 batches | lr 1.0 | loss  4.54 | ppl    93.49\n","| epoch  39 |   120/  224 batches | lr 1.0 | loss  4.56 | ppl    95.77\n","| epoch  39 |   140/  224 batches | lr 1.0 | loss  4.57 | ppl    96.43\n","| epoch  39 |   160/  224 batches | lr 1.0 | loss  4.61 | ppl    99.99\n","| epoch  39 |   180/  224 batches | lr 1.0 | loss  4.58 | ppl    97.04\n","| epoch  39 |   200/  224 batches | lr 1.0 | loss  4.52 | ppl    92.23\n","| epoch  39 |   220/  224 batches | lr 1.0 | loss  4.55 | ppl    94.50\n","Epoch: 40 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.353 |  Val. PPL: 77.70\n","| epoch  40 |    20/  224 batches | lr 1.0 | loss  4.80 | ppl   121.03\n","| epoch  40 |    40/  224 batches | lr 1.0 | loss  4.52 | ppl    91.43\n","| epoch  40 |    60/  224 batches | lr 1.0 | loss  4.57 | ppl    96.52\n","| epoch  40 |    80/  224 batches | lr 1.0 | loss  4.55 | ppl    94.70\n","| epoch  40 |   100/  224 batches | lr 1.0 | loss  4.53 | ppl    92.92\n","| epoch  40 |   120/  224 batches | lr 1.0 | loss  4.56 | ppl    95.16\n","| epoch  40 |   140/  224 batches | lr 1.0 | loss  4.56 | ppl    95.89\n","| epoch  40 |   160/  224 batches | lr 1.0 | loss  4.60 | ppl    99.40\n","| epoch  40 |   180/  224 batches | lr 1.0 | loss  4.57 | ppl    96.37\n","| epoch  40 |   200/  224 batches | lr 1.0 | loss  4.52 | ppl    91.81\n","| epoch  40 |   220/  224 batches | lr 1.0 | loss  4.55 | ppl    94.22\n","Epoch: 41 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.347 |  Val. PPL: 77.24\n","| epoch  41 |    20/  224 batches | lr 1.0 | loss  4.79 | ppl   120.58\n","| epoch  41 |    40/  224 batches | lr 1.0 | loss  4.51 | ppl    90.77\n","| epoch  41 |    60/  224 batches | lr 1.0 | loss  4.56 | ppl    95.93\n","| epoch  41 |    80/  224 batches | lr 1.0 | loss  4.54 | ppl    94.07\n","| epoch  41 |   100/  224 batches | lr 1.0 | loss  4.53 | ppl    92.34\n","| epoch  41 |   120/  224 batches | lr 1.0 | loss  4.55 | ppl    94.98\n","| epoch  41 |   140/  224 batches | lr 1.0 | loss  4.56 | ppl    95.31\n","| epoch  41 |   160/  224 batches | lr 1.0 | loss  4.60 | ppl    99.12\n","| epoch  41 |   180/  224 batches | lr 1.0 | loss  4.56 | ppl    95.99\n","| epoch  41 |   200/  224 batches | lr 1.0 | loss  4.52 | ppl    91.41\n","| epoch  41 |   220/  224 batches | lr 1.0 | loss  4.54 | ppl    93.58\n","Epoch: 42 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.345 |  Val. PPL: 77.09\n","| epoch  42 |    20/  224 batches | lr 1.0 | loss  4.78 | ppl   119.44\n","| epoch  42 |    40/  224 batches | lr 1.0 | loss  4.50 | ppl    90.31\n","| epoch  42 |    60/  224 batches | lr 1.0 | loss  4.56 | ppl    95.29\n","| epoch  42 |    80/  224 batches | lr 1.0 | loss  4.54 | ppl    93.51\n","| epoch  42 |   100/  224 batches | lr 1.0 | loss  4.52 | ppl    91.77\n","| epoch  42 |   120/  224 batches | lr 1.0 | loss  4.55 | ppl    94.23\n","| epoch  42 |   140/  224 batches | lr 1.0 | loss  4.55 | ppl    94.75\n","| epoch  42 |   160/  224 batches | lr 1.0 | loss  4.59 | ppl    98.39\n","| epoch  42 |   180/  224 batches | lr 1.0 | loss  4.56 | ppl    95.68\n","| epoch  42 |   200/  224 batches | lr 1.0 | loss  4.51 | ppl    90.84\n","| epoch  42 |   220/  224 batches | lr 1.0 | loss  4.54 | ppl    93.51\n","Epoch: 43 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.342 |  Val. PPL: 76.85\n","| epoch  43 |    20/  224 batches | lr 1.0 | loss  4.77 | ppl   118.50\n","| epoch  43 |    40/  224 batches | lr 1.0 | loss  4.50 | ppl    89.87\n","| epoch  43 |    60/  224 batches | lr 1.0 | loss  4.55 | ppl    94.57\n","| epoch  43 |    80/  224 batches | lr 1.0 | loss  4.53 | ppl    93.09\n","| epoch  43 |   100/  224 batches | lr 1.0 | loss  4.51 | ppl    91.12\n","| epoch  43 |   120/  224 batches | lr 1.0 | loss  4.54 | ppl    93.55\n","| epoch  43 |   140/  224 batches | lr 1.0 | loss  4.55 | ppl    94.52\n","| epoch  43 |   160/  224 batches | lr 1.0 | loss  4.58 | ppl    97.76\n","| epoch  43 |   180/  224 batches | lr 1.0 | loss  4.56 | ppl    95.11\n","| epoch  43 |   200/  224 batches | lr 1.0 | loss  4.50 | ppl    90.41\n","| epoch  43 |   220/  224 batches | lr 1.0 | loss  4.53 | ppl    92.88\n","Epoch: 44 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.343 |  Val. PPL: 76.91\n","| epoch  44 |    20/  224 batches | lr 0.25 | loss  4.78 | ppl   118.54\n","| epoch  44 |    40/  224 batches | lr 0.25 | loss  4.50 | ppl    90.31\n","| epoch  44 |    60/  224 batches | lr 0.25 | loss  4.55 | ppl    94.95\n","| epoch  44 |    80/  224 batches | lr 0.25 | loss  4.54 | ppl    93.27\n","| epoch  44 |   100/  224 batches | lr 0.25 | loss  4.51 | ppl    91.37\n","| epoch  44 |   120/  224 batches | lr 0.25 | loss  4.54 | ppl    93.86\n","| epoch  44 |   140/  224 batches | lr 0.25 | loss  4.55 | ppl    94.20\n","| epoch  44 |   160/  224 batches | lr 0.25 | loss  4.58 | ppl    97.64\n","| epoch  44 |   180/  224 batches | lr 0.25 | loss  4.55 | ppl    94.23\n","| epoch  44 |   200/  224 batches | lr 0.25 | loss  4.49 | ppl    89.33\n","| epoch  44 |   220/  224 batches | lr 0.25 | loss  4.52 | ppl    91.60\n","Epoch: 45 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.335 |  Val. PPL: 76.30\n","| epoch  45 |    20/  224 batches | lr 0.25 | loss  4.77 | ppl   118.32\n","| epoch  45 |    40/  224 batches | lr 0.25 | loss  4.50 | ppl    89.86\n","| epoch  45 |    60/  224 batches | lr 0.25 | loss  4.55 | ppl    94.59\n","| epoch  45 |    80/  224 batches | lr 0.25 | loss  4.53 | ppl    92.60\n","| epoch  45 |   100/  224 batches | lr 0.25 | loss  4.51 | ppl    90.94\n","| epoch  45 |   120/  224 batches | lr 0.25 | loss  4.54 | ppl    93.50\n","| epoch  45 |   140/  224 batches | lr 0.25 | loss  4.54 | ppl    93.99\n","| epoch  45 |   160/  224 batches | lr 0.25 | loss  4.58 | ppl    97.16\n","| epoch  45 |   180/  224 batches | lr 0.25 | loss  4.55 | ppl    94.34\n","| epoch  45 |   200/  224 batches | lr 0.25 | loss  4.49 | ppl    89.33\n","| epoch  45 |   220/  224 batches | lr 0.25 | loss  4.52 | ppl    91.88\n","Epoch: 46 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.334 |  Val. PPL: 76.22\n","| epoch  46 |    20/  224 batches | lr 0.25 | loss  4.77 | ppl   118.12\n","| epoch  46 |    40/  224 batches | lr 0.25 | loss  4.49 | ppl    89.43\n","| epoch  46 |    60/  224 batches | lr 0.25 | loss  4.55 | ppl    94.26\n","| epoch  46 |    80/  224 batches | lr 0.25 | loss  4.53 | ppl    92.68\n","| epoch  46 |   100/  224 batches | lr 0.25 | loss  4.51 | ppl    90.73\n","| epoch  46 |   120/  224 batches | lr 0.25 | loss  4.53 | ppl    93.01\n","| epoch  46 |   140/  224 batches | lr 0.25 | loss  4.54 | ppl    93.63\n","| epoch  46 |   160/  224 batches | lr 0.25 | loss  4.58 | ppl    97.37\n","| epoch  46 |   180/  224 batches | lr 0.25 | loss  4.54 | ppl    94.08\n","| epoch  46 |   200/  224 batches | lr 0.25 | loss  4.49 | ppl    89.17\n","| epoch  46 |   220/  224 batches | lr 0.25 | loss  4.52 | ppl    91.73\n","Epoch: 47 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.332 |  Val. PPL: 76.08\n","| epoch  47 |    20/  224 batches | lr 0.25 | loss  4.77 | ppl   117.72\n","| epoch  47 |    40/  224 batches | lr 0.25 | loss  4.49 | ppl    89.28\n","| epoch  47 |    60/  224 batches | lr 0.25 | loss  4.55 | ppl    94.22\n","| epoch  47 |    80/  224 batches | lr 0.25 | loss  4.52 | ppl    92.29\n","| epoch  47 |   100/  224 batches | lr 0.25 | loss  4.51 | ppl    90.48\n","| epoch  47 |   120/  224 batches | lr 0.25 | loss  4.53 | ppl    92.86\n","| epoch  47 |   140/  224 batches | lr 0.25 | loss  4.54 | ppl    93.54\n","| epoch  47 |   160/  224 batches | lr 0.25 | loss  4.57 | ppl    97.00\n","| epoch  47 |   180/  224 batches | lr 0.25 | loss  4.54 | ppl    94.07\n","| epoch  47 |   200/  224 batches | lr 0.25 | loss  4.49 | ppl    89.35\n","| epoch  47 |   220/  224 batches | lr 0.25 | loss  4.52 | ppl    91.51\n","Epoch: 48 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.331 |  Val. PPL: 76.06\n","| epoch  48 |    20/  224 batches | lr 0.25 | loss  4.77 | ppl   117.34\n","| epoch  48 |    40/  224 batches | lr 0.25 | loss  4.49 | ppl    89.22\n","| epoch  48 |    60/  224 batches | lr 0.25 | loss  4.54 | ppl    94.05\n","| epoch  48 |    80/  224 batches | lr 0.25 | loss  4.52 | ppl    92.05\n","| epoch  48 |   100/  224 batches | lr 0.25 | loss  4.50 | ppl    90.31\n","| epoch  48 |   120/  224 batches | lr 0.25 | loss  4.53 | ppl    92.87\n","| epoch  48 |   140/  224 batches | lr 0.25 | loss  4.54 | ppl    93.49\n","| epoch  48 |   160/  224 batches | lr 0.25 | loss  4.57 | ppl    96.83\n","| epoch  48 |   180/  224 batches | lr 0.25 | loss  4.54 | ppl    94.09\n","| epoch  48 |   200/  224 batches | lr 0.25 | loss  4.49 | ppl    89.03\n","| epoch  48 |   220/  224 batches | lr 0.25 | loss  4.52 | ppl    91.60\n","Epoch: 49 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.331 |  Val. PPL: 76.03\n","| epoch  49 |    20/  224 batches | lr 0.25 | loss  4.76 | ppl   117.19\n","| epoch  49 |    40/  224 batches | lr 0.25 | loss  4.49 | ppl    88.87\n","| epoch  49 |    60/  224 batches | lr 0.25 | loss  4.54 | ppl    93.72\n","| epoch  49 |    80/  224 batches | lr 0.25 | loss  4.52 | ppl    91.81\n","| epoch  49 |   100/  224 batches | lr 0.25 | loss  4.50 | ppl    90.07\n","| epoch  49 |   120/  224 batches | lr 0.25 | loss  4.53 | ppl    92.68\n","| epoch  49 |   140/  224 batches | lr 0.25 | loss  4.54 | ppl    93.39\n","| epoch  49 |   160/  224 batches | lr 0.25 | loss  4.57 | ppl    96.76\n","| epoch  49 |   180/  224 batches | lr 0.25 | loss  4.54 | ppl    93.80\n","| epoch  49 |   200/  224 batches | lr 0.25 | loss  4.49 | ppl    89.13\n","| epoch  49 |   220/  224 batches | lr 0.25 | loss  4.51 | ppl    91.37\n","Epoch: 50 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.330 |  Val. PPL: 75.96\n","| epoch  50 |    20/  224 batches | lr 0.25 | loss  4.76 | ppl   116.81\n","| epoch  50 |    40/  224 batches | lr 0.25 | loss  4.49 | ppl    88.94\n","| epoch  50 |    60/  224 batches | lr 0.25 | loss  4.54 | ppl    93.43\n","| epoch  50 |    80/  224 batches | lr 0.25 | loss  4.52 | ppl    91.53\n","| epoch  50 |   100/  224 batches | lr 0.25 | loss  4.50 | ppl    90.17\n","| epoch  50 |   120/  224 batches | lr 0.25 | loss  4.53 | ppl    92.50\n","| epoch  50 |   140/  224 batches | lr 0.25 | loss  4.53 | ppl    93.04\n","| epoch  50 |   160/  224 batches | lr 0.25 | loss  4.57 | ppl    96.60\n","| epoch  50 |   180/  224 batches | lr 0.25 | loss  4.54 | ppl    93.89\n","| epoch  50 |   200/  224 batches | lr 0.25 | loss  4.49 | ppl    88.80\n","| epoch  50 |   220/  224 batches | lr 0.25 | loss  4.51 | ppl    91.23\n","Epoch: 51 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.330 |  Val. PPL: 75.93\n","| epoch  51 |    20/  224 batches | lr 0.25 | loss  4.76 | ppl   116.92\n","| epoch  51 |    40/  224 batches | lr 0.25 | loss  4.48 | ppl    88.59\n","| epoch  51 |    60/  224 batches | lr 0.25 | loss  4.53 | ppl    93.19\n","| epoch  51 |    80/  224 batches | lr 0.25 | loss  4.52 | ppl    91.60\n","| epoch  51 |   100/  224 batches | lr 0.25 | loss  4.50 | ppl    89.89\n","| epoch  51 |   120/  224 batches | lr 0.25 | loss  4.53 | ppl    92.53\n","| epoch  51 |   140/  224 batches | lr 0.25 | loss  4.53 | ppl    93.08\n","| epoch  51 |   160/  224 batches | lr 0.25 | loss  4.57 | ppl    96.49\n","| epoch  51 |   180/  224 batches | lr 0.25 | loss  4.54 | ppl    93.70\n","| epoch  51 |   200/  224 batches | lr 0.25 | loss  4.49 | ppl    88.83\n","| epoch  51 |   220/  224 batches | lr 0.25 | loss  4.51 | ppl    91.21\n","Epoch: 52 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.330 |  Val. PPL: 75.94\n","| epoch  52 |    20/  224 batches | lr 0.0625 | loss  4.76 | ppl   116.92\n","| epoch  52 |    40/  224 batches | lr 0.0625 | loss  4.49 | ppl    89.11\n","| epoch  52 |    60/  224 batches | lr 0.0625 | loss  4.54 | ppl    94.04\n","| epoch  52 |    80/  224 batches | lr 0.0625 | loss  4.52 | ppl    91.84\n","| epoch  52 |   100/  224 batches | lr 0.0625 | loss  4.50 | ppl    90.07\n","| epoch  52 |   120/  224 batches | lr 0.0625 | loss  4.53 | ppl    92.50\n","| epoch  52 |   140/  224 batches | lr 0.0625 | loss  4.53 | ppl    93.16\n","| epoch  52 |   160/  224 batches | lr 0.0625 | loss  4.57 | ppl    96.20\n","| epoch  52 |   180/  224 batches | lr 0.0625 | loss  4.53 | ppl    93.05\n","| epoch  52 |   200/  224 batches | lr 0.0625 | loss  4.48 | ppl    88.38\n","| epoch  52 |   220/  224 batches | lr 0.0625 | loss  4.51 | ppl    90.79\n","Epoch: 53 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.326 |  Val. PPL: 75.64\n","| epoch  53 |    20/  224 batches | lr 0.0625 | loss  4.76 | ppl   116.64\n","| epoch  53 |    40/  224 batches | lr 0.0625 | loss  4.49 | ppl    88.92\n","| epoch  53 |    60/  224 batches | lr 0.0625 | loss  4.54 | ppl    93.32\n","| epoch  53 |    80/  224 batches | lr 0.0625 | loss  4.52 | ppl    91.79\n","| epoch  53 |   100/  224 batches | lr 0.0625 | loss  4.50 | ppl    89.91\n","| epoch  53 |   120/  224 batches | lr 0.0625 | loss  4.53 | ppl    92.34\n","| epoch  53 |   140/  224 batches | lr 0.0625 | loss  4.53 | ppl    92.96\n","| epoch  53 |   160/  224 batches | lr 0.0625 | loss  4.56 | ppl    96.06\n","| epoch  53 |   180/  224 batches | lr 0.0625 | loss  4.54 | ppl    93.33\n","| epoch  53 |   200/  224 batches | lr 0.0625 | loss  4.48 | ppl    88.45\n","| epoch  53 |   220/  224 batches | lr 0.0625 | loss  4.51 | ppl    90.69\n","Epoch: 54 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.326 |  Val. PPL: 75.61\n","| epoch  54 |    20/  224 batches | lr 0.0625 | loss  4.76 | ppl   116.65\n","| epoch  54 |    40/  224 batches | lr 0.0625 | loss  4.48 | ppl    88.60\n","| epoch  54 |    60/  224 batches | lr 0.0625 | loss  4.54 | ppl    93.62\n","| epoch  54 |    80/  224 batches | lr 0.0625 | loss  4.52 | ppl    91.84\n","| epoch  54 |   100/  224 batches | lr 0.0625 | loss  4.50 | ppl    89.80\n","| epoch  54 |   120/  224 batches | lr 0.0625 | loss  4.53 | ppl    92.52\n","| epoch  54 |   140/  224 batches | lr 0.0625 | loss  4.53 | ppl    92.99\n","| epoch  54 |   160/  224 batches | lr 0.0625 | loss  4.56 | ppl    95.96\n","| epoch  54 |   180/  224 batches | lr 0.0625 | loss  4.54 | ppl    93.30\n","| epoch  54 |   200/  224 batches | lr 0.0625 | loss  4.48 | ppl    88.45\n","| epoch  54 |   220/  224 batches | lr 0.0625 | loss  4.51 | ppl    90.88\n","Epoch: 55 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.325 |  Val. PPL: 75.58\n","| epoch  55 |    20/  224 batches | lr 0.0625 | loss  4.76 | ppl   116.35\n","| epoch  55 |    40/  224 batches | lr 0.0625 | loss  4.48 | ppl    88.60\n","| epoch  55 |    60/  224 batches | lr 0.0625 | loss  4.54 | ppl    93.59\n","| epoch  55 |    80/  224 batches | lr 0.0625 | loss  4.52 | ppl    91.49\n","| epoch  55 |   100/  224 batches | lr 0.0625 | loss  4.49 | ppl    89.41\n","| epoch  55 |   120/  224 batches | lr 0.0625 | loss  4.53 | ppl    92.38\n","| epoch  55 |   140/  224 batches | lr 0.0625 | loss  4.53 | ppl    93.08\n","| epoch  55 |   160/  224 batches | lr 0.0625 | loss  4.57 | ppl    96.10\n","| epoch  55 |   180/  224 batches | lr 0.0625 | loss  4.54 | ppl    93.39\n","| epoch  55 |   200/  224 batches | lr 0.0625 | loss  4.48 | ppl    88.49\n","| epoch  55 |   220/  224 batches | lr 0.0625 | loss  4.51 | ppl    91.16\n","Epoch: 56 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.325 |  Val. PPL: 75.56\n","| epoch  56 |    20/  224 batches | lr 0.0625 | loss  4.76 | ppl   116.91\n","| epoch  56 |    40/  224 batches | lr 0.0625 | loss  4.48 | ppl    88.47\n","| epoch  56 |    60/  224 batches | lr 0.0625 | loss  4.54 | ppl    93.33\n","| epoch  56 |    80/  224 batches | lr 0.0625 | loss  4.52 | ppl    91.59\n","| epoch  56 |   100/  224 batches | lr 0.0625 | loss  4.49 | ppl    89.48\n","| epoch  56 |   120/  224 batches | lr 0.0625 | loss  4.52 | ppl    92.29\n","| epoch  56 |   140/  224 batches | lr 0.0625 | loss  4.53 | ppl    92.89\n","| epoch  56 |   160/  224 batches | lr 0.0625 | loss  4.57 | ppl    96.13\n","| epoch  56 |   180/  224 batches | lr 0.0625 | loss  4.54 | ppl    93.25\n","| epoch  56 |   200/  224 batches | lr 0.0625 | loss  4.48 | ppl    88.45\n","| epoch  56 |   220/  224 batches | lr 0.0625 | loss  4.51 | ppl    91.06\n","Epoch: 57 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.325 |  Val. PPL: 75.57\n","| epoch  57 |    20/  224 batches | lr 0.015625 | loss  4.76 | ppl   116.42\n","| epoch  57 |    40/  224 batches | lr 0.015625 | loss  4.48 | ppl    88.39\n","| epoch  57 |    60/  224 batches | lr 0.015625 | loss  4.54 | ppl    93.43\n","| epoch  57 |    80/  224 batches | lr 0.015625 | loss  4.52 | ppl    91.43\n","| epoch  57 |   100/  224 batches | lr 0.015625 | loss  4.50 | ppl    89.74\n","| epoch  57 |   120/  224 batches | lr 0.015625 | loss  4.53 | ppl    92.46\n","| epoch  57 |   140/  224 batches | lr 0.015625 | loss  4.53 | ppl    92.91\n","| epoch  57 |   160/  224 batches | lr 0.015625 | loss  4.56 | ppl    95.86\n","| epoch  57 |   180/  224 batches | lr 0.015625 | loss  4.53 | ppl    93.17\n","| epoch  57 |   200/  224 batches | lr 0.015625 | loss  4.48 | ppl    88.35\n","| epoch  57 |   220/  224 batches | lr 0.015625 | loss  4.51 | ppl    90.85\n","Epoch: 58 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.324 |  Val. PPL: 75.52\n","| epoch  58 |    20/  224 batches | lr 0.015625 | loss  4.76 | ppl   116.54\n","| epoch  58 |    40/  224 batches | lr 0.015625 | loss  4.48 | ppl    88.66\n","| epoch  58 |    60/  224 batches | lr 0.015625 | loss  4.54 | ppl    93.38\n","| epoch  58 |    80/  224 batches | lr 0.015625 | loss  4.52 | ppl    91.66\n","| epoch  58 |   100/  224 batches | lr 0.015625 | loss  4.50 | ppl    89.66\n","| epoch  58 |   120/  224 batches | lr 0.015625 | loss  4.53 | ppl    92.39\n","| epoch  58 |   140/  224 batches | lr 0.015625 | loss  4.53 | ppl    93.00\n","| epoch  58 |   160/  224 batches | lr 0.015625 | loss  4.56 | ppl    95.91\n","| epoch  58 |   180/  224 batches | lr 0.015625 | loss  4.53 | ppl    93.16\n","| epoch  58 |   200/  224 batches | lr 0.015625 | loss  4.48 | ppl    88.37\n","| epoch  58 |   220/  224 batches | lr 0.015625 | loss  4.51 | ppl    90.86\n","Epoch: 59 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.324 |  Val. PPL: 75.51\n","| epoch  59 |    20/  224 batches | lr 0.015625 | loss  4.76 | ppl   116.24\n","| epoch  59 |    40/  224 batches | lr 0.015625 | loss  4.48 | ppl    88.60\n","| epoch  59 |    60/  224 batches | lr 0.015625 | loss  4.53 | ppl    93.22\n","| epoch  59 |    80/  224 batches | lr 0.015625 | loss  4.52 | ppl    91.79\n","| epoch  59 |   100/  224 batches | lr 0.015625 | loss  4.50 | ppl    89.58\n","| epoch  59 |   120/  224 batches | lr 0.015625 | loss  4.53 | ppl    92.38\n","| epoch  59 |   140/  224 batches | lr 0.015625 | loss  4.53 | ppl    92.97\n","| epoch  59 |   160/  224 batches | lr 0.015625 | loss  4.56 | ppl    95.91\n","| epoch  59 |   180/  224 batches | lr 0.015625 | loss  4.54 | ppl    93.23\n","| epoch  59 |   200/  224 batches | lr 0.015625 | loss  4.48 | ppl    88.35\n","| epoch  59 |   220/  224 batches | lr 0.015625 | loss  4.51 | ppl    90.72\n","Epoch: 60 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.325 |  Val. PPL: 75.54\n","| epoch  60 |    20/  224 batches | lr 0.00390625 | loss  4.76 | ppl   116.40\n","| epoch  60 |    40/  224 batches | lr 0.00390625 | loss  4.48 | ppl    88.47\n","| epoch  60 |    60/  224 batches | lr 0.00390625 | loss  4.54 | ppl    93.45\n","| epoch  60 |    80/  224 batches | lr 0.00390625 | loss  4.52 | ppl    91.66\n","| epoch  60 |   100/  224 batches | lr 0.00390625 | loss  4.50 | ppl    89.71\n","| epoch  60 |   120/  224 batches | lr 0.00390625 | loss  4.53 | ppl    92.40\n","| epoch  60 |   140/  224 batches | lr 0.00390625 | loss  4.53 | ppl    92.74\n","| epoch  60 |   160/  224 batches | lr 0.00390625 | loss  4.56 | ppl    95.74\n","| epoch  60 |   180/  224 batches | lr 0.00390625 | loss  4.53 | ppl    92.97\n","| epoch  60 |   200/  224 batches | lr 0.00390625 | loss  4.48 | ppl    88.62\n","| epoch  60 |   220/  224 batches | lr 0.00390625 | loss  4.51 | ppl    90.77\n","Epoch: 61 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.324 |  Val. PPL: 75.50\n","| epoch  61 |    20/  224 batches | lr 0.00390625 | loss  4.76 | ppl   116.38\n","| epoch  61 |    40/  224 batches | lr 0.00390625 | loss  4.48 | ppl    88.59\n","| epoch  61 |    60/  224 batches | lr 0.00390625 | loss  4.54 | ppl    93.24\n","| epoch  61 |    80/  224 batches | lr 0.00390625 | loss  4.52 | ppl    91.47\n","| epoch  61 |   100/  224 batches | lr 0.00390625 | loss  4.49 | ppl    89.50\n","| epoch  61 |   120/  224 batches | lr 0.00390625 | loss  4.53 | ppl    92.45\n","| epoch  61 |   140/  224 batches | lr 0.00390625 | loss  4.53 | ppl    92.84\n","| epoch  61 |   160/  224 batches | lr 0.00390625 | loss  4.56 | ppl    95.91\n","| epoch  61 |   180/  224 batches | lr 0.00390625 | loss  4.53 | ppl    93.07\n","| epoch  61 |   200/  224 batches | lr 0.00390625 | loss  4.48 | ppl    88.46\n","| epoch  61 |   220/  224 batches | lr 0.00390625 | loss  4.51 | ppl    90.77\n","Epoch: 62 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.324 |  Val. PPL: 75.48\n","| epoch  62 |    20/  224 batches | lr 0.00390625 | loss  4.76 | ppl   116.42\n","| epoch  62 |    40/  224 batches | lr 0.00390625 | loss  4.48 | ppl    88.58\n","| epoch  62 |    60/  224 batches | lr 0.00390625 | loss  4.54 | ppl    93.30\n","| epoch  62 |    80/  224 batches | lr 0.00390625 | loss  4.52 | ppl    91.64\n","| epoch  62 |   100/  224 batches | lr 0.00390625 | loss  4.50 | ppl    89.69\n","| epoch  62 |   120/  224 batches | lr 0.00390625 | loss  4.53 | ppl    92.33\n","| epoch  62 |   140/  224 batches | lr 0.00390625 | loss  4.53 | ppl    92.82\n","| epoch  62 |   160/  224 batches | lr 0.00390625 | loss  4.56 | ppl    95.82\n","| epoch  62 |   180/  224 batches | lr 0.00390625 | loss  4.53 | ppl    93.09\n","| epoch  62 |   200/  224 batches | lr 0.00390625 | loss  4.48 | ppl    88.37\n","| epoch  62 |   220/  224 batches | lr 0.00390625 | loss  4.51 | ppl    90.90\n","Epoch: 63 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.324 |  Val. PPL: 75.47\n","| epoch  63 |    20/  224 batches | lr 0.00390625 | loss  4.76 | ppl   116.38\n","| epoch  63 |    40/  224 batches | lr 0.00390625 | loss  4.48 | ppl    88.30\n","| epoch  63 |    60/  224 batches | lr 0.00390625 | loss  4.54 | ppl    93.42\n","| epoch  63 |    80/  224 batches | lr 0.00390625 | loss  4.52 | ppl    91.70\n","| epoch  63 |   100/  224 batches | lr 0.00390625 | loss  4.49 | ppl    89.32\n","| epoch  63 |   120/  224 batches | lr 0.00390625 | loss  4.52 | ppl    92.24\n","| epoch  63 |   140/  224 batches | lr 0.00390625 | loss  4.53 | ppl    92.99\n","| epoch  63 |   160/  224 batches | lr 0.00390625 | loss  4.56 | ppl    95.80\n","| epoch  63 |   180/  224 batches | lr 0.00390625 | loss  4.53 | ppl    93.00\n","| epoch  63 |   200/  224 batches | lr 0.00390625 | loss  4.48 | ppl    88.48\n","| epoch  63 |   220/  224 batches | lr 0.00390625 | loss  4.51 | ppl    90.75\n","Epoch: 64 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.324 |  Val. PPL: 75.46\n","| epoch  64 |    20/  224 batches | lr 0.00390625 | loss  4.76 | ppl   116.30\n","| epoch  64 |    40/  224 batches | lr 0.00390625 | loss  4.49 | ppl    88.69\n","| epoch  64 |    60/  224 batches | lr 0.00390625 | loss  4.54 | ppl    93.34\n","| epoch  64 |    80/  224 batches | lr 0.00390625 | loss  4.52 | ppl    91.40\n","| epoch  64 |   100/  224 batches | lr 0.00390625 | loss  4.50 | ppl    89.73\n","| epoch  64 |   120/  224 batches | lr 0.00390625 | loss  4.52 | ppl    92.06\n","| epoch  64 |   140/  224 batches | lr 0.00390625 | loss  4.53 | ppl    92.91\n","| epoch  64 |   160/  224 batches | lr 0.00390625 | loss  4.56 | ppl    95.82\n","| epoch  64 |   180/  224 batches | lr 0.00390625 | loss  4.53 | ppl    92.94\n","| epoch  64 |   200/  224 batches | lr 0.00390625 | loss  4.48 | ppl    88.34\n","| epoch  64 |   220/  224 batches | lr 0.00390625 | loss  4.51 | ppl    90.87\n","Epoch: 65 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.324 |  Val. PPL: 75.46\n","| epoch  65 |    20/  224 batches | lr 0.00390625 | loss  4.76 | ppl   116.41\n","| epoch  65 |    40/  224 batches | lr 0.00390625 | loss  4.48 | ppl    88.29\n","| epoch  65 |    60/  224 batches | lr 0.00390625 | loss  4.54 | ppl    93.23\n","| epoch  65 |    80/  224 batches | lr 0.00390625 | loss  4.52 | ppl    91.53\n","| epoch  65 |   100/  224 batches | lr 0.00390625 | loss  4.49 | ppl    89.52\n","| epoch  65 |   120/  224 batches | lr 0.00390625 | loss  4.53 | ppl    92.33\n","| epoch  65 |   140/  224 batches | lr 0.00390625 | loss  4.53 | ppl    92.82\n","| epoch  65 |   160/  224 batches | lr 0.00390625 | loss  4.56 | ppl    95.97\n","| epoch  65 |   180/  224 batches | lr 0.00390625 | loss  4.53 | ppl    93.19\n","| epoch  65 |   200/  224 batches | lr 0.00390625 | loss  4.48 | ppl    88.29\n","| epoch  65 |   220/  224 batches | lr 0.00390625 | loss  4.51 | ppl    90.91\n","Epoch: 66 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.324 |  Val. PPL: 75.47\n","| epoch  66 |    20/  224 batches | lr 0.0009765625 | loss  4.76 | ppl   116.27\n","| epoch  66 |    40/  224 batches | lr 0.0009765625 | loss  4.48 | ppl    88.46\n","| epoch  66 |    60/  224 batches | lr 0.0009765625 | loss  4.54 | ppl    93.29\n","| epoch  66 |    80/  224 batches | lr 0.0009765625 | loss  4.52 | ppl    91.57\n","| epoch  66 |   100/  224 batches | lr 0.0009765625 | loss  4.49 | ppl    89.38\n","| epoch  66 |   120/  224 batches | lr 0.0009765625 | loss  4.53 | ppl    92.38\n","| epoch  66 |   140/  224 batches | lr 0.0009765625 | loss  4.53 | ppl    92.75\n","| epoch  66 |   160/  224 batches | lr 0.0009765625 | loss  4.56 | ppl    95.83\n","| epoch  66 |   180/  224 batches | lr 0.0009765625 | loss  4.53 | ppl    93.05\n","| epoch  66 |   200/  224 batches | lr 0.0009765625 | loss  4.48 | ppl    88.52\n","| epoch  66 |   220/  224 batches | lr 0.0009765625 | loss  4.51 | ppl    90.74\n","Epoch: 67 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.324 |  Val. PPL: 75.46\n","| epoch  67 |    20/  224 batches | lr 0.000244140625 | loss  4.75 | ppl   116.09\n","| epoch  67 |    40/  224 batches | lr 0.000244140625 | loss  4.48 | ppl    88.49\n","| epoch  67 |    60/  224 batches | lr 0.000244140625 | loss  4.54 | ppl    93.53\n","| epoch  67 |    80/  224 batches | lr 0.000244140625 | loss  4.52 | ppl    91.72\n","| epoch  67 |   100/  224 batches | lr 0.000244140625 | loss  4.49 | ppl    89.46\n","| epoch  67 |   120/  224 batches | lr 0.000244140625 | loss  4.52 | ppl    92.16\n","| epoch  67 |   140/  224 batches | lr 0.000244140625 | loss  4.53 | ppl    92.81\n","| epoch  67 |   160/  224 batches | lr 0.000244140625 | loss  4.56 | ppl    95.83\n","| epoch  67 |   180/  224 batches | lr 0.000244140625 | loss  4.53 | ppl    92.93\n","| epoch  67 |   200/  224 batches | lr 0.000244140625 | loss  4.48 | ppl    88.41\n","| epoch  67 |   220/  224 batches | lr 0.000244140625 | loss  4.51 | ppl    90.99\n","Epoch: 68 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.324 |  Val. PPL: 75.46\n","| epoch  68 |    20/  224 batches | lr 6.103515625e-05 | loss  4.76 | ppl   116.28\n","| epoch  68 |    40/  224 batches | lr 6.103515625e-05 | loss  4.48 | ppl    88.34\n","| epoch  68 |    60/  224 batches | lr 6.103515625e-05 | loss  4.54 | ppl    93.42\n","| epoch  68 |    80/  224 batches | lr 6.103515625e-05 | loss  4.52 | ppl    91.49\n","| epoch  68 |   100/  224 batches | lr 6.103515625e-05 | loss  4.50 | ppl    89.62\n","| epoch  68 |   120/  224 batches | lr 6.103515625e-05 | loss  4.52 | ppl    92.25\n","| epoch  68 |   140/  224 batches | lr 6.103515625e-05 | loss  4.53 | ppl    92.79\n","| epoch  68 |   160/  224 batches | lr 6.103515625e-05 | loss  4.56 | ppl    95.68\n","| epoch  68 |   180/  224 batches | lr 6.103515625e-05 | loss  4.53 | ppl    92.93\n","| epoch  68 |   200/  224 batches | lr 6.103515625e-05 | loss  4.48 | ppl    88.35\n","| epoch  68 |   220/  224 batches | lr 6.103515625e-05 | loss  4.51 | ppl    90.73\n","Epoch: 69 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.324 |  Val. PPL: 75.46\n","| epoch  69 |    20/  224 batches | lr 1.52587890625e-05 | loss  4.76 | ppl   116.55\n","| epoch  69 |    40/  224 batches | lr 1.52587890625e-05 | loss  4.48 | ppl    88.41\n","| epoch  69 |    60/  224 batches | lr 1.52587890625e-05 | loss  4.54 | ppl    93.36\n","| epoch  69 |    80/  224 batches | lr 1.52587890625e-05 | loss  4.52 | ppl    91.48\n","| epoch  69 |   100/  224 batches | lr 1.52587890625e-05 | loss  4.49 | ppl    89.56\n","| epoch  69 |   120/  224 batches | lr 1.52587890625e-05 | loss  4.53 | ppl    92.33\n","| epoch  69 |   140/  224 batches | lr 1.52587890625e-05 | loss  4.53 | ppl    92.89\n","| epoch  69 |   160/  224 batches | lr 1.52587890625e-05 | loss  4.56 | ppl    95.97\n","| epoch  69 |   180/  224 batches | lr 1.52587890625e-05 | loss  4.53 | ppl    93.14\n","| epoch  69 |   200/  224 batches | lr 1.52587890625e-05 | loss  4.48 | ppl    88.42\n","| epoch  69 |   220/  224 batches | lr 1.52587890625e-05 | loss  4.51 | ppl    90.94\n","Epoch: 70 | Epoch Time: 2m 35s\n","\t Val. Loss: 4.324 |  Val. PPL: 75.46\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kfXpagXpHDrC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1592831409684,"user_tz":-120,"elapsed":6298,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"outputId":"04bc1df9-397c-4e75-982d-302b20414a58"},"source":["# Run on test data.\n","test_loss = evaluate(model, test_iter, criterion)\n","print('=' * 89)\n","print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n","    test_loss, math.exp(test_loss)))\n","print('=' * 89)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["=========================================================================================\n","| End of training | test loss  4.15 | test ppl    63.31\n","=========================================================================================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2Sog2uHGXr2L","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592832188652,"user_tz":-120,"elapsed":878,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["def generate(prime_str, predict_len = 20, temperature = 0.7):\n","    hidden = model.init_hidden(1)\n","    inputs_list = [TEXT.vocab.stoi[k] for k in prime_str.split()]\n","    inputs = torch.tensor(inputs_list, dtype=torch.long).unsqueeze(1).to(device)\n","    # Use priming string to \"build up\" hidden state\n","    words = prime_str.split()\n","    for p in range(len(inputs_list) - 1):\n","        _, hidden = model(inputs[p].unsqueeze(1), hidden)\n","\n","    inp = inputs[-1].unsqueeze(1)\n","    for i in range(predict_len):\n","        output, hidden = model(inp, hidden)\n","        word_weights = output.squeeze().div(temperature).exp().cpu()\n","        # word_weights = word_weights[-1]\n","        word_idx = torch.multinomial(word_weights, 1)[0]\n","        inp.fill_(word_idx)\n","        word = TEXT.vocab.itos[word_idx]\n","        words.append(word)\n","    return  ' '.join(words)\n","\n","# One-hot matrix of first to last letters (not including EOS) for input\n","def inputTensor(line):\n","    word_indexes = [TEXT.vocab.stoi[k] for k in line.split()]\n","    return torch.tensor(word_indexes).unsqueeze(1).to(device)\n","\n","import numpy as np\n","\n","def softmax(x):\n","    \"\"\" applies softmax to an input x\"\"\"\n","    e_x = np.exp(x)\n","    return e_x / e_x.sum()\n","\n","def greedy_search(prime_str, predict_len = 20):\n","    inputs = inputTensor(prime_str)\n","    hidden = model.init_hidden(1).to(device)\n","    input_list = prime_str.split()\n","    # Use priming string to \"build up\" hidden state\n","    with torch.no_grad():\n","        for p in range(len(input_list)-1):\n","            _, hidden = model(inputs[p].unsqueeze(1), hidden)\n","        inputs = inputs[-1].unsqueeze(1).to(device)\n","\n","        prob = []\n","        for i in range(predict_len):\n","            output, hidden = model(inputs, hidden)\n","            output_np = output.data.cpu().numpy()[0]\n","            all_probs = softmax(output_np)\n","            \n","            topv, topp = output.topk(1)\n","\n","            topi = topp.item()\n","            prob.append(all_probs[topi])\n","            if topi == 1:\n","                inputs.fill_(topi)\n","                word = TEXT.vocab.itos[topi]\n","                input_list.append(word)\n","                break   \n","            else:\n","                inputs.fill_(topi)\n","                word = TEXT.vocab.itos[topi]\n","                input_list.append(word)\n","    return ' '.join(input_list), prob, np.prod(prob)\n","\n","\n","def random_choice(prime_str, top_k = 5, predict_len = 20):\n","    inputs = inputTensor(prime_str)\n","    hidden = model.init_hidden(1).to(device)\n","    input_list = prime_str.split(',')\n","    # Use priming string to \"build up\" hidden state\n","    with torch.no_grad():\n","        for p in range(len(input_list)-1):\n","            _, hidden = model(inputs[p].unsqueeze(1), hidden)\n","        inputs = inputs[-1].unsqueeze(1).to(device)\n","\n","        prob = []\n","        for i in range(predict_len):\n","            output, hidden = model(inputs, hidden)\n","            output_np = output.data.cpu().numpy()[0]\n","            all_probs = softmax(output_np)\n","            \n","            _, topps = output.topk(top_k)\n","            choices = topps.tolist()\n","            topi = np.random.choice(choices[0])\n","            prob.append(all_probs[topi])\n","            if topi == 1:\n","                inputs.fill_(topi)\n","                word = TEXT.vocab.itos[topi]\n","                input_list.append(word)\n","                break   \n","            else:\n","                inputs.fill_(topi)\n","                word = TEXT.vocab.itos[topi]\n","                input_list.append(word)\n","    return ' '.join(input_list), prob, np.prod(prob)"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"jJcmlv5o3uww","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592832529695,"user_tz":-120,"elapsed":700,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"outputId":"f34bfb33-a5b9-4b60-dee1-453a7b8a0948"},"source":["i = 'my'\n","generate(i, temperature=0.8)"],"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'my girl , was become in one of the design of the family . the director of the wall was in'"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"code","metadata":{"id":"5mcc7dY96AVt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"ok","timestamp":1592832513886,"user_tz":-120,"elapsed":830,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"outputId":"db4f7786-f22a-47b4-fdde-4d1162ff5ce5"},"source":["greedy_search(i)"],"execution_count":65,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('my < unk > , and the < unk > of the < unk > , which is a < unk',\n"," [0.061742943,\n","  0.99999887,\n","  0.99999106,\n","  0.12676093,\n","  0.13301022,\n","  0.17028119,\n","  0.092724964,\n","  0.9999933,\n","  0.9999985,\n","  0.16161998,\n","  0.43439707,\n","  0.119035535,\n","  0.9999957,\n","  0.9999975,\n","  0.12628525,\n","  0.09518967,\n","  0.1424818,\n","  0.0666404,\n","  0.07087717,\n","  0.99997914],\n"," 1.1112343e-12)"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"XFLiaZyrLOmm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"ok","timestamp":1592832539206,"user_tz":-120,"elapsed":809,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"outputId":"3093a92d-9c37-4408-c4b0-cbbe127f2e5f"},"source":["random_choice(i)"],"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('my own name for \" ode . in a <   , and a man \" and a \" white ,',\n"," [0.009784639,\n","  0.011308314,\n","  0.07020123,\n","  0.05974017,\n","  0.015353499,\n","  0.020234983,\n","  0.016850049,\n","  0.06322432,\n","  0.09004022,\n","  1.9562922e-06,\n","  0.00025247503,\n","  0.04140955,\n","  0.14365011,\n","  0.00981843,\n","  0.053170785,\n","  0.039070062,\n","  0.13081944,\n","  0.09925737,\n","  0.006800825,\n","  0.008428886],\n"," 6.168374e-37)"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"code","metadata":{"id":"0R1cxWE_MpkW","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}