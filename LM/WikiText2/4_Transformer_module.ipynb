{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transformer_torchtext.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOjdBYfV5pJ6wDjQkwopp+M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"TUmYPPQJ8SEC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593257542049,"user_tz":-120,"elapsed":8408,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["import torch\n","from torchtext import data\n","import spacy\n","from spacy.symbols import ORTH\n","from torchtext.datasets import WikiText2\n","\n","my_tok = spacy.load('en')\n"," \n","def spacy_tok(x):\n","    return [tok.text for tok in my_tok.tokenizer(x)]\n"," \n","TEXT = data.Field(lower=True, tokenize=spacy_tok)\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ziR8iDC8YeG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593257542051,"user_tz":-120,"elapsed":8404,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["my_tok.tokenizer.add_special_case(\"don't\", [{ORTH: \"do\"}, {ORTH: \"n't\"}])"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"PI-crEV_8YpT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593257559436,"user_tz":-120,"elapsed":25738,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"outputId":"f75ced07-ac59-4e65-a5a9-31903cc27669"},"source":["train, valid, test = WikiText2.splits(TEXT)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["downloading wikitext-2-v1.zip\n"],"name":"stdout"},{"output_type":"stream","text":["wikitext-2-v1.zip: 100%|██████████| 4.48M/4.48M [00:01<00:00, 2.62MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["extracting\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hfKtX6Ma8Y0j","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593257559439,"user_tz":-120,"elapsed":25736,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["TEXT.build_vocab(train)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"e78nXRFV8Y_2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593257559440,"user_tz":-120,"elapsed":25733,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["batch_size = 50\n","bptt = 200"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZB7ppJ7l8ZKm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593257560103,"user_tz":-120,"elapsed":26386,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"outputId":"8ec6b944-8988-4250-9d0e-59de8d86ef9f"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1y0lv-j18ZVg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593257560105,"user_tz":-120,"elapsed":26382,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["train_iter, valid_iter, test_iter = data.BPTTIterator.splits(\n","    (train, valid, test),\n","    batch_size=batch_size,\n","    bptt_len=bptt, \n","    device=device,\n","    repeat=False)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"vXD8hRKU8Zfw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593257562854,"user_tz":-120,"elapsed":1238,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import TransformerEncoder, TransformerEncoderLayer\n","\n","class PositionalEncoding(nn.Module):\n","    r\"\"\"Inject some information about the relative or absolute position of the tokens\n","        in the sequence. The positional encodings have the same dimension as\n","        the embeddings, so that the two can be summed. Here, we use sine and cosine\n","        functions of different frequencies.\n","    .. math::\n","        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n","        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n","        \\text{where pos is the word position and i is the embed idx)\n","    Args:\n","        d_model: the embed dim (required).\n","        dropout: the dropout value (default=0.1).\n","        max_len: the max. length of the incoming sequence (default=5000).\n","    Examples:\n","        >>> pos_encoder = PositionalEncoding(d_model)\n","    \"\"\"\n","\n","    def __init__(self, d_model, dropout=0.1, max_len = bptt):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        r\"\"\"Inputs of forward function\n","        Args:\n","            x: the sequence fed to the positional encoder model (required).\n","        Shape:\n","            x: [sequence length, batch size, embed dim]\n","            output: [sequence length, batch size, embed dim]\n","        Examples:\n","            >>> output = pos_encoder(x)\n","        \"\"\"\n","\n","        x = x + self.pe[:x.size(0), :]\n","        return self.dropout(x)\n","\n","class TransformerModel(nn.Module):\n","    \"\"\"Container module with an encoder, a recurrent or transformer module, and a decoder.\"\"\"\n","\n","    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n","        super(TransformerModel, self).__init__()\n","        try:\n","            from torch.nn import TransformerEncoder, TransformerEncoderLayer\n","        except:\n","            raise ImportError('TransformerEncoder module does not exist in PyTorch 1.1 or lower.')\n","        self.model_type = 'Transformer'\n","        self.src_mask = None\n","        self.pos_encoder = PositionalEncoding(ninp, dropout)\n","        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n","        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n","        self.encoder = nn.Embedding(ntoken, ninp)\n","        self.ninp = ninp\n","        self.decoder = nn.Linear(ninp, ntoken)\n","\n","        self.init_weights()\n","\n","    def _generate_square_subsequent_mask(self, sz):\n","        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n","        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","        return mask\n","\n","    def init_weights(self):\n","        initrange = 0.1\n","        nn.init.uniform_(self.encoder.weight, -initrange, initrange)\n","        nn.init.zeros_(self.decoder.weight)\n","        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n","\n","    def forward(self, src, has_mask = True):\n","      \n","        #src = [seq len, batch size]\n","\n","        if has_mask:\n","            device = src.device\n","            if self.src_mask is None or self.src_mask.size(0) != len(src):\n","                mask = self._generate_square_subsequent_mask(len(src)).to(device)\n","                self.src_mask = mask\n","        else:\n","            self.src_mask = None\n","\n","        src = self.encoder(src) * math.sqrt(self.ninp)\n","\n","        #src = [seq len, batch size, emb_dim]\n","        \n","        src = self.pos_encoder(src)\n","        \n","        #src = [seq len, batch size, emb_dim]\n","        \n","        hidden_state = self.transformer_encoder(src, self.src_mask)\n","        \n","        #output = [seq len, batch size, emb_dim]\n","        \n","        output = self.decoder(hidden_state)\n","        \n","        #output = [seq len, batch size, vocab_size]\n","        \n","        return F.log_softmax(output, dim=-1), hidden_state"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"gP7B-7v38o-k","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593257566229,"user_tz":-120,"elapsed":2126,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["vocab_size = len(TEXT.vocab)\n","# emb_dim = 256\n","# hid_dim = 256\n","# n_layers = 10\n","# n_heads = 8\n","# dropout = 0.1\n","\n","emb_dim = 128\n","hid_dim = 128\n","n_layers = 4\n","n_heads = 4\n","dropout = 0.1\n","\n","lr = 4\n","log_interval = 20\n","\n","model = TransformerModel(vocab_size, emb_dim, n_heads, hid_dim, n_layers, dropout)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"KDW3eBn98pF7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593257569537,"user_tz":-120,"elapsed":1893,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"outputId":"e3c51459-13a6-460b-d084-da88b883e369"},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["The model has 7,817,926 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2I9_i2tm8pOf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593257571575,"user_tz":-120,"elapsed":1955,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["import torch.optim as optim\n","\n","criterion = nn.NLLLoss()"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"WldZ_PHT8pYE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593257581861,"user_tz":-120,"elapsed":11885,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["model=model.to(device)\n","criterion=criterion.to(device)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"AKMMGus28phA","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593257592661,"user_tz":-120,"elapsed":589,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["def train(model, iterator, criterion):\n","    clip = 0.25\n","    total_loss = 0\n","    \n","    model.train()\n","            \n","    for k, batch in enumerate(iterator):\n","        data = batch.text\n","        targets = batch.target.view(-1)\n","\n","        data = data.to(device)\n","        targets = targets.to(device)\n","\n","        model.zero_grad()\n","      \n","        output, hidden = model(data) \n","\n","        output = output.view(-1, vocab_size)\n","        \n","        loss = criterion(output, targets)\n","                \n","        loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        for p in model.parameters():\n","            p.data.add_(-lr, p.grad.data)\n","        \n","        total_loss += loss.item()\n","        \n","        if k % log_interval == 0 and k > 0:\n","            cur_loss = total_loss / log_interval\n","            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {} | '\n","                    'loss {:5.2f} | ppl {:8.2f}'.format(epoch, k, len(iterator), lr, cur_loss, math.exp(cur_loss)))\n","            total_loss = 0\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"DdawGDOj8ZqV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593257593513,"user_tz":-120,"elapsed":1064,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["def evaluate(model, iterator, criterion):\n","    \n","    total_loss = 0\n","    \n","    model.eval()\n","        \n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","            data = batch.text\n","            targets = batch.target.view(-1)\n","\n","            data = data.to(device)\n","            targets = targets.to(device)\n","\n","            output, hidden = model(data)\n","\n","            output = output.view(-1, vocab_size)\n","            \n","            loss = criterion(output, targets).item()\n","\n","            total_loss += len(data) * loss\n","\n","        \n","    return total_loss / (len(iterator)*bptt - 1)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"U5bfvCzR89s2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593257596476,"user_tz":-120,"elapsed":2046,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"olB9u2R_891m","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593260164730,"user_tz":-120,"elapsed":2567107,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"outputId":"0f6bc3c8-7c68-4f4c-80a3-053633b8404d"},"source":["N_EPOCHS = 100\n","\n","best_valid_loss = float('inf')\n","counter = 0\n","patience = 5\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","    \n","    train(model, train_iter, criterion)\n","    valid_loss = evaluate(model, valid_iter, criterion)\n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):.2f}')\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        #torch.save(model.state_dict(), 'tut2-model.pt')\n","        counter = 0 \n","    else:\n","        lr /= 4.0\n","        counter += 1\n","        if counter >= patience:\n","            break\n","\n","    "],"execution_count":17,"outputs":[{"output_type":"stream","text":["/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha)\n"],"name":"stderr"},{"output_type":"stream","text":["| epoch   0 |    20/  224 batches | lr 4 | loss  8.63 | ppl  5598.79\n","| epoch   0 |    40/  224 batches | lr 4 | loss  7.38 | ppl  1599.76\n","| epoch   0 |    60/  224 batches | lr 4 | loss  7.18 | ppl  1310.59\n","| epoch   0 |    80/  224 batches | lr 4 | loss  6.99 | ppl  1086.52\n","| epoch   0 |   100/  224 batches | lr 4 | loss  6.88 | ppl   977.07\n","| epoch   0 |   120/  224 batches | lr 4 | loss  6.81 | ppl   904.11\n","| epoch   0 |   140/  224 batches | lr 4 | loss  6.65 | ppl   769.73\n","| epoch   0 |   160/  224 batches | lr 4 | loss  6.63 | ppl   756.54\n","| epoch   0 |   180/  224 batches | lr 4 | loss  6.58 | ppl   723.27\n","| epoch   0 |   200/  224 batches | lr 4 | loss  6.51 | ppl   673.17\n","| epoch   0 |   220/  224 batches | lr 4 | loss  6.51 | ppl   671.33\n","Epoch: 01 | Epoch Time: 0m 39s\n","\t Val. Loss: 5.856 |  Val. PPL: 349.18\n","| epoch   1 |    20/  224 batches | lr 4 | loss  6.76 | ppl   862.95\n","| epoch   1 |    40/  224 batches | lr 4 | loss  6.36 | ppl   578.93\n","| epoch   1 |    60/  224 batches | lr 4 | loss  6.40 | ppl   602.28\n","| epoch   1 |    80/  224 batches | lr 4 | loss  6.33 | ppl   560.81\n","| epoch   1 |   100/  224 batches | lr 4 | loss  6.29 | ppl   541.84\n","| epoch   1 |   120/  224 batches | lr 4 | loss  6.31 | ppl   551.60\n","| epoch   1 |   140/  224 batches | lr 4 | loss  6.24 | ppl   513.56\n","| epoch   1 |   160/  224 batches | lr 4 | loss  6.24 | ppl   514.74\n","| epoch   1 |   180/  224 batches | lr 4 | loss  6.21 | ppl   499.22\n","| epoch   1 |   200/  224 batches | lr 4 | loss  6.17 | ppl   478.38\n","| epoch   1 |   220/  224 batches | lr 4 | loss  6.18 | ppl   484.76\n","Epoch: 02 | Epoch Time: 0m 42s\n","\t Val. Loss: 5.488 |  Val. PPL: 241.79\n","| epoch   2 |    20/  224 batches | lr 4 | loss  6.44 | ppl   627.50\n","| epoch   2 |    40/  224 batches | lr 4 | loss  6.06 | ppl   430.43\n","| epoch   2 |    60/  224 batches | lr 4 | loss  6.10 | ppl   447.83\n","| epoch   2 |    80/  224 batches | lr 4 | loss  6.07 | ppl   430.80\n","| epoch   2 |   100/  224 batches | lr 4 | loss  6.03 | ppl   417.31\n","| epoch   2 |   120/  224 batches | lr 4 | loss  6.07 | ppl   432.50\n","| epoch   2 |   140/  224 batches | lr 4 | loss  6.00 | ppl   405.03\n","| epoch   2 |   160/  224 batches | lr 4 | loss  6.01 | ppl   407.60\n","| epoch   2 |   180/  224 batches | lr 4 | loss  5.97 | ppl   393.08\n","| epoch   2 |   200/  224 batches | lr 4 | loss  5.95 | ppl   382.70\n","| epoch   2 |   220/  224 batches | lr 4 | loss  5.97 | ppl   389.76\n","Epoch: 03 | Epoch Time: 0m 40s\n","\t Val. Loss: 5.322 |  Val. PPL: 204.83\n","| epoch   3 |    20/  224 batches | lr 4 | loss  6.22 | ppl   501.01\n","| epoch   3 |    40/  224 batches | lr 4 | loss  5.86 | ppl   350.89\n","| epoch   3 |    60/  224 batches | lr 4 | loss  5.90 | ppl   365.63\n","| epoch   3 |    80/  224 batches | lr 4 | loss  5.87 | ppl   353.70\n","| epoch   3 |   100/  224 batches | lr 4 | loss  5.84 | ppl   343.35\n","| epoch   3 |   120/  224 batches | lr 4 | loss  5.87 | ppl   355.04\n","| epoch   3 |   140/  224 batches | lr 4 | loss  5.82 | ppl   336.01\n","| epoch   3 |   160/  224 batches | lr 4 | loss  5.83 | ppl   340.49\n","| epoch   3 |   180/  224 batches | lr 4 | loss  5.80 | ppl   331.91\n","| epoch   3 |   200/  224 batches | lr 4 | loss  5.78 | ppl   323.16\n","| epoch   3 |   220/  224 batches | lr 4 | loss  5.80 | ppl   329.84\n","Epoch: 04 | Epoch Time: 0m 41s\n","\t Val. Loss: 5.158 |  Val. PPL: 173.90\n","| epoch   4 |    20/  224 batches | lr 4 | loss  6.05 | ppl   425.54\n","| epoch   4 |    40/  224 batches | lr 4 | loss  5.70 | ppl   299.02\n","| epoch   4 |    60/  224 batches | lr 4 | loss  5.75 | ppl   314.27\n","| epoch   4 |    80/  224 batches | lr 4 | loss  5.72 | ppl   304.23\n","| epoch   4 |   100/  224 batches | lr 4 | loss  5.69 | ppl   295.62\n","| epoch   4 |   120/  224 batches | lr 4 | loss  5.72 | ppl   303.39\n","| epoch   4 |   140/  224 batches | lr 4 | loss  5.68 | ppl   292.30\n","| epoch   4 |   160/  224 batches | lr 4 | loss  5.69 | ppl   296.84\n","| epoch   4 |   180/  224 batches | lr 4 | loss  5.67 | ppl   289.58\n","| epoch   4 |   200/  224 batches | lr 4 | loss  5.64 | ppl   280.96\n","| epoch   4 |   220/  224 batches | lr 4 | loss  5.66 | ppl   288.07\n","Epoch: 05 | Epoch Time: 0m 41s\n","\t Val. Loss: 5.104 |  Val. PPL: 164.73\n","| epoch   5 |    20/  224 batches | lr 4 | loss  5.92 | ppl   370.69\n","| epoch   5 |    40/  224 batches | lr 4 | loss  5.57 | ppl   262.19\n","| epoch   5 |    60/  224 batches | lr 4 | loss  5.61 | ppl   273.30\n","| epoch   5 |    80/  224 batches | lr 4 | loss  5.59 | ppl   268.86\n","| epoch   5 |   100/  224 batches | lr 4 | loss  5.57 | ppl   261.67\n","| epoch   5 |   120/  224 batches | lr 4 | loss  5.59 | ppl   268.56\n","| epoch   5 |   140/  224 batches | lr 4 | loss  5.56 | ppl   259.98\n","| epoch   5 |   160/  224 batches | lr 4 | loss  5.57 | ppl   262.82\n","| epoch   5 |   180/  224 batches | lr 4 | loss  5.55 | ppl   257.94\n","| epoch   5 |   200/  224 batches | lr 4 | loss  5.52 | ppl   249.65\n","| epoch   5 |   220/  224 batches | lr 4 | loss  5.55 | ppl   256.17\n","Epoch: 06 | Epoch Time: 0m 41s\n","\t Val. Loss: 5.029 |  Val. PPL: 152.70\n","| epoch   6 |    20/  224 batches | lr 4 | loss  5.79 | ppl   327.54\n","| epoch   6 |    40/  224 batches | lr 4 | loss  5.46 | ppl   234.55\n","| epoch   6 |    60/  224 batches | lr 4 | loss  5.50 | ppl   245.10\n","| epoch   6 |    80/  224 batches | lr 4 | loss  5.48 | ppl   239.49\n","| epoch   6 |   100/  224 batches | lr 4 | loss  5.46 | ppl   234.80\n","| epoch   6 |   120/  224 batches | lr 4 | loss  5.48 | ppl   238.73\n","| epoch   6 |   140/  224 batches | lr 4 | loss  5.45 | ppl   232.60\n","| epoch   6 |   160/  224 batches | lr 4 | loss  5.48 | ppl   239.34\n","| epoch   6 |   180/  224 batches | lr 4 | loss  5.45 | ppl   233.14\n","| epoch   6 |   200/  224 batches | lr 4 | loss  5.42 | ppl   224.98\n","| epoch   6 |   220/  224 batches | lr 4 | loss  5.45 | ppl   231.71\n","Epoch: 07 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.922 |  Val. PPL: 137.29\n","| epoch   7 |    20/  224 batches | lr 4 | loss  5.68 | ppl   294.18\n","| epoch   7 |    40/  224 batches | lr 4 | loss  5.36 | ppl   212.60\n","| epoch   7 |    60/  224 batches | lr 4 | loss  5.40 | ppl   220.31\n","| epoch   7 |    80/  224 batches | lr 4 | loss  5.38 | ppl   216.75\n","| epoch   7 |   100/  224 batches | lr 4 | loss  5.36 | ppl   212.85\n","| epoch   7 |   120/  224 batches | lr 4 | loss  5.38 | ppl   217.41\n","| epoch   7 |   140/  224 batches | lr 4 | loss  5.36 | ppl   213.07\n","| epoch   7 |   160/  224 batches | lr 4 | loss  5.38 | ppl   217.53\n","| epoch   7 |   180/  224 batches | lr 4 | loss  5.36 | ppl   212.93\n","| epoch   7 |   200/  224 batches | lr 4 | loss  5.32 | ppl   204.97\n","| epoch   7 |   220/  224 batches | lr 4 | loss  5.34 | ppl   209.25\n","Epoch: 08 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.890 |  Val. PPL: 132.95\n","| epoch   8 |    20/  224 batches | lr 4 | loss  5.59 | ppl   267.95\n","| epoch   8 |    40/  224 batches | lr 4 | loss  5.26 | ppl   192.46\n","| epoch   8 |    60/  224 batches | lr 4 | loss  5.31 | ppl   202.09\n","| epoch   8 |    80/  224 batches | lr 4 | loss  5.29 | ppl   198.48\n","| epoch   8 |   100/  224 batches | lr 4 | loss  5.27 | ppl   194.27\n","| epoch   8 |   120/  224 batches | lr 4 | loss  5.29 | ppl   198.60\n","| epoch   8 |   140/  224 batches | lr 4 | loss  5.28 | ppl   196.67\n","| epoch   8 |   160/  224 batches | lr 4 | loss  5.30 | ppl   199.37\n","| epoch   8 |   180/  224 batches | lr 4 | loss  5.28 | ppl   196.62\n","| epoch   8 |   200/  224 batches | lr 4 | loss  5.24 | ppl   188.31\n","| epoch   8 |   220/  224 batches | lr 4 | loss  5.26 | ppl   192.79\n","Epoch: 09 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.798 |  Val. PPL: 121.28\n","| epoch   9 |    20/  224 batches | lr 4 | loss  5.50 | ppl   244.10\n","| epoch   9 |    40/  224 batches | lr 4 | loss  5.19 | ppl   179.22\n","| epoch   9 |    60/  224 batches | lr 4 | loss  5.23 | ppl   186.33\n","| epoch   9 |    80/  224 batches | lr 4 | loss  5.20 | ppl   181.97\n","| epoch   9 |   100/  224 batches | lr 4 | loss  5.19 | ppl   180.06\n","| epoch   9 |   120/  224 batches | lr 4 | loss  5.21 | ppl   183.58\n","| epoch   9 |   140/  224 batches | lr 4 | loss  5.20 | ppl   181.20\n","| epoch   9 |   160/  224 batches | lr 4 | loss  5.23 | ppl   185.93\n","| epoch   9 |   180/  224 batches | lr 4 | loss  5.20 | ppl   181.94\n","| epoch   9 |   200/  224 batches | lr 4 | loss  5.16 | ppl   174.98\n","| epoch   9 |   220/  224 batches | lr 4 | loss  5.19 | ppl   178.79\n","Epoch: 10 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.734 |  Val. PPL: 113.80\n","| epoch  10 |    20/  224 batches | lr 4 | loss  5.42 | ppl   226.08\n","| epoch  10 |    40/  224 batches | lr 4 | loss  5.11 | ppl   166.29\n","| epoch  10 |    60/  224 batches | lr 4 | loss  5.16 | ppl   173.62\n","| epoch  10 |    80/  224 batches | lr 4 | loss  5.13 | ppl   168.97\n","| epoch  10 |   100/  224 batches | lr 4 | loss  5.12 | ppl   167.08\n","| epoch  10 |   120/  224 batches | lr 4 | loss  5.13 | ppl   169.80\n","| epoch  10 |   140/  224 batches | lr 4 | loss  5.13 | ppl   169.49\n","| epoch  10 |   160/  224 batches | lr 4 | loss  5.15 | ppl   172.99\n","| epoch  10 |   180/  224 batches | lr 4 | loss  5.13 | ppl   169.74\n","| epoch  10 |   200/  224 batches | lr 4 | loss  5.09 | ppl   163.16\n","| epoch  10 |   220/  224 batches | lr 4 | loss  5.12 | ppl   166.56\n","Epoch: 11 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.684 |  Val. PPL: 108.23\n","| epoch  11 |    20/  224 batches | lr 4 | loss  5.34 | ppl   209.04\n","| epoch  11 |    40/  224 batches | lr 4 | loss  5.04 | ppl   154.88\n","| epoch  11 |    60/  224 batches | lr 4 | loss  5.09 | ppl   162.25\n","| epoch  11 |    80/  224 batches | lr 4 | loss  5.06 | ppl   157.80\n","| epoch  11 |   100/  224 batches | lr 4 | loss  5.04 | ppl   155.07\n","| epoch  11 |   120/  224 batches | lr 4 | loss  5.07 | ppl   159.11\n","| epoch  11 |   140/  224 batches | lr 4 | loss  5.07 | ppl   158.69\n","| epoch  11 |   160/  224 batches | lr 4 | loss  5.09 | ppl   162.36\n","| epoch  11 |   180/  224 batches | lr 4 | loss  5.07 | ppl   158.84\n","| epoch  11 |   200/  224 batches | lr 4 | loss  5.03 | ppl   152.33\n","| epoch  11 |   220/  224 batches | lr 4 | loss  5.04 | ppl   154.95\n","Epoch: 12 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.657 |  Val. PPL: 105.33\n","| epoch  12 |    20/  224 batches | lr 4 | loss  5.28 | ppl   195.73\n","| epoch  12 |    40/  224 batches | lr 4 | loss  4.98 | ppl   145.99\n","| epoch  12 |    60/  224 batches | lr 4 | loss  5.02 | ppl   151.41\n","| epoch  12 |    80/  224 batches | lr 4 | loss  5.00 | ppl   148.62\n","| epoch  12 |   100/  224 batches | lr 4 | loss  4.99 | ppl   146.48\n","| epoch  12 |   120/  224 batches | lr 4 | loss  5.00 | ppl   148.67\n","| epoch  12 |   140/  224 batches | lr 4 | loss  5.00 | ppl   148.23\n","| epoch  12 |   160/  224 batches | lr 4 | loss  5.03 | ppl   152.98\n","| epoch  12 |   180/  224 batches | lr 4 | loss  5.01 | ppl   150.12\n","| epoch  12 |   200/  224 batches | lr 4 | loss  4.97 | ppl   143.38\n","| epoch  12 |   220/  224 batches | lr 4 | loss  4.99 | ppl   146.38\n","Epoch: 13 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.621 |  Val. PPL: 101.58\n","| epoch  13 |    20/  224 batches | lr 4 | loss  5.21 | ppl   182.67\n","| epoch  13 |    40/  224 batches | lr 4 | loss  4.92 | ppl   136.73\n","| epoch  13 |    60/  224 batches | lr 4 | loss  4.96 | ppl   142.77\n","| epoch  13 |    80/  224 batches | lr 4 | loss  4.94 | ppl   140.08\n","| epoch  13 |   100/  224 batches | lr 4 | loss  4.93 | ppl   137.97\n","| epoch  13 |   120/  224 batches | lr 4 | loss  4.94 | ppl   140.02\n","| epoch  13 |   140/  224 batches | lr 4 | loss  4.94 | ppl   140.35\n","| epoch  13 |   160/  224 batches | lr 4 | loss  4.98 | ppl   145.26\n","| epoch  13 |   180/  224 batches | lr 4 | loss  4.95 | ppl   141.63\n","| epoch  13 |   200/  224 batches | lr 4 | loss  4.91 | ppl   135.29\n","| epoch  13 |   220/  224 batches | lr 4 | loss  4.93 | ppl   137.96\n","Epoch: 14 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.588 |  Val. PPL: 98.29\n","| epoch  14 |    20/  224 batches | lr 4 | loss  5.15 | ppl   172.07\n","| epoch  14 |    40/  224 batches | lr 4 | loss  4.86 | ppl   129.44\n","| epoch  14 |    60/  224 batches | lr 4 | loss  4.91 | ppl   136.23\n","| epoch  14 |    80/  224 batches | lr 4 | loss  4.89 | ppl   132.42\n","| epoch  14 |   100/  224 batches | lr 4 | loss  4.87 | ppl   130.36\n","| epoch  14 |   120/  224 batches | lr 4 | loss  4.88 | ppl   132.23\n","| epoch  14 |   140/  224 batches | lr 4 | loss  4.89 | ppl   132.81\n","| epoch  14 |   160/  224 batches | lr 4 | loss  4.92 | ppl   137.11\n","| epoch  14 |   180/  224 batches | lr 4 | loss  4.90 | ppl   134.31\n","| epoch  14 |   200/  224 batches | lr 4 | loss  4.85 | ppl   128.31\n","| epoch  14 |   220/  224 batches | lr 4 | loss  4.88 | ppl   131.15\n","Epoch: 15 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.549 |  Val. PPL: 94.52\n","| epoch  15 |    20/  224 batches | lr 4 | loss  5.09 | ppl   163.18\n","| epoch  15 |    40/  224 batches | lr 4 | loss  4.81 | ppl   122.60\n","| epoch  15 |    60/  224 batches | lr 4 | loss  4.85 | ppl   128.31\n","| epoch  15 |    80/  224 batches | lr 4 | loss  4.83 | ppl   125.55\n","| epoch  15 |   100/  224 batches | lr 4 | loss  4.82 | ppl   123.52\n","| epoch  15 |   120/  224 batches | lr 4 | loss  4.84 | ppl   126.69\n","| epoch  15 |   140/  224 batches | lr 4 | loss  4.84 | ppl   126.24\n","| epoch  15 |   160/  224 batches | lr 4 | loss  4.88 | ppl   131.25\n","| epoch  15 |   180/  224 batches | lr 4 | loss  4.85 | ppl   127.61\n","| epoch  15 |   200/  224 batches | lr 4 | loss  4.81 | ppl   122.19\n","| epoch  15 |   220/  224 batches | lr 4 | loss  4.83 | ppl   125.26\n","Epoch: 16 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.515 |  Val. PPL: 91.35\n","| epoch  16 |    20/  224 batches | lr 4 | loss  5.04 | ppl   154.64\n","| epoch  16 |    40/  224 batches | lr 4 | loss  4.76 | ppl   117.04\n","| epoch  16 |    60/  224 batches | lr 4 | loss  4.81 | ppl   122.85\n","| epoch  16 |    80/  224 batches | lr 4 | loss  4.78 | ppl   118.84\n","| epoch  16 |   100/  224 batches | lr 4 | loss  4.77 | ppl   117.61\n","| epoch  16 |   120/  224 batches | lr 4 | loss  4.79 | ppl   120.21\n","| epoch  16 |   140/  224 batches | lr 4 | loss  4.79 | ppl   120.25\n","| epoch  16 |   160/  224 batches | lr 4 | loss  4.83 | ppl   125.03\n","| epoch  16 |   180/  224 batches | lr 4 | loss  4.80 | ppl   121.55\n","| epoch  16 |   200/  224 batches | lr 4 | loss  4.75 | ppl   115.86\n","| epoch  16 |   220/  224 batches | lr 4 | loss  4.79 | ppl   119.72\n","Epoch: 17 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.504 |  Val. PPL: 90.42\n","| epoch  17 |    20/  224 batches | lr 4 | loss  4.99 | ppl   147.17\n","| epoch  17 |    40/  224 batches | lr 4 | loss  4.72 | ppl   111.68\n","| epoch  17 |    60/  224 batches | lr 4 | loss  4.76 | ppl   117.22\n","| epoch  17 |    80/  224 batches | lr 4 | loss  4.74 | ppl   113.98\n","| epoch  17 |   100/  224 batches | lr 4 | loss  4.72 | ppl   112.14\n","| epoch  17 |   120/  224 batches | lr 4 | loss  4.74 | ppl   114.17\n","| epoch  17 |   140/  224 batches | lr 4 | loss  4.74 | ppl   114.79\n","| epoch  17 |   160/  224 batches | lr 4 | loss  4.78 | ppl   119.61\n","| epoch  17 |   180/  224 batches | lr 4 | loss  4.75 | ppl   115.99\n","| epoch  17 |   200/  224 batches | lr 4 | loss  4.71 | ppl   111.02\n","| epoch  17 |   220/  224 batches | lr 4 | loss  4.74 | ppl   114.61\n","Epoch: 18 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.483 |  Val. PPL: 88.51\n","| epoch  18 |    20/  224 batches | lr 4 | loss  4.94 | ppl   139.87\n","| epoch  18 |    40/  224 batches | lr 4 | loss  4.68 | ppl   107.49\n","| epoch  18 |    60/  224 batches | lr 4 | loss  4.72 | ppl   112.37\n","| epoch  18 |    80/  224 batches | lr 4 | loss  4.69 | ppl   108.66\n","| epoch  18 |   100/  224 batches | lr 4 | loss  4.68 | ppl   107.35\n","| epoch  18 |   120/  224 batches | lr 4 | loss  4.70 | ppl   109.94\n","| epoch  18 |   140/  224 batches | lr 4 | loss  4.70 | ppl   110.09\n","| epoch  18 |   160/  224 batches | lr 4 | loss  4.74 | ppl   113.99\n","| epoch  18 |   180/  224 batches | lr 4 | loss  4.72 | ppl   111.85\n","| epoch  18 |   200/  224 batches | lr 4 | loss  4.67 | ppl   106.44\n","| epoch  18 |   220/  224 batches | lr 4 | loss  4.69 | ppl   108.94\n","Epoch: 19 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.479 |  Val. PPL: 88.13\n","| epoch  19 |    20/  224 batches | lr 4 | loss  4.90 | ppl   134.51\n","| epoch  19 |    40/  224 batches | lr 4 | loss  4.63 | ppl   102.22\n","| epoch  19 |    60/  224 batches | lr 4 | loss  4.67 | ppl   107.01\n","| epoch  19 |    80/  224 batches | lr 4 | loss  4.64 | ppl   103.88\n","| epoch  19 |   100/  224 batches | lr 4 | loss  4.64 | ppl   103.16\n","| epoch  19 |   120/  224 batches | lr 4 | loss  4.66 | ppl   105.50\n","| epoch  19 |   140/  224 batches | lr 4 | loss  4.66 | ppl   105.31\n","| epoch  19 |   160/  224 batches | lr 4 | loss  4.69 | ppl   109.37\n","| epoch  19 |   180/  224 batches | lr 4 | loss  4.67 | ppl   106.18\n","| epoch  19 |   200/  224 batches | lr 4 | loss  4.63 | ppl   102.43\n","| epoch  19 |   220/  224 batches | lr 4 | loss  4.65 | ppl   104.82\n","Epoch: 20 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.453 |  Val. PPL: 85.87\n","| epoch  20 |    20/  224 batches | lr 4 | loss  4.86 | ppl   128.55\n","| epoch  20 |    40/  224 batches | lr 4 | loss  4.58 | ppl    97.81\n","| epoch  20 |    60/  224 batches | lr 4 | loss  4.63 | ppl   102.25\n","| epoch  20 |    80/  224 batches | lr 4 | loss  4.60 | ppl    99.51\n","| epoch  20 |   100/  224 batches | lr 4 | loss  4.60 | ppl    99.47\n","| epoch  20 |   120/  224 batches | lr 4 | loss  4.62 | ppl   101.23\n","| epoch  20 |   140/  224 batches | lr 4 | loss  4.62 | ppl   101.22\n","| epoch  20 |   160/  224 batches | lr 4 | loss  4.66 | ppl   105.57\n","| epoch  20 |   180/  224 batches | lr 4 | loss  4.64 | ppl   103.55\n","| epoch  20 |   200/  224 batches | lr 4 | loss  4.58 | ppl    97.89\n","| epoch  20 |   220/  224 batches | lr 4 | loss  4.62 | ppl   101.40\n","Epoch: 21 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.433 |  Val. PPL: 84.21\n","| epoch  21 |    20/  224 batches | lr 4 | loss  4.82 | ppl   123.51\n","| epoch  21 |    40/  224 batches | lr 4 | loss  4.54 | ppl    94.08\n","| epoch  21 |    60/  224 batches | lr 4 | loss  4.60 | ppl    99.57\n","| epoch  21 |    80/  224 batches | lr 4 | loss  4.57 | ppl    96.21\n","| epoch  21 |   100/  224 batches | lr 4 | loss  4.56 | ppl    95.11\n","| epoch  21 |   120/  224 batches | lr 4 | loss  4.59 | ppl    98.17\n","| epoch  21 |   140/  224 batches | lr 4 | loss  4.58 | ppl    97.34\n","| epoch  21 |   160/  224 batches | lr 4 | loss  4.63 | ppl   102.04\n","| epoch  21 |   180/  224 batches | lr 4 | loss  4.61 | ppl    99.98\n","| epoch  21 |   200/  224 batches | lr 4 | loss  4.55 | ppl    94.85\n","| epoch  21 |   220/  224 batches | lr 4 | loss  4.58 | ppl    97.74\n","Epoch: 22 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.417 |  Val. PPL: 82.84\n","| epoch  22 |    20/  224 batches | lr 4 | loss  4.78 | ppl   118.59\n","| epoch  22 |    40/  224 batches | lr 4 | loss  4.51 | ppl    90.80\n","| epoch  22 |    60/  224 batches | lr 4 | loss  4.56 | ppl    95.20\n","| epoch  22 |    80/  224 batches | lr 4 | loss  4.53 | ppl    92.74\n","| epoch  22 |   100/  224 batches | lr 4 | loss  4.52 | ppl    91.54\n","| epoch  22 |   120/  224 batches | lr 4 | loss  4.56 | ppl    95.16\n","| epoch  22 |   140/  224 batches | lr 4 | loss  4.54 | ppl    94.08\n","| epoch  22 |   160/  224 batches | lr 4 | loss  4.59 | ppl    98.19\n","| epoch  22 |   180/  224 batches | lr 4 | loss  4.57 | ppl    96.21\n","| epoch  22 |   200/  224 batches | lr 4 | loss  4.52 | ppl    91.72\n","| epoch  22 |   220/  224 batches | lr 4 | loss  4.55 | ppl    94.16\n","Epoch: 23 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.421 |  Val. PPL: 83.18\n","| epoch  23 |    20/  224 batches | lr 1.0 | loss  4.67 | ppl   106.91\n","| epoch  23 |    40/  224 batches | lr 1.0 | loss  4.40 | ppl    81.46\n","| epoch  23 |    60/  224 batches | lr 1.0 | loss  4.44 | ppl    85.01\n","| epoch  23 |    80/  224 batches | lr 1.0 | loss  4.41 | ppl    82.21\n","| epoch  23 |   100/  224 batches | lr 1.0 | loss  4.39 | ppl    80.92\n","| epoch  23 |   120/  224 batches | lr 1.0 | loss  4.42 | ppl    83.33\n","| epoch  23 |   140/  224 batches | lr 1.0 | loss  4.41 | ppl    82.55\n","| epoch  23 |   160/  224 batches | lr 1.0 | loss  4.45 | ppl    85.59\n","| epoch  23 |   180/  224 batches | lr 1.0 | loss  4.42 | ppl    83.11\n","| epoch  23 |   200/  224 batches | lr 1.0 | loss  4.37 | ppl    79.09\n","| epoch  23 |   220/  224 batches | lr 1.0 | loss  4.39 | ppl    80.81\n","Epoch: 24 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.347 |  Val. PPL: 77.23\n","| epoch  24 |    20/  224 batches | lr 1.0 | loss  4.63 | ppl   102.17\n","| epoch  24 |    40/  224 batches | lr 1.0 | loss  4.37 | ppl    78.66\n","| epoch  24 |    60/  224 batches | lr 1.0 | loss  4.41 | ppl    82.50\n","| epoch  24 |    80/  224 batches | lr 1.0 | loss  4.38 | ppl    80.06\n","| epoch  24 |   100/  224 batches | lr 1.0 | loss  4.37 | ppl    78.86\n","| epoch  24 |   120/  224 batches | lr 1.0 | loss  4.40 | ppl    81.56\n","| epoch  24 |   140/  224 batches | lr 1.0 | loss  4.39 | ppl    80.84\n","| epoch  24 |   160/  224 batches | lr 1.0 | loss  4.43 | ppl    83.93\n","| epoch  24 |   180/  224 batches | lr 1.0 | loss  4.41 | ppl    81.92\n","| epoch  24 |   200/  224 batches | lr 1.0 | loss  4.36 | ppl    77.89\n","| epoch  24 |   220/  224 batches | lr 1.0 | loss  4.38 | ppl    79.72\n","Epoch: 25 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.341 |  Val. PPL: 76.82\n","| epoch  25 |    20/  224 batches | lr 1.0 | loss  4.60 | ppl    99.84\n","| epoch  25 |    40/  224 batches | lr 1.0 | loss  4.35 | ppl    77.28\n","| epoch  25 |    60/  224 batches | lr 1.0 | loss  4.39 | ppl    80.80\n","| epoch  25 |    80/  224 batches | lr 1.0 | loss  4.36 | ppl    78.41\n","| epoch  25 |   100/  224 batches | lr 1.0 | loss  4.35 | ppl    77.54\n","| epoch  25 |   120/  224 batches | lr 1.0 | loss  4.38 | ppl    80.19\n","| epoch  25 |   140/  224 batches | lr 1.0 | loss  4.38 | ppl    79.62\n","| epoch  25 |   160/  224 batches | lr 1.0 | loss  4.41 | ppl    82.57\n","| epoch  25 |   180/  224 batches | lr 1.0 | loss  4.39 | ppl    80.65\n","| epoch  25 |   200/  224 batches | lr 1.0 | loss  4.34 | ppl    76.84\n","| epoch  25 |   220/  224 batches | lr 1.0 | loss  4.36 | ppl    78.57\n","Epoch: 26 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.335 |  Val. PPL: 76.36\n","| epoch  26 |    20/  224 batches | lr 1.0 | loss  4.59 | ppl    98.02\n","| epoch  26 |    40/  224 batches | lr 1.0 | loss  4.33 | ppl    75.89\n","| epoch  26 |    60/  224 batches | lr 1.0 | loss  4.38 | ppl    79.53\n","| epoch  26 |    80/  224 batches | lr 1.0 | loss  4.34 | ppl    76.94\n","| epoch  26 |   100/  224 batches | lr 1.0 | loss  4.34 | ppl    76.38\n","| epoch  26 |   120/  224 batches | lr 1.0 | loss  4.37 | ppl    79.04\n","| epoch  26 |   140/  224 batches | lr 1.0 | loss  4.36 | ppl    78.42\n","| epoch  26 |   160/  224 batches | lr 1.0 | loss  4.40 | ppl    81.49\n","| epoch  26 |   180/  224 batches | lr 1.0 | loss  4.37 | ppl    79.43\n","| epoch  26 |   200/  224 batches | lr 1.0 | loss  4.33 | ppl    75.74\n","| epoch  26 |   220/  224 batches | lr 1.0 | loss  4.35 | ppl    77.45\n","Epoch: 27 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.333 |  Val. PPL: 76.17\n","| epoch  27 |    20/  224 batches | lr 1.0 | loss  4.57 | ppl    96.31\n","| epoch  27 |    40/  224 batches | lr 1.0 | loss  4.31 | ppl    74.58\n","| epoch  27 |    60/  224 batches | lr 1.0 | loss  4.36 | ppl    78.10\n","| epoch  27 |    80/  224 batches | lr 1.0 | loss  4.33 | ppl    76.12\n","| epoch  27 |   100/  224 batches | lr 1.0 | loss  4.32 | ppl    75.27\n","| epoch  27 |   120/  224 batches | lr 1.0 | loss  4.36 | ppl    78.07\n","| epoch  27 |   140/  224 batches | lr 1.0 | loss  4.35 | ppl    77.33\n","| epoch  27 |   160/  224 batches | lr 1.0 | loss  4.38 | ppl    80.21\n","| epoch  27 |   180/  224 batches | lr 1.0 | loss  4.36 | ppl    78.29\n","| epoch  27 |   200/  224 batches | lr 1.0 | loss  4.31 | ppl    74.49\n","| epoch  27 |   220/  224 batches | lr 1.0 | loss  4.34 | ppl    76.42\n","Epoch: 28 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.330 |  Val. PPL: 75.92\n","| epoch  28 |    20/  224 batches | lr 1.0 | loss  4.55 | ppl    94.64\n","| epoch  28 |    40/  224 batches | lr 1.0 | loss  4.30 | ppl    73.50\n","| epoch  28 |    60/  224 batches | lr 1.0 | loss  4.34 | ppl    77.02\n","| epoch  28 |    80/  224 batches | lr 1.0 | loss  4.31 | ppl    74.69\n","| epoch  28 |   100/  224 batches | lr 1.0 | loss  4.30 | ppl    74.06\n","| epoch  28 |   120/  224 batches | lr 1.0 | loss  4.35 | ppl    77.24\n","| epoch  28 |   140/  224 batches | lr 1.0 | loss  4.34 | ppl    76.34\n","| epoch  28 |   160/  224 batches | lr 1.0 | loss  4.37 | ppl    79.15\n","| epoch  28 |   180/  224 batches | lr 1.0 | loss  4.35 | ppl    77.25\n","| epoch  28 |   200/  224 batches | lr 1.0 | loss  4.30 | ppl    73.60\n","| epoch  28 |   220/  224 batches | lr 1.0 | loss  4.32 | ppl    75.56\n","Epoch: 29 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.327 |  Val. PPL: 75.68\n","| epoch  29 |    20/  224 batches | lr 1.0 | loss  4.54 | ppl    93.48\n","| epoch  29 |    40/  224 batches | lr 1.0 | loss  4.28 | ppl    72.44\n","| epoch  29 |    60/  224 batches | lr 1.0 | loss  4.33 | ppl    75.93\n","| epoch  29 |    80/  224 batches | lr 1.0 | loss  4.30 | ppl    73.85\n","| epoch  29 |   100/  224 batches | lr 1.0 | loss  4.29 | ppl    73.15\n","| epoch  29 |   120/  224 batches | lr 1.0 | loss  4.33 | ppl    75.96\n","| epoch  29 |   140/  224 batches | lr 1.0 | loss  4.32 | ppl    75.40\n","| epoch  29 |   160/  224 batches | lr 1.0 | loss  4.36 | ppl    78.03\n","| epoch  29 |   180/  224 batches | lr 1.0 | loss  4.33 | ppl    76.25\n","| epoch  29 |   200/  224 batches | lr 1.0 | loss  4.29 | ppl    72.91\n","| epoch  29 |   220/  224 batches | lr 1.0 | loss  4.31 | ppl    74.60\n","Epoch: 30 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.322 |  Val. PPL: 75.37\n","| epoch  30 |    20/  224 batches | lr 1.0 | loss  4.52 | ppl    91.96\n","| epoch  30 |    40/  224 batches | lr 1.0 | loss  4.27 | ppl    71.45\n","| epoch  30 |    60/  224 batches | lr 1.0 | loss  4.32 | ppl    75.05\n","| epoch  30 |    80/  224 batches | lr 1.0 | loss  4.29 | ppl    72.78\n","| epoch  30 |   100/  224 batches | lr 1.0 | loss  4.28 | ppl    72.23\n","| epoch  30 |   120/  224 batches | lr 1.0 | loss  4.32 | ppl    75.03\n","| epoch  30 |   140/  224 batches | lr 1.0 | loss  4.31 | ppl    74.57\n","| epoch  30 |   160/  224 batches | lr 1.0 | loss  4.35 | ppl    77.31\n","| epoch  30 |   180/  224 batches | lr 1.0 | loss  4.32 | ppl    75.44\n","| epoch  30 |   200/  224 batches | lr 1.0 | loss  4.28 | ppl    71.89\n","| epoch  30 |   220/  224 batches | lr 1.0 | loss  4.30 | ppl    73.57\n","Epoch: 31 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.321 |  Val. PPL: 75.25\n","| epoch  31 |    20/  224 batches | lr 1.0 | loss  4.51 | ppl    90.74\n","| epoch  31 |    40/  224 batches | lr 1.0 | loss  4.26 | ppl    70.57\n","| epoch  31 |    60/  224 batches | lr 1.0 | loss  4.30 | ppl    73.81\n","| epoch  31 |    80/  224 batches | lr 1.0 | loss  4.27 | ppl    71.84\n","| epoch  31 |   100/  224 batches | lr 1.0 | loss  4.27 | ppl    71.19\n","| epoch  31 |   120/  224 batches | lr 1.0 | loss  4.30 | ppl    74.00\n","| epoch  31 |   140/  224 batches | lr 1.0 | loss  4.30 | ppl    73.37\n","| epoch  31 |   160/  224 batches | lr 1.0 | loss  4.33 | ppl    76.13\n","| epoch  31 |   180/  224 batches | lr 1.0 | loss  4.31 | ppl    74.62\n","| epoch  31 |   200/  224 batches | lr 1.0 | loss  4.26 | ppl    71.04\n","| epoch  31 |   220/  224 batches | lr 1.0 | loss  4.29 | ppl    72.93\n","Epoch: 32 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.317 |  Val. PPL: 74.93\n","| epoch  32 |    20/  224 batches | lr 1.0 | loss  4.49 | ppl    89.50\n","| epoch  32 |    40/  224 batches | lr 1.0 | loss  4.24 | ppl    69.48\n","| epoch  32 |    60/  224 batches | lr 1.0 | loss  4.29 | ppl    73.19\n","| epoch  32 |    80/  224 batches | lr 1.0 | loss  4.26 | ppl    70.87\n","| epoch  32 |   100/  224 batches | lr 1.0 | loss  4.25 | ppl    70.34\n","| epoch  32 |   120/  224 batches | lr 1.0 | loss  4.29 | ppl    73.10\n","| epoch  32 |   140/  224 batches | lr 1.0 | loss  4.28 | ppl    72.56\n","| epoch  32 |   160/  224 batches | lr 1.0 | loss  4.32 | ppl    75.37\n","| epoch  32 |   180/  224 batches | lr 1.0 | loss  4.30 | ppl    73.47\n","| epoch  32 |   200/  224 batches | lr 1.0 | loss  4.25 | ppl    70.27\n","| epoch  32 |   220/  224 batches | lr 1.0 | loss  4.28 | ppl    71.98\n","Epoch: 33 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.315 |  Val. PPL: 74.82\n","| epoch  33 |    20/  224 batches | lr 1.0 | loss  4.48 | ppl    88.42\n","| epoch  33 |    40/  224 batches | lr 1.0 | loss  4.23 | ppl    68.81\n","| epoch  33 |    60/  224 batches | lr 1.0 | loss  4.28 | ppl    72.23\n","| epoch  33 |    80/  224 batches | lr 1.0 | loss  4.25 | ppl    70.21\n","| epoch  33 |   100/  224 batches | lr 1.0 | loss  4.24 | ppl    69.48\n","| epoch  33 |   120/  224 batches | lr 1.0 | loss  4.28 | ppl    72.26\n","| epoch  33 |   140/  224 batches | lr 1.0 | loss  4.27 | ppl    71.57\n","| epoch  33 |   160/  224 batches | lr 1.0 | loss  4.31 | ppl    74.34\n","| epoch  33 |   180/  224 batches | lr 1.0 | loss  4.29 | ppl    72.73\n","| epoch  33 |   200/  224 batches | lr 1.0 | loss  4.24 | ppl    69.45\n","| epoch  33 |   220/  224 batches | lr 1.0 | loss  4.26 | ppl    71.05\n","Epoch: 34 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.312 |  Val. PPL: 74.62\n","| epoch  34 |    20/  224 batches | lr 1.0 | loss  4.47 | ppl    87.09\n","| epoch  34 |    40/  224 batches | lr 1.0 | loss  4.22 | ppl    67.90\n","| epoch  34 |    60/  224 batches | lr 1.0 | loss  4.26 | ppl    71.10\n","| epoch  34 |    80/  224 batches | lr 1.0 | loss  4.24 | ppl    69.20\n","| epoch  34 |   100/  224 batches | lr 1.0 | loss  4.23 | ppl    68.92\n","| epoch  34 |   120/  224 batches | lr 1.0 | loss  4.27 | ppl    71.62\n","| epoch  34 |   140/  224 batches | lr 1.0 | loss  4.26 | ppl    70.88\n","| epoch  34 |   160/  224 batches | lr 1.0 | loss  4.30 | ppl    73.59\n","| epoch  34 |   180/  224 batches | lr 1.0 | loss  4.28 | ppl    71.92\n","| epoch  34 |   200/  224 batches | lr 1.0 | loss  4.23 | ppl    68.76\n","| epoch  34 |   220/  224 batches | lr 1.0 | loss  4.25 | ppl    70.29\n","Epoch: 35 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.310 |  Val. PPL: 74.46\n","| epoch  35 |    20/  224 batches | lr 1.0 | loss  4.46 | ppl    86.09\n","| epoch  35 |    40/  224 batches | lr 1.0 | loss  4.21 | ppl    67.20\n","| epoch  35 |    60/  224 batches | lr 1.0 | loss  4.25 | ppl    70.34\n","| epoch  35 |    80/  224 batches | lr 1.0 | loss  4.22 | ppl    68.31\n","| epoch  35 |   100/  224 batches | lr 1.0 | loss  4.22 | ppl    67.96\n","| epoch  35 |   120/  224 batches | lr 1.0 | loss  4.26 | ppl    70.70\n","| epoch  35 |   140/  224 batches | lr 1.0 | loss  4.25 | ppl    70.23\n","| epoch  35 |   160/  224 batches | lr 1.0 | loss  4.29 | ppl    72.63\n","| epoch  35 |   180/  224 batches | lr 1.0 | loss  4.26 | ppl    71.10\n","| epoch  35 |   200/  224 batches | lr 1.0 | loss  4.22 | ppl    67.86\n","| epoch  35 |   220/  224 batches | lr 1.0 | loss  4.24 | ppl    69.51\n","Epoch: 36 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.309 |  Val. PPL: 74.34\n","| epoch  36 |    20/  224 batches | lr 1.0 | loss  4.44 | ppl    84.96\n","| epoch  36 |    40/  224 batches | lr 1.0 | loss  4.19 | ppl    66.26\n","| epoch  36 |    60/  224 batches | lr 1.0 | loss  4.24 | ppl    69.38\n","| epoch  36 |    80/  224 batches | lr 1.0 | loss  4.22 | ppl    67.75\n","| epoch  36 |   100/  224 batches | lr 1.0 | loss  4.21 | ppl    67.16\n","| epoch  36 |   120/  224 batches | lr 1.0 | loss  4.25 | ppl    70.05\n","| epoch  36 |   140/  224 batches | lr 1.0 | loss  4.24 | ppl    69.40\n","| epoch  36 |   160/  224 batches | lr 1.0 | loss  4.28 | ppl    71.90\n","| epoch  36 |   180/  224 batches | lr 1.0 | loss  4.25 | ppl    70.35\n","| epoch  36 |   200/  224 batches | lr 1.0 | loss  4.21 | ppl    67.15\n","| epoch  36 |   220/  224 batches | lr 1.0 | loss  4.23 | ppl    68.62\n","Epoch: 37 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.304 |  Val. PPL: 74.00\n","| epoch  37 |    20/  224 batches | lr 1.0 | loss  4.43 | ppl    83.87\n","| epoch  37 |    40/  224 batches | lr 1.0 | loss  4.18 | ppl    65.50\n","| epoch  37 |    60/  224 batches | lr 1.0 | loss  4.23 | ppl    68.62\n","| epoch  37 |    80/  224 batches | lr 1.0 | loss  4.20 | ppl    66.91\n","| epoch  37 |   100/  224 batches | lr 1.0 | loss  4.19 | ppl    66.34\n","| epoch  37 |   120/  224 batches | lr 1.0 | loss  4.24 | ppl    69.40\n","| epoch  37 |   140/  224 batches | lr 1.0 | loss  4.23 | ppl    68.52\n","| epoch  37 |   160/  224 batches | lr 1.0 | loss  4.26 | ppl    71.05\n","| epoch  37 |   180/  224 batches | lr 1.0 | loss  4.24 | ppl    69.63\n","| epoch  37 |   200/  224 batches | lr 1.0 | loss  4.20 | ppl    66.49\n","| epoch  37 |   220/  224 batches | lr 1.0 | loss  4.22 | ppl    67.97\n","Epoch: 38 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.303 |  Val. PPL: 73.94\n","| epoch  38 |    20/  224 batches | lr 1.0 | loss  4.42 | ppl    83.08\n","| epoch  38 |    40/  224 batches | lr 1.0 | loss  4.17 | ppl    64.76\n","| epoch  38 |    60/  224 batches | lr 1.0 | loss  4.22 | ppl    67.98\n","| epoch  38 |    80/  224 batches | lr 1.0 | loss  4.19 | ppl    66.16\n","| epoch  38 |   100/  224 batches | lr 1.0 | loss  4.18 | ppl    65.65\n","| epoch  38 |   120/  224 batches | lr 1.0 | loss  4.22 | ppl    68.32\n","| epoch  38 |   140/  224 batches | lr 1.0 | loss  4.22 | ppl    67.88\n","| epoch  38 |   160/  224 batches | lr 1.0 | loss  4.25 | ppl    70.43\n","| epoch  38 |   180/  224 batches | lr 1.0 | loss  4.23 | ppl    68.75\n","| epoch  38 |   200/  224 batches | lr 1.0 | loss  4.19 | ppl    65.71\n","| epoch  38 |   220/  224 batches | lr 1.0 | loss  4.21 | ppl    67.24\n","Epoch: 39 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.302 |  Val. PPL: 73.84\n","| epoch  39 |    20/  224 batches | lr 1.0 | loss  4.41 | ppl    81.97\n","| epoch  39 |    40/  224 batches | lr 1.0 | loss  4.16 | ppl    64.15\n","| epoch  39 |    60/  224 batches | lr 1.0 | loss  4.21 | ppl    67.12\n","| epoch  39 |    80/  224 batches | lr 1.0 | loss  4.18 | ppl    65.31\n","| epoch  39 |   100/  224 batches | lr 1.0 | loss  4.17 | ppl    64.89\n","| epoch  39 |   120/  224 batches | lr 1.0 | loss  4.22 | ppl    67.93\n","| epoch  39 |   140/  224 batches | lr 1.0 | loss  4.21 | ppl    67.17\n","| epoch  39 |   160/  224 batches | lr 1.0 | loss  4.24 | ppl    69.67\n","| epoch  39 |   180/  224 batches | lr 1.0 | loss  4.22 | ppl    68.32\n","| epoch  39 |   200/  224 batches | lr 1.0 | loss  4.17 | ppl    65.02\n","| epoch  39 |   220/  224 batches | lr 1.0 | loss  4.20 | ppl    66.79\n","Epoch: 40 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.301 |  Val. PPL: 73.80\n","| epoch  40 |    20/  224 batches | lr 1.0 | loss  4.39 | ppl    80.94\n","| epoch  40 |    40/  224 batches | lr 1.0 | loss  4.15 | ppl    63.42\n","| epoch  40 |    60/  224 batches | lr 1.0 | loss  4.20 | ppl    66.54\n","| epoch  40 |    80/  224 batches | lr 1.0 | loss  4.17 | ppl    64.77\n","| epoch  40 |   100/  224 batches | lr 1.0 | loss  4.16 | ppl    64.27\n","| epoch  40 |   120/  224 batches | lr 1.0 | loss  4.21 | ppl    67.11\n","| epoch  40 |   140/  224 batches | lr 1.0 | loss  4.20 | ppl    66.42\n","| epoch  40 |   160/  224 batches | lr 1.0 | loss  4.23 | ppl    68.88\n","| epoch  40 |   180/  224 batches | lr 1.0 | loss  4.21 | ppl    67.41\n","| epoch  40 |   200/  224 batches | lr 1.0 | loss  4.17 | ppl    64.57\n","| epoch  40 |   220/  224 batches | lr 1.0 | loss  4.19 | ppl    65.95\n","Epoch: 41 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.300 |  Val. PPL: 73.67\n","| epoch  41 |    20/  224 batches | lr 1.0 | loss  4.38 | ppl    80.18\n","| epoch  41 |    40/  224 batches | lr 1.0 | loss  4.14 | ppl    62.72\n","| epoch  41 |    60/  224 batches | lr 1.0 | loss  4.19 | ppl    65.76\n","| epoch  41 |    80/  224 batches | lr 1.0 | loss  4.16 | ppl    64.25\n","| epoch  41 |   100/  224 batches | lr 1.0 | loss  4.15 | ppl    63.70\n","| epoch  41 |   120/  224 batches | lr 1.0 | loss  4.20 | ppl    66.37\n","| epoch  41 |   140/  224 batches | lr 1.0 | loss  4.19 | ppl    65.81\n","| epoch  41 |   160/  224 batches | lr 1.0 | loss  4.22 | ppl    68.04\n","| epoch  41 |   180/  224 batches | lr 1.0 | loss  4.20 | ppl    66.75\n","| epoch  41 |   200/  224 batches | lr 1.0 | loss  4.16 | ppl    63.78\n","| epoch  41 |   220/  224 batches | lr 1.0 | loss  4.18 | ppl    65.30\n","Epoch: 42 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.298 |  Val. PPL: 73.58\n","| epoch  42 |    20/  224 batches | lr 1.0 | loss  4.37 | ppl    79.35\n","| epoch  42 |    40/  224 batches | lr 1.0 | loss  4.13 | ppl    62.10\n","| epoch  42 |    60/  224 batches | lr 1.0 | loss  4.18 | ppl    65.17\n","| epoch  42 |    80/  224 batches | lr 1.0 | loss  4.15 | ppl    63.50\n","| epoch  42 |   100/  224 batches | lr 1.0 | loss  4.14 | ppl    62.94\n","| epoch  42 |   120/  224 batches | lr 1.0 | loss  4.19 | ppl    65.80\n","| epoch  42 |   140/  224 batches | lr 1.0 | loss  4.18 | ppl    65.18\n","| epoch  42 |   160/  224 batches | lr 1.0 | loss  4.21 | ppl    67.60\n","| epoch  42 |   180/  224 batches | lr 1.0 | loss  4.19 | ppl    66.06\n","| epoch  42 |   200/  224 batches | lr 1.0 | loss  4.14 | ppl    63.05\n","| epoch  42 |   220/  224 batches | lr 1.0 | loss  4.17 | ppl    64.65\n","Epoch: 43 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.295 |  Val. PPL: 73.32\n","| epoch  43 |    20/  224 batches | lr 1.0 | loss  4.36 | ppl    78.39\n","| epoch  43 |    40/  224 batches | lr 1.0 | loss  4.12 | ppl    61.44\n","| epoch  43 |    60/  224 batches | lr 1.0 | loss  4.17 | ppl    64.52\n","| epoch  43 |    80/  224 batches | lr 1.0 | loss  4.14 | ppl    62.70\n","| epoch  43 |   100/  224 batches | lr 1.0 | loss  4.13 | ppl    62.35\n","| epoch  43 |   120/  224 batches | lr 1.0 | loss  4.18 | ppl    65.24\n","| epoch  43 |   140/  224 batches | lr 1.0 | loss  4.17 | ppl    64.67\n","| epoch  43 |   160/  224 batches | lr 1.0 | loss  4.20 | ppl    66.94\n","| epoch  43 |   180/  224 batches | lr 1.0 | loss  4.18 | ppl    65.46\n","| epoch  43 |   200/  224 batches | lr 1.0 | loss  4.13 | ppl    62.47\n","| epoch  43 |   220/  224 batches | lr 1.0 | loss  4.16 | ppl    64.18\n","Epoch: 44 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.294 |  Val. PPL: 73.24\n","| epoch  44 |    20/  224 batches | lr 1.0 | loss  4.35 | ppl    77.50\n","| epoch  44 |    40/  224 batches | lr 1.0 | loss  4.11 | ppl    60.80\n","| epoch  44 |    60/  224 batches | lr 1.0 | loss  4.16 | ppl    63.77\n","| epoch  44 |    80/  224 batches | lr 1.0 | loss  4.13 | ppl    62.04\n","| epoch  44 |   100/  224 batches | lr 1.0 | loss  4.12 | ppl    61.73\n","| epoch  44 |   120/  224 batches | lr 1.0 | loss  4.17 | ppl    64.48\n","| epoch  44 |   140/  224 batches | lr 1.0 | loss  4.16 | ppl    63.98\n","| epoch  44 |   160/  224 batches | lr 1.0 | loss  4.19 | ppl    66.33\n","| epoch  44 |   180/  224 batches | lr 1.0 | loss  4.17 | ppl    64.92\n","| epoch  44 |   200/  224 batches | lr 1.0 | loss  4.13 | ppl    61.99\n","| epoch  44 |   220/  224 batches | lr 1.0 | loss  4.15 | ppl    63.51\n","Epoch: 45 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.295 |  Val. PPL: 73.30\n","| epoch  45 |    20/  224 batches | lr 0.25 | loss  4.35 | ppl    77.33\n","| epoch  45 |    40/  224 batches | lr 0.25 | loss  4.10 | ppl    60.44\n","| epoch  45 |    60/  224 batches | lr 0.25 | loss  4.15 | ppl    63.46\n","| epoch  45 |    80/  224 batches | lr 0.25 | loss  4.12 | ppl    61.66\n","| epoch  45 |   100/  224 batches | lr 0.25 | loss  4.11 | ppl    61.13\n","| epoch  45 |   120/  224 batches | lr 0.25 | loss  4.16 | ppl    63.77\n","| epoch  45 |   140/  224 batches | lr 0.25 | loss  4.14 | ppl    62.88\n","| epoch  45 |   160/  224 batches | lr 0.25 | loss  4.17 | ppl    64.72\n","| epoch  45 |   180/  224 batches | lr 0.25 | loss  4.14 | ppl    63.04\n","| epoch  45 |   200/  224 batches | lr 0.25 | loss  4.09 | ppl    59.99\n","| epoch  45 |   220/  224 batches | lr 0.25 | loss  4.12 | ppl    61.27\n","Epoch: 46 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.282 |  Val. PPL: 72.41\n","| epoch  46 |    20/  224 batches | lr 0.25 | loss  4.34 | ppl    76.65\n","| epoch  46 |    40/  224 batches | lr 0.25 | loss  4.10 | ppl    60.07\n","| epoch  46 |    60/  224 batches | lr 0.25 | loss  4.14 | ppl    62.94\n","| epoch  46 |    80/  224 batches | lr 0.25 | loss  4.11 | ppl    61.09\n","| epoch  46 |   100/  224 batches | lr 0.25 | loss  4.11 | ppl    60.78\n","| epoch  46 |   120/  224 batches | lr 0.25 | loss  4.15 | ppl    63.48\n","| epoch  46 |   140/  224 batches | lr 0.25 | loss  4.14 | ppl    62.49\n","| epoch  46 |   160/  224 batches | lr 0.25 | loss  4.17 | ppl    64.55\n","| epoch  46 |   180/  224 batches | lr 0.25 | loss  4.14 | ppl    62.89\n","| epoch  46 |   200/  224 batches | lr 0.25 | loss  4.09 | ppl    59.98\n","| epoch  46 |   220/  224 batches | lr 0.25 | loss  4.12 | ppl    61.43\n","Epoch: 47 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.281 |  Val. PPL: 72.35\n","| epoch  47 |    20/  224 batches | lr 0.25 | loss  4.33 | ppl    76.12\n","| epoch  47 |    40/  224 batches | lr 0.25 | loss  4.09 | ppl    59.74\n","| epoch  47 |    60/  224 batches | lr 0.25 | loss  4.13 | ppl    62.47\n","| epoch  47 |    80/  224 batches | lr 0.25 | loss  4.11 | ppl    60.69\n","| epoch  47 |   100/  224 batches | lr 0.25 | loss  4.10 | ppl    60.51\n","| epoch  47 |   120/  224 batches | lr 0.25 | loss  4.14 | ppl    63.11\n","| epoch  47 |   140/  224 batches | lr 0.25 | loss  4.13 | ppl    62.18\n","| epoch  47 |   160/  224 batches | lr 0.25 | loss  4.17 | ppl    64.41\n","| epoch  47 |   180/  224 batches | lr 0.25 | loss  4.14 | ppl    62.73\n","| epoch  47 |   200/  224 batches | lr 0.25 | loss  4.09 | ppl    59.96\n","| epoch  47 |   220/  224 batches | lr 0.25 | loss  4.12 | ppl    61.32\n","Epoch: 48 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.281 |  Val. PPL: 72.28\n","| epoch  48 |    20/  224 batches | lr 0.25 | loss  4.33 | ppl    75.82\n","| epoch  48 |    40/  224 batches | lr 0.25 | loss  4.08 | ppl    59.43\n","| epoch  48 |    60/  224 batches | lr 0.25 | loss  4.13 | ppl    62.34\n","| epoch  48 |    80/  224 batches | lr 0.25 | loss  4.10 | ppl    60.60\n","| epoch  48 |   100/  224 batches | lr 0.25 | loss  4.10 | ppl    60.23\n","| epoch  48 |   120/  224 batches | lr 0.25 | loss  4.14 | ppl    62.89\n","| epoch  48 |   140/  224 batches | lr 0.25 | loss  4.13 | ppl    62.04\n","| epoch  48 |   160/  224 batches | lr 0.25 | loss  4.16 | ppl    64.22\n","| epoch  48 |   180/  224 batches | lr 0.25 | loss  4.14 | ppl    62.58\n","| epoch  48 |   200/  224 batches | lr 0.25 | loss  4.09 | ppl    59.84\n","| epoch  48 |   220/  224 batches | lr 0.25 | loss  4.11 | ppl    61.17\n","Epoch: 49 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.281 |  Val. PPL: 72.32\n","| epoch  49 |    20/  224 batches | lr 0.0625 | loss  4.33 | ppl    76.14\n","| epoch  49 |    40/  224 batches | lr 0.0625 | loss  4.09 | ppl    60.00\n","| epoch  49 |    60/  224 batches | lr 0.0625 | loss  4.14 | ppl    62.78\n","| epoch  49 |    80/  224 batches | lr 0.0625 | loss  4.11 | ppl    61.06\n","| epoch  49 |   100/  224 batches | lr 0.0625 | loss  4.10 | ppl    60.57\n","| epoch  49 |   120/  224 batches | lr 0.0625 | loss  4.15 | ppl    63.34\n","| epoch  49 |   140/  224 batches | lr 0.0625 | loss  4.13 | ppl    62.39\n","| epoch  49 |   160/  224 batches | lr 0.0625 | loss  4.16 | ppl    64.20\n","| epoch  49 |   180/  224 batches | lr 0.0625 | loss  4.13 | ppl    62.27\n","| epoch  49 |   200/  224 batches | lr 0.0625 | loss  4.08 | ppl    59.33\n","| epoch  49 |   220/  224 batches | lr 0.0625 | loss  4.11 | ppl    60.95\n","Epoch: 50 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.275 |  Val. PPL: 71.91\n","| epoch  50 |    20/  224 batches | lr 0.0625 | loss  4.33 | ppl    75.84\n","| epoch  50 |    40/  224 batches | lr 0.0625 | loss  4.09 | ppl    59.56\n","| epoch  50 |    60/  224 batches | lr 0.0625 | loss  4.14 | ppl    62.61\n","| epoch  50 |    80/  224 batches | lr 0.0625 | loss  4.11 | ppl    60.81\n","| epoch  50 |   100/  224 batches | lr 0.0625 | loss  4.10 | ppl    60.19\n","| epoch  50 |   120/  224 batches | lr 0.0625 | loss  4.14 | ppl    63.01\n","| epoch  50 |   140/  224 batches | lr 0.0625 | loss  4.13 | ppl    62.11\n","| epoch  50 |   160/  224 batches | lr 0.0625 | loss  4.16 | ppl    64.15\n","| epoch  50 |   180/  224 batches | lr 0.0625 | loss  4.13 | ppl    62.41\n","| epoch  50 |   200/  224 batches | lr 0.0625 | loss  4.09 | ppl    59.53\n","| epoch  50 |   220/  224 batches | lr 0.0625 | loss  4.11 | ppl    60.90\n","Epoch: 51 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.275 |  Val. PPL: 71.85\n","| epoch  51 |    20/  224 batches | lr 0.0625 | loss  4.33 | ppl    75.91\n","| epoch  51 |    40/  224 batches | lr 0.0625 | loss  4.09 | ppl    59.66\n","| epoch  51 |    60/  224 batches | lr 0.0625 | loss  4.13 | ppl    62.40\n","| epoch  51 |    80/  224 batches | lr 0.0625 | loss  4.10 | ppl    60.49\n","| epoch  51 |   100/  224 batches | lr 0.0625 | loss  4.10 | ppl    60.20\n","| epoch  51 |   120/  224 batches | lr 0.0625 | loss  4.14 | ppl    62.77\n","| epoch  51 |   140/  224 batches | lr 0.0625 | loss  4.13 | ppl    62.05\n","| epoch  51 |   160/  224 batches | lr 0.0625 | loss  4.16 | ppl    64.06\n","| epoch  51 |   180/  224 batches | lr 0.0625 | loss  4.13 | ppl    62.32\n","| epoch  51 |   200/  224 batches | lr 0.0625 | loss  4.09 | ppl    59.59\n","| epoch  51 |   220/  224 batches | lr 0.0625 | loss  4.11 | ppl    60.78\n","Epoch: 52 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.275 |  Val. PPL: 71.86\n","| epoch  52 |    20/  224 batches | lr 0.015625 | loss  4.33 | ppl    76.15\n","| epoch  52 |    40/  224 batches | lr 0.015625 | loss  4.09 | ppl    59.95\n","| epoch  52 |    60/  224 batches | lr 0.015625 | loss  4.14 | ppl    62.65\n","| epoch  52 |    80/  224 batches | lr 0.015625 | loss  4.11 | ppl    60.93\n","| epoch  52 |   100/  224 batches | lr 0.015625 | loss  4.10 | ppl    60.34\n","| epoch  52 |   120/  224 batches | lr 0.015625 | loss  4.15 | ppl    63.13\n","| epoch  52 |   140/  224 batches | lr 0.015625 | loss  4.13 | ppl    62.20\n","| epoch  52 |   160/  224 batches | lr 0.015625 | loss  4.16 | ppl    64.01\n","| epoch  52 |   180/  224 batches | lr 0.015625 | loss  4.13 | ppl    62.09\n","| epoch  52 |   200/  224 batches | lr 0.015625 | loss  4.08 | ppl    59.26\n","| epoch  52 |   220/  224 batches | lr 0.015625 | loss  4.11 | ppl    60.73\n","Epoch: 53 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.274 |  Val. PPL: 71.78\n","| epoch  53 |    20/  224 batches | lr 0.015625 | loss  4.33 | ppl    76.05\n","| epoch  53 |    40/  224 batches | lr 0.015625 | loss  4.09 | ppl    59.67\n","| epoch  53 |    60/  224 batches | lr 0.015625 | loss  4.14 | ppl    62.50\n","| epoch  53 |    80/  224 batches | lr 0.015625 | loss  4.11 | ppl    60.67\n","| epoch  53 |   100/  224 batches | lr 0.015625 | loss  4.10 | ppl    60.16\n","| epoch  53 |   120/  224 batches | lr 0.015625 | loss  4.14 | ppl    63.01\n","| epoch  53 |   140/  224 batches | lr 0.015625 | loss  4.13 | ppl    62.05\n","| epoch  53 |   160/  224 batches | lr 0.015625 | loss  4.16 | ppl    63.96\n","| epoch  53 |   180/  224 batches | lr 0.015625 | loss  4.13 | ppl    62.20\n","| epoch  53 |   200/  224 batches | lr 0.015625 | loss  4.08 | ppl    59.32\n","| epoch  53 |   220/  224 batches | lr 0.015625 | loss  4.11 | ppl    60.90\n","Epoch: 54 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.273 |  Val. PPL: 71.77\n","| epoch  54 |    20/  224 batches | lr 0.015625 | loss  4.33 | ppl    76.14\n","| epoch  54 |    40/  224 batches | lr 0.015625 | loss  4.09 | ppl    59.77\n","| epoch  54 |    60/  224 batches | lr 0.015625 | loss  4.13 | ppl    62.36\n","| epoch  54 |    80/  224 batches | lr 0.015625 | loss  4.10 | ppl    60.56\n","| epoch  54 |   100/  224 batches | lr 0.015625 | loss  4.10 | ppl    60.08\n","| epoch  54 |   120/  224 batches | lr 0.015625 | loss  4.14 | ppl    63.03\n","| epoch  54 |   140/  224 batches | lr 0.015625 | loss  4.13 | ppl    62.18\n","| epoch  54 |   160/  224 batches | lr 0.015625 | loss  4.16 | ppl    63.87\n","| epoch  54 |   180/  224 batches | lr 0.015625 | loss  4.13 | ppl    62.20\n","| epoch  54 |   200/  224 batches | lr 0.015625 | loss  4.08 | ppl    59.37\n","| epoch  54 |   220/  224 batches | lr 0.015625 | loss  4.11 | ppl    60.94\n","Epoch: 55 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.273 |  Val. PPL: 71.77\n","| epoch  55 |    20/  224 batches | lr 0.015625 | loss  4.33 | ppl    76.04\n","| epoch  55 |    40/  224 batches | lr 0.015625 | loss  4.09 | ppl    59.56\n","| epoch  55 |    60/  224 batches | lr 0.015625 | loss  4.14 | ppl    62.55\n","| epoch  55 |    80/  224 batches | lr 0.015625 | loss  4.11 | ppl    60.65\n","| epoch  55 |   100/  224 batches | lr 0.015625 | loss  4.10 | ppl    60.09\n","| epoch  55 |   120/  224 batches | lr 0.015625 | loss  4.14 | ppl    62.96\n","| epoch  55 |   140/  224 batches | lr 0.015625 | loss  4.13 | ppl    62.20\n","| epoch  55 |   160/  224 batches | lr 0.015625 | loss  4.16 | ppl    64.05\n","| epoch  55 |   180/  224 batches | lr 0.015625 | loss  4.13 | ppl    62.17\n","| epoch  55 |   200/  224 batches | lr 0.015625 | loss  4.08 | ppl    59.39\n","| epoch  55 |   220/  224 batches | lr 0.015625 | loss  4.11 | ppl    61.04\n","Epoch: 56 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.273 |  Val. PPL: 71.76\n","| epoch  56 |    20/  224 batches | lr 0.015625 | loss  4.33 | ppl    76.08\n","| epoch  56 |    40/  224 batches | lr 0.015625 | loss  4.09 | ppl    59.65\n","| epoch  56 |    60/  224 batches | lr 0.015625 | loss  4.13 | ppl    62.32\n","| epoch  56 |    80/  224 batches | lr 0.015625 | loss  4.10 | ppl    60.50\n","| epoch  56 |   100/  224 batches | lr 0.015625 | loss  4.09 | ppl    59.99\n","| epoch  56 |   120/  224 batches | lr 0.015625 | loss  4.14 | ppl    62.99\n","| epoch  56 |   140/  224 batches | lr 0.015625 | loss  4.13 | ppl    62.04\n","| epoch  56 |   160/  224 batches | lr 0.015625 | loss  4.16 | ppl    64.09\n","| epoch  56 |   180/  224 batches | lr 0.015625 | loss  4.13 | ppl    62.25\n","| epoch  56 |   200/  224 batches | lr 0.015625 | loss  4.08 | ppl    59.19\n","| epoch  56 |   220/  224 batches | lr 0.015625 | loss  4.11 | ppl    60.91\n","Epoch: 57 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.273 |  Val. PPL: 71.75\n","| epoch  57 |    20/  224 batches | lr 0.015625 | loss  4.33 | ppl    75.96\n","| epoch  57 |    40/  224 batches | lr 0.015625 | loss  4.09 | ppl    59.66\n","| epoch  57 |    60/  224 batches | lr 0.015625 | loss  4.13 | ppl    62.27\n","| epoch  57 |    80/  224 batches | lr 0.015625 | loss  4.10 | ppl    60.62\n","| epoch  57 |   100/  224 batches | lr 0.015625 | loss  4.09 | ppl    59.92\n","| epoch  57 |   120/  224 batches | lr 0.015625 | loss  4.14 | ppl    62.95\n","| epoch  57 |   140/  224 batches | lr 0.015625 | loss  4.13 | ppl    62.22\n","| epoch  57 |   160/  224 batches | lr 0.015625 | loss  4.16 | ppl    63.98\n","| epoch  57 |   180/  224 batches | lr 0.015625 | loss  4.13 | ppl    62.17\n","| epoch  57 |   200/  224 batches | lr 0.015625 | loss  4.08 | ppl    59.39\n","| epoch  57 |   220/  224 batches | lr 0.015625 | loss  4.11 | ppl    60.71\n","Epoch: 58 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.273 |  Val. PPL: 71.76\n","| epoch  58 |    20/  224 batches | lr 0.00390625 | loss  4.33 | ppl    76.00\n","| epoch  58 |    40/  224 batches | lr 0.00390625 | loss  4.09 | ppl    59.84\n","| epoch  58 |    60/  224 batches | lr 0.00390625 | loss  4.13 | ppl    62.38\n","| epoch  58 |    80/  224 batches | lr 0.00390625 | loss  4.10 | ppl    60.53\n","| epoch  58 |   100/  224 batches | lr 0.00390625 | loss  4.10 | ppl    60.10\n","| epoch  58 |   120/  224 batches | lr 0.00390625 | loss  4.14 | ppl    62.99\n","| epoch  58 |   140/  224 batches | lr 0.00390625 | loss  4.13 | ppl    62.09\n","| epoch  58 |   160/  224 batches | lr 0.00390625 | loss  4.15 | ppl    63.74\n","| epoch  58 |   180/  224 batches | lr 0.00390625 | loss  4.13 | ppl    62.17\n","| epoch  58 |   200/  224 batches | lr 0.00390625 | loss  4.08 | ppl    59.31\n","| epoch  58 |   220/  224 batches | lr 0.00390625 | loss  4.11 | ppl    60.88\n","Epoch: 59 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.273 |  Val. PPL: 71.76\n","| epoch  59 |    20/  224 batches | lr 0.0009765625 | loss  4.33 | ppl    76.05\n","| epoch  59 |    40/  224 batches | lr 0.0009765625 | loss  4.09 | ppl    59.77\n","| epoch  59 |    60/  224 batches | lr 0.0009765625 | loss  4.13 | ppl    62.40\n","| epoch  59 |    80/  224 batches | lr 0.0009765625 | loss  4.11 | ppl    60.65\n","| epoch  59 |   100/  224 batches | lr 0.0009765625 | loss  4.09 | ppl    60.02\n","| epoch  59 |   120/  224 batches | lr 0.0009765625 | loss  4.14 | ppl    62.88\n","| epoch  59 |   140/  224 batches | lr 0.0009765625 | loss  4.13 | ppl    62.06\n","| epoch  59 |   160/  224 batches | lr 0.0009765625 | loss  4.15 | ppl    63.71\n","| epoch  59 |   180/  224 batches | lr 0.0009765625 | loss  4.13 | ppl    62.00\n","| epoch  59 |   200/  224 batches | lr 0.0009765625 | loss  4.08 | ppl    59.21\n","| epoch  59 |   220/  224 batches | lr 0.0009765625 | loss  4.11 | ppl    60.74\n","Epoch: 60 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.273 |  Val. PPL: 71.76\n","| epoch  60 |    20/  224 batches | lr 0.000244140625 | loss  4.33 | ppl    75.96\n","| epoch  60 |    40/  224 batches | lr 0.000244140625 | loss  4.09 | ppl    59.85\n","| epoch  60 |    60/  224 batches | lr 0.000244140625 | loss  4.13 | ppl    62.45\n","| epoch  60 |    80/  224 batches | lr 0.000244140625 | loss  4.10 | ppl    60.52\n","| epoch  60 |   100/  224 batches | lr 0.000244140625 | loss  4.09 | ppl    60.02\n","| epoch  60 |   120/  224 batches | lr 0.000244140625 | loss  4.14 | ppl    62.80\n","| epoch  60 |   140/  224 batches | lr 0.000244140625 | loss  4.13 | ppl    62.00\n","| epoch  60 |   160/  224 batches | lr 0.000244140625 | loss  4.16 | ppl    63.81\n","| epoch  60 |   180/  224 batches | lr 0.000244140625 | loss  4.13 | ppl    62.06\n","| epoch  60 |   200/  224 batches | lr 0.000244140625 | loss  4.08 | ppl    59.24\n","| epoch  60 |   220/  224 batches | lr 0.000244140625 | loss  4.11 | ppl    60.79\n","Epoch: 61 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.273 |  Val. PPL: 71.76\n","| epoch  61 |    20/  224 batches | lr 6.103515625e-05 | loss  4.33 | ppl    76.18\n","| epoch  61 |    40/  224 batches | lr 6.103515625e-05 | loss  4.09 | ppl    59.63\n","| epoch  61 |    60/  224 batches | lr 6.103515625e-05 | loss  4.13 | ppl    62.37\n","| epoch  61 |    80/  224 batches | lr 6.103515625e-05 | loss  4.10 | ppl    60.64\n","| epoch  61 |   100/  224 batches | lr 6.103515625e-05 | loss  4.10 | ppl    60.08\n","| epoch  61 |   120/  224 batches | lr 6.103515625e-05 | loss  4.14 | ppl    62.90\n","| epoch  61 |   140/  224 batches | lr 6.103515625e-05 | loss  4.13 | ppl    62.05\n","| epoch  61 |   160/  224 batches | lr 6.103515625e-05 | loss  4.16 | ppl    63.84\n","| epoch  61 |   180/  224 batches | lr 6.103515625e-05 | loss  4.13 | ppl    62.01\n","| epoch  61 |   200/  224 batches | lr 6.103515625e-05 | loss  4.08 | ppl    59.27\n","| epoch  61 |   220/  224 batches | lr 6.103515625e-05 | loss  4.11 | ppl    60.68\n","Epoch: 62 | Epoch Time: 0m 41s\n","\t Val. Loss: 4.273 |  Val. PPL: 71.76\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6xX_LW6S8-Af","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593261153002,"user_tz":-120,"elapsed":3533,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"outputId":"fd5d3326-01fa-41e4-c258-872d602f40b1"},"source":["# Run on test data.\n","test_loss = evaluate(model, test_iter, criterion)\n","print('=' * 89)\n","print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n","    test_loss, math.exp(test_loss)))\n","print('=' * 89)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["=========================================================================================\n","| End of training | test loss  4.10 | test ppl    60.04\n","=========================================================================================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IQs3fGbadDrh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593261190136,"user_tz":-120,"elapsed":2028,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["import numpy as np\n","\n","\n","def inputTensor(line):\n","    word_indexes = [TEXT.vocab.stoi[k] for k in line.split()]\n","    return torch.tensor(word_indexes).unsqueeze(1).to(device)\n","\n","def generate(prime_str, predict_len = 20, temperature = 0.7):\n","    input = inputTensor(prime_str)\n","    words = prime_str.split()\n","\n","    with torch.no_grad():\n","      for i in range(predict_len):\n","          output, hid = model(input)\n","          word_weights = output[-1].squeeze().div(temperature).exp().cpu()\n","          word_idx = torch.multinomial(word_weights, 1)[0]\n","          word_tensor = torch.Tensor([[word_idx]]).long().to(device)\n","          input = torch.cat([input, word_tensor], 0)\n","          word = TEXT.vocab.itos[word_idx]\n","          words.append(word)\n","      return ' '.join(words), hid\n","\n","def greedy_search(prime_str, predict_len = 20):\n","    input = inputTensor(prime_str)\n","    words = prime_str.split()\n","\n","    with torch.no_grad():\n","      for i in range(predict_len):\n","          output = model(input)\n","          topv, top = output[-1].topk(1)\n","          word_idx = top.item()\n","          word_tensor = torch.Tensor([[word_idx]]).long().to(device)\n","          input = torch.cat([input, word_tensor], 0)\n","          word = TEXT.vocab.itos[word_idx]\n","          words.append(word)\n","      return ' '.join(words)\n","\n","\n","def random_choice(prime_str, top_k = 5, predict_len = 20):\n","    input = inputTensor(prime_str)\n","    words = prime_str.split()\n","\n","    with torch.no_grad():\n","      for i in range(predict_len):\n","          output = model(input)\n","          topv, top = output[-1].topk(top_k)\n","          choices = top.tolist()\n","          word_idx = np.random.choice(choices[0])\n","          word_tensor = torch.Tensor([[word_idx]]).long().to(device)\n","          input = torch.cat([input, word_tensor], 0)\n","          word = TEXT.vocab.itos[word_idx]\n","          words.append(word)\n","      return ' '.join(words)\n","\n","\n"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"pJbG1xWmdqKq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593261192316,"user_tz":-120,"elapsed":1816,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["input_str = 'hello my name is'"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"AxXEByolcwUj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593261931020,"user_tz":-120,"elapsed":1635,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["o,h=generate(input_str, temperature=0.1)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"aytLD1tuz8R2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593261942316,"user_tz":-120,"elapsed":1348,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"outputId":"ac718bb1-de62-4345-c38b-b024fec37448"},"source":["o"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'hello my name is a < unk > , and the < unk > of the < unk > of the < unk >'"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"djzsM3rLz9RC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593261952489,"user_tz":-120,"elapsed":974,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"outputId":"6df6ca90-a3ac-46ba-f8ed-a1fd819582b4"},"source":["h.shape"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([23, 1, 128])"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"9L_ZN_KMdXbb","colab_type":"code","colab":{}},"source":["greedy_search(input_str)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BJAhPrTzfkaI","colab_type":"code","colab":{}},"source":["random_choice(input_str)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ltPqS2tkgIVx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593262645994,"user_tz":-120,"elapsed":901,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["a = 'hello'\n","b = 'hi'"],"execution_count":146,"outputs":[]},{"cell_type":"code","metadata":{"id":"BUvKq1TP0aPH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593262645995,"user_tz":-120,"elapsed":631,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["a_t = inputTensor(a)\n","b_t = inputTensor(b)"],"execution_count":147,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mk-Cr2Vh0csL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593262647426,"user_tz":-120,"elapsed":1808,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["_,h1 = model(a_t)\n","_,h2 = model(b_t)"],"execution_count":148,"outputs":[]},{"cell_type":"code","metadata":{"id":"zypdWsoO0geS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593262647428,"user_tz":-120,"elapsed":1528,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"outputId":"fff08c6b-9371-4fa7-a196-2be7c81184a4"},"source":["h1.shape, h2.shape"],"execution_count":149,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1, 1, 128]), torch.Size([1, 1, 128]))"]},"metadata":{"tags":[]},"execution_count":149}]},{"cell_type":"code","metadata":{"id":"0clSPRtK0ois","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593262647429,"user_tz":-120,"elapsed":1266,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["h1 = h1.mean(dim=0) \n","h2 = h2.mean(dim=0)"],"execution_count":150,"outputs":[]},{"cell_type":"code","metadata":{"id":"a7bov1UR1k4q","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593262647430,"user_tz":-120,"elapsed":987,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["h1 = h1.squeeze()\n","h2 = h2.squeeze()"],"execution_count":151,"outputs":[]},{"cell_type":"code","metadata":{"id":"6dkRcH_C04wP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593262647432,"user_tz":-120,"elapsed":624,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["h1 = h1.detach().cpu().numpy()\n","h2 = h2.detach().cpu().numpy()"],"execution_count":152,"outputs":[]},{"cell_type":"code","metadata":{"id":"qO5m6GGK1SyJ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593262648957,"user_tz":-120,"elapsed":1638,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}}},"source":["import numpy as np"],"execution_count":153,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3ji9vxT1hEd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593262648959,"user_tz":-120,"elapsed":998,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"outputId":"ff592db6-ad9d-4949-8ff8-efec52d013b8"},"source":["np.dot(h1,h2)/(np.linalg.norm(h1)*np.linalg.norm(h2))"],"execution_count":154,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.35752913"]},"metadata":{"tags":[]},"execution_count":154}]},{"cell_type":"code","metadata":{"id":"BQtW1gYc1iK3","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}