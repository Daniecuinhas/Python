{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_L_QpVIGlRZc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# read data from text files\n",
    "with open('data/reviews_sample.txt', 'r') as f:\n",
    "    reviews = f.read()\n",
    "with open('data/labels_sample.txt', 'r') as f:\n",
    "    labels = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RYypyzcLlWpR"
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "# get rid of punctuation\n",
    "reviews = reviews.lower() # lowercase, standardize\n",
    "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
    "\n",
    "# split by new lines and spaces\n",
    "reviews_split = all_text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J4aCMAG7mcAc"
   },
   "outputs": [],
   "source": [
    "reviews_split=reviews_split[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ym2G2nPxmdd7"
   },
   "outputs": [],
   "source": [
    "# 1=positive, 0=negative label conversion\n",
    "labels_split = labels.split('\\n')\n",
    "labels_split=labels_split[:-1]\n",
    "encoded_labels_ = np.array([1 if label == 'positive' else 0 for label in labels_split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e3Z9OYxgmfDB"
   },
   "outputs": [],
   "source": [
    "encoded_labels= np.zeros((encoded_labels_.size, encoded_labels_.max()+1))\n",
    "encoded_labels[np.arange(encoded_labels_.size),encoded_labels_] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VYM4_Xcemg3d"
   },
   "outputs": [],
   "source": [
    "nb_labels=encoded_labels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7985,
     "status": "ok",
     "timestamp": 1575487844285,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "q42VTT1Smid8",
    "outputId": "6dac2f15-a7d5-424c-eeba-ea8921d5e915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.2.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.11.1)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.35)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.27)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.83)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.27 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.27)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.27->boto3->transformers) (2.6.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.27->boto3->transformers) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11998,
     "status": "ok",
     "timestamp": 1575487848328,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "9BKkjM1JmkX9",
    "outputId": "25fc0625-161b-4da0-aa39-ca4d197abff9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertModel, AdamW\n",
    "\n",
    "\n",
    "\n",
    "BERT_MODEL='distilbert-base-uncased'\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(BERT_MODEL)\n",
    "bert = DistilBertModel.from_pretrained(BERT_MODEL, num_labels=nb_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11960,
     "status": "ok",
     "timestamp": 1575487848330,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "pQPgK2lrmxdB",
    "outputId": "08a8593a-c974-4120-fa08-3afdfadf4e4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [SEP] [PAD] [UNK]\n"
     ]
    }
   ],
   "source": [
    "init_token = tokenizer.cls_token\n",
    "eos_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "print(init_token, eos_token, pad_token, unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11931,
     "status": "ok",
     "timestamp": 1575487848331,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "KFwNZfcjm6E7",
    "outputId": "57d30f2f-2544-4aa0-dbbd-76c3dbab8116"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 102 0 100\n"
     ]
    }
   ],
   "source": [
    "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
    "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11893,
     "status": "ok",
     "timestamp": 1575487848331,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "FWDz3boxm7_W",
    "outputId": "0bb4c5c9-8ea0-4f85-9207-6834016c78a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes[BERT_MODEL]\n",
    "\n",
    "print(max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qvg3G7qJm9uo"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_cut(sentence):\n",
    "    tokens=\"[CLS] \"+sentence+\" [SEP]\"\n",
    "    tokens = tokenizer.tokenize(tokens) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens\n",
    "\n",
    "def pad_features(reviews_ints, seq_length):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's \n",
    "        or truncated to the input seq_length.\n",
    "    '''\n",
    "    \n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
    "\n",
    "    # for each review, I grab that review and \n",
    "    for i, row in enumerate(reviews_ints):\n",
    "        features[i, :len(row)] = np.array(row)[:seq_length]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Qwd_u8Bm_7i"
   },
   "outputs": [],
   "source": [
    "tokenized_texts = [tokenize_and_cut(sent) for sent in reviews_split]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xe6I65_4nEyU"
   },
   "outputs": [],
   "source": [
    "input_ids=[tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OP98bcUgnJk5"
   },
   "outputs": [],
   "source": [
    "max_len=200\n",
    "\n",
    "input_ids=pad_features(input_ids, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S85rt2jxnRXA"
   },
   "outputs": [],
   "source": [
    "attention_masks = [[float(i>0) for i in ii] for ii in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 113182,
     "status": "ok",
     "timestamp": 1575487949715,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "10Ff8DMInTlI",
    "outputId": "866c5719-ec56-4f75-f1bc-38dfa13dc410"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000, 25000)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_labels), len(input_ids), len(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 113169,
     "status": "ok",
     "timestamp": 1575487949716,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "9aiOKzKfVp9m",
    "outputId": "0b978791-2410-4dce-f2cc-a61b49f9d7d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(20000, 200) \n",
      "Validation set: \t(2500, 200) \n",
      "Test set: \t\t(2500, 200)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "\n",
    "split_idx = int(len(input_ids)*split_frac)\n",
    "tr_inputs, remaining_inputs = input_ids[:split_idx], input_ids[split_idx:]\n",
    "tr_tags, remaining_tags = encoded_labels_[:split_idx], encoded_labels_[split_idx:]\n",
    "tr_masks, remaining_masks = attention_masks[:split_idx], attention_masks[split_idx:]\n",
    "\n",
    "test_idx = int(len(remaining_inputs)*0.5)\n",
    "val_inputs, test_inputs = remaining_inputs[:test_idx], remaining_inputs[test_idx:]\n",
    "val_tags, test_tags = remaining_tags[:test_idx], remaining_tags[test_idx:]\n",
    "val_masks, test_masks = remaining_masks[:test_idx], remaining_masks[test_idx:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(tr_inputs.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_inputs.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_inputs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qwF4d2renYnF"
   },
   "outputs": [],
   "source": [
    "tr_inputs = torch.tensor(tr_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "test_inputs=torch.tensor(test_inputs)\n",
    "\n",
    "tr_tags = torch.tensor(tr_tags)\n",
    "val_tags = torch.tensor(val_tags)\n",
    "test_tags=torch.tensor(test_tags)\n",
    "\n",
    "tr_masks = torch.tensor(tr_masks)\n",
    "val_masks = torch.tensor(val_masks)\n",
    "test_masks=torch.tensor(test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErBWBonHnaWn"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TWd0iYnPnb46"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_tags)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cnBjafWhndb3"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BERTGRUSentiment(nn.Module):\n",
    "    def __init__(self, bert, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        embedding_dim = bert.config.to_dict()['dim']\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers = n_layers, bidirectional = bidirectional,batch_first = True, dropout = 0 if n_layers < 2 else dropout)\n",
    "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text, mask):\n",
    "        text = text.long() #text = [batch size, sent len]\n",
    "      \n",
    "        with torch.no_grad():\n",
    "            embedded = bert(text, mask)[0] #embedded = [batch size, sent len, emb dim]\n",
    "      \n",
    "        _, hidden = self.rnn(embedded) #hidden = [n layers * n directions, batch size, emb dim]\n",
    "      \n",
    "        if self.rnn.bidirectional:\n",
    "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)) #hidden = [batch size, hid dim]\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1,:,:]) #hidden = [batch size, hid dim]\n",
    "  \n",
    "        output = self.out(hidden) #output = [batch size, out dim]\n",
    "                        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3R1---pdnn6V"
   },
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 1\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "\n",
    "model = BERTGRUSentiment(bert,\n",
    "                         HIDDEN_DIM,\n",
    "                         OUTPUT_DIM,\n",
    "                         N_LAYERS,\n",
    "                         BIDIRECTIONAL,\n",
    "                         DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 113056,
     "status": "ok",
     "timestamp": 1575487949723,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "xVr2tjN_np9t",
    "outputId": "1807b4b3-e3a9-447c-bbdc-377351b15149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 67,939,329 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AmuHvGZxnwRY"
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if name.startswith('bert'):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 113493,
     "status": "ok",
     "timestamp": 1575487950189,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "e0vP7eu5nyJS",
    "outputId": "e26eece8-1af9-4644-928f-5ccbb414fb3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,576,449 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 113477,
     "status": "ok",
     "timestamp": 1575487950190,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "Z9Otiolxnztq",
    "outputId": "b62b8930-4ac5-4a3a-cd91-e1ea8791a7bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn.weight_ih_l0\n",
      "rnn.weight_hh_l0\n",
      "rnn.bias_ih_l0\n",
      "rnn.bias_hh_l0\n",
      "rnn.weight_ih_l0_reverse\n",
      "rnn.weight_hh_l0_reverse\n",
      "rnn.bias_ih_l0_reverse\n",
      "rnn.bias_hh_l0_reverse\n",
      "out.weight\n",
      "out.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nf-s49rBn1qt"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "215MVHrIn4Ae"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 116451,
     "status": "ok",
     "timestamp": 1575487953212,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "gviNIa3dn5ju",
    "outputId": "f3a8f955-ae79-4b0f-fcf5-b4ecd4c54b5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H_RmNVS8n7IZ"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sGNk9tX-oFX2"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for text, masks, labs in iterator:\n",
    "        text=text.cuda()\n",
    "        masks=masks.cuda()\n",
    "        labs=labs.cuda()\n",
    "        labs=labs.float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(text, masks).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, labs)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, labs)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3SXW8ivooIJe"
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      \n",
    "        for text, masks, labs in iterator:\n",
    "            text=text.cuda()\n",
    "            masks=masks.cuda()\n",
    "            labs=labs.cuda()\n",
    "            labs=labs.float()\n",
    "\n",
    "            predictions = model(text, masks).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, labs)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, labs)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJhtcZ0JoKDl"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1414014,
     "status": "ok",
     "timestamp": 1575489250869,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "5RJj5C4moL3z",
    "outputId": "a8640c17-2c9f-4f4e-b919-6ec1ac56915c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.653 | Train Acc: 64.17%\n",
      "\t Val. Loss: 0.600 |  Val. Acc: 76.17%\n",
      "Epoch: 02 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.520 | Train Acc: 76.71%\n",
      "\t Val. Loss: 0.451 |  Val. Acc: 80.00%\n",
      "Epoch: 03 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.426 | Train Acc: 80.92%\n",
      "\t Val. Loss: 0.409 |  Val. Acc: 82.89%\n",
      "Epoch: 04 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.403 | Train Acc: 81.98%\n",
      "\t Val. Loss: 0.392 |  Val. Acc: 83.59%\n",
      "Epoch: 05 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 0.391 | Train Acc: 82.90%\n",
      "\t Val. Loss: 0.385 |  Val. Acc: 83.55%\n",
      "Epoch: 06 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 0.384 | Train Acc: 83.11%\n",
      "\t Val. Loss: 0.376 |  Val. Acc: 84.10%\n",
      "Epoch: 07 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 0.373 | Train Acc: 83.67%\n",
      "\t Val. Loss: 0.365 |  Val. Acc: 84.65%\n",
      "Epoch: 08 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 0.367 | Train Acc: 83.74%\n",
      "\t Val. Loss: 0.367 |  Val. Acc: 84.10%\n",
      "Epoch: 09 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 0.363 | Train Acc: 84.17%\n",
      "\t Val. Loss: 0.357 |  Val. Acc: 84.92%\n",
      "Epoch: 10 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 0.355 | Train Acc: 84.73%\n",
      "\t Val. Loss: 0.356 |  Val. Acc: 85.12%\n",
      "Epoch: 11 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 0.350 | Train Acc: 84.92%\n",
      "\t Val. Loss: 0.352 |  Val. Acc: 85.16%\n",
      "Epoch: 12 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 0.347 | Train Acc: 85.26%\n",
      "\t Val. Loss: 0.350 |  Val. Acc: 85.08%\n",
      "Epoch: 13 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 0.341 | Train Acc: 85.25%\n",
      "\t Val. Loss: 0.348 |  Val. Acc: 85.20%\n",
      "Epoch: 14 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 0.339 | Train Acc: 85.59%\n",
      "\t Val. Loss: 0.345 |  Val. Acc: 85.12%\n",
      "Epoch: 15 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 0.336 | Train Acc: 85.54%\n",
      "\t Val. Loss: 0.370 |  Val. Acc: 83.75%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 15\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_dataloader, criterion)\n",
    "        \n",
    "    end_time = time.time()\n",
    "        \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut6-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1422544,
     "status": "ok",
     "timestamp": 1575489259417,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "QzJLV5fvoOUy",
    "outputId": "dbb25681-5bb4-4781-864b-b1d458c5b268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.380 | Test Acc: 83.24%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_dataloader,criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JnGrXNB4ba1H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "BERT+GRU.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
