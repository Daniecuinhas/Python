{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BiLSTM.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6uGcFMHdygzJ","colab_type":"code","outputId":"6c1fe8cf-0431-44a7-ae63-d7a7b68df562","executionInfo":{"status":"ok","timestamp":1584286273810,"user_tz":-60,"elapsed":1141,"user":{"displayName":"Daniel Cui침as V치zquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3LUbeh_oyht8","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","# read data from text files\n","with open('/content/drive/My Drive/Colab Notebooks/Sentiment/data/reviews.txt', 'r') as f:\n","    reviews = f.read()\n","with open('/content/drive/My Drive/Colab Notebooks/Sentiment/data/labels.txt', 'r') as f:\n","    labels = f.read()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NIf5mfrUyv9I","colab_type":"code","colab":{}},"source":["from string import punctuation\n","\n","# get rid of punctuation\n","reviews = reviews.lower() # lowercase, standardize\n","all_text = ''.join([c for c in reviews if c not in punctuation])\n","\n","# split by new lines and spaces\n","reviews_split = all_text.split('\\n')\n","all_text = ' '.join(reviews_split)\n","\n","# create a list of words\n","words = all_text.split()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"90rVa-FnyzeL","colab_type":"code","colab":{}},"source":["# feel free to use this import \n","from collections import Counter\n","\n","## Build a dictionary that maps words to integers\n","counts = Counter(words)\n","vocab = sorted(counts, key=counts.get, reverse=True)\n","vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n","vocab_to_int['<pad>']=0\n","\n","int2vocab={i:w for w,i in vocab_to_int.items()}\n","\n","## use the dict to tokenize each review in reviews_split\n","## store the tokenized reviews in reviews_ints\n","reviews_ints = []\n","for review in reviews_split:\n","    reviews_ints.append([vocab_to_int[word] for word in review.split()])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sF_uzxqty1xG","colab_type":"code","colab":{}},"source":["# 1=positive, 0=negative label conversion\n","labels_split = labels.split('\\n')\n","encoded_labels = np.array([1 if label == 'positive' else 0 for label in labels_split])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yl2LjYC0zMPd","colab_type":"code","colab":{}},"source":["non_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n","\n","# remove 0-length reviews and their labels\n","reviews_ints = [reviews_ints[ii] for ii in non_zero_idx]\n","encoded_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])\n","lens=list(map(len, reviews_ints))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nB7T2fCZzOR1","colab_type":"code","colab":{}},"source":["def pad_features(reviews_ints, seq_length):\n","    ''' Return features of review_ints, where each review is padded with 0's \n","        or truncated to the input seq_length.\n","    '''\n","    \n","    # getting the correct rows x cols shape\n","    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n","\n","    # for each review, I grab that review and \n","    for i, row in enumerate(reviews_ints):\n","        features[i, :len(row)] = np.array(row)[:seq_length]\n","    \n","    return features"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wdUC-0SX83sC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9bQOxxgizPvj","colab_type":"code","colab":{}},"source":["\n","seq_length = 200\n","seq_length = max(lens)\n","# seq_length = int(np.percentile(lens,95))\n","\n","features = pad_features(reviews_ints,seq_length)\n","\n","review_lengths = np.sum(features!=0,axis=1)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Be6Bjn5ErwJi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M6iWtMNGzRT9","colab_type":"code","outputId":"f87e9409-d234-4105-a6cf-777efb122545","executionInfo":{"status":"ok","timestamp":1584286281211,"user_tz":-60,"elapsed":5530,"user":{"displayName":"Daniel Cui침as V치zquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["split_frac = 0.8\n","\n","## split data into training, validation, and test data (features and labels, x and y)\n","\n","split_idx = int(len(features)*split_frac)\n","train_x, remaining_x = features[:split_idx], features[split_idx:]\n","train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n","train_length, remaining_length=review_lengths[:split_idx], review_lengths[split_idx:]\n","\n","test_idx = int(len(remaining_x)*0.5)\n","val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n","val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n","val_legth, test_length = remaining_length[:test_idx], remaining_length[test_idx:]\n","\n","## print out the shapes of your resultant feature data\n","print(\"\\t\\t\\tFeature Shapes:\")\n","print(\"Train set: \\t\\t{}\".format(train_x.shape), \n","      \"\\nValidation set: \\t{}\".format(val_x.shape),\n","      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["\t\t\tFeature Shapes:\n","Train set: \t\t(20000, 2514) \n","Validation set: \t(2500, 2514) \n","Test set: \t\t(2500, 2514)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"01o7eJnOzTZL","colab_type":"code","colab":{}},"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_length), torch.from_numpy(train_y))\n","valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_legth), torch.from_numpy(val_y))\n","test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_length), torch.from_numpy(test_y))\n","\n","# dataloaders\n","BATCH_SIZE = 64\n","\n","# make sure the SHUFFLE your training data\n","train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)\n","valid_loader = DataLoader(valid_data, shuffle=True, batch_size=BATCH_SIZE)\n","test_loader = DataLoader(test_data, shuffle=True, batch_size=BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fDhw-FOMI0d8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pdQk07oFI0tu","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XVxFcYd5zVCy","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","\n","\n","class LSTM(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n","        super(LSTM, self).__init__()\n","  \n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout = 0 if n_layers < 2 else dropout)\n","        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","\n","    def forward(self, text, text_lengths):\n","\n","        text=text.long() # ojo con esto\n","        text=text.transpose(1,0) # ojo con esto too\n","        text_lengths = text_lengths.long()\n","\n","        embedded = self.dropout(self.embedding(text))\n","        \n","        #embedded = [sent len, batch size, emb dim]\n","        \n","        #pack sequence\n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, enforce_sorted=False)\n","        \n","        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n","        \n","        #unpack sequence\n","        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n","\n","        #output = [sent len, batch size, hid dim * num directions]\n","        #output over padding tokens are zero tensors\n","        \n","        #hidden = [num layers * num directions, batch size, hid dim]\n","        #cell = [num layers * num directions, batch size, hid dim]\n","        \n","        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n","        #and apply dropout\n","        if self.rnn.bidirectional:\n","            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n","        else:\n","            hidden = self.dropout(hidden[-1,:,:])\n","                            \n","        #hidden = [batch size, hid dim * num directions]\n","            \n","        return self.fc(hidden)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5xysY5Yr7Srm","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"soozatXEzWt8","colab_type":"code","colab":{}},"source":["INPUT_DIM = len(vocab_to_int)\n","EMBEDDING_DIM = 100\n","HIDDEN_DIM = 256\n","OUTPUT_DIM = 1\n","N_LAYERS = 1\n","BIDIRECTIONAL = True\n","DROPOUT = 0.5\n","# PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","model = LSTM(INPUT_DIM, \n","            EMBEDDING_DIM, \n","            HIDDEN_DIM, \n","            OUTPUT_DIM, \n","            N_LAYERS, \n","            BIDIRECTIONAL, \n","            DROPOUT)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"onuSSAJUzYsT","colab_type":"code","outputId":"a1644b41-04d1-4978-bec5-4e50b9e7e362","executionInfo":{"status":"ok","timestamp":1584286281215,"user_tz":-60,"elapsed":2931,"user":{"displayName":"Daniel Cui침as V치zquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":13,"outputs":[{"output_type":"stream","text":["The model has 8,140,997 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gS9EjsPpzaTD","colab_type":"code","colab":{}},"source":["import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eivApCX-zd0X","colab_type":"code","outputId":"b821e439-d7af-400e-bcb0-16b761591f1c","executionInfo":{"status":"ok","timestamp":1584286281630,"user_tz":-60,"elapsed":2755,"user":{"displayName":"Daniel Cui침as V치zquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"zAnKfxIJzfPr","colab_type":"code","colab":{}},"source":["criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0oef4fSzziwP","colab_type":"code","colab":{}},"source":["def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division \n","    acc = correct.sum() / len(correct)\n","    return acc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fykMKmVCzkQ4","colab_type":"code","colab":{}},"source":["def train(model, iterator, optimizer, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.train()\n","    \n","    for text, text_lengths, label in iterator:\n","        text, text_lengths, label=text.cuda(), text_lengths.cuda(), label.cuda()\n","\n","        optimizer.zero_grad()\n","      \n","        predictions = model(text, text_lengths).squeeze(1)\n","        \n","        loss = criterion(predictions, label.float())\n","        \n","        acc = binary_accuracy(predictions, label.float())\n","        \n","        loss.backward()\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ggds3tiCzlxc","colab_type":"code","colab":{}},"source":["def evaluate(model, iterator, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.eval()\n","    \n","    with torch.no_grad():\n","    \n","        for text, text_lengths, label in iterator:\n","            text, text_lengths, label=text.cuda(), text_lengths.cuda(), label.cuda()\n","            \n","            predictions = model(text, text_lengths).squeeze(1)\n","            \n","            loss = criterion(predictions, label.float())\n","            \n","            acc = binary_accuracy(predictions, label.float())\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"171W_VNzzndk","colab_type":"code","colab":{}},"source":["import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RqUidEJXzo8e","colab_type":"code","outputId":"f298bb04-3c8b-458e-e8e1-86b892776f3b","executionInfo":{"status":"ok","timestamp":1584286866926,"user_tz":-60,"elapsed":586155,"user":{"displayName":"Daniel Cui침as V치zquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":527}},"source":["N_EPOCHS = 10\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","    \n","    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_loader, criterion)\n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'tut2-model.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Epoch Time: 0m 58s\n","\tTrain Loss: 0.656 | Train Acc: 60.17%\n","\t Val. Loss: 0.558 |  Val. Acc: 72.34%\n","Epoch: 02 | Epoch Time: 0m 59s\n","\tTrain Loss: 0.582 | Train Acc: 69.33%\n","\t Val. Loss: 0.556 |  Val. Acc: 72.93%\n","Epoch: 03 | Epoch Time: 1m 0s\n","\tTrain Loss: 0.551 | Train Acc: 71.84%\n","\t Val. Loss: 0.613 |  Val. Acc: 67.46%\n","Epoch: 04 | Epoch Time: 0m 55s\n","\tTrain Loss: 0.522 | Train Acc: 73.86%\n","\t Val. Loss: 0.508 |  Val. Acc: 74.26%\n","Epoch: 05 | Epoch Time: 0m 54s\n","\tTrain Loss: 0.506 | Train Acc: 75.48%\n","\t Val. Loss: 0.522 |  Val. Acc: 74.92%\n","Epoch: 06 | Epoch Time: 0m 59s\n","\tTrain Loss: 0.397 | Train Acc: 82.19%\n","\t Val. Loss: 0.767 |  Val. Acc: 68.79%\n","Epoch: 07 | Epoch Time: 0m 55s\n","\tTrain Loss: 0.361 | Train Acc: 84.27%\n","\t Val. Loss: 0.357 |  Val. Acc: 85.74%\n","Epoch: 08 | Epoch Time: 1m 0s\n","\tTrain Loss: 0.310 | Train Acc: 87.02%\n","\t Val. Loss: 0.349 |  Val. Acc: 85.51%\n","Epoch: 09 | Epoch Time: 0m 59s\n","\tTrain Loss: 0.277 | Train Acc: 88.58%\n","\t Val. Loss: 0.331 |  Val. Acc: 86.29%\n","Epoch: 10 | Epoch Time: 0m 59s\n","\tTrain Loss: 0.248 | Train Acc: 90.05%\n","\t Val. Loss: 0.339 |  Val. Acc: 86.41%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5jcfxMbhztOS","colab_type":"code","outputId":"2d19bbf8-bf00-4b9b-a52b-4e6be9598acd","executionInfo":{"status":"ok","timestamp":1584286869895,"user_tz":-60,"elapsed":588778,"user":{"displayName":"Daniel Cui침as V치zquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# model.load_state_dict(torch.load('tut2-model.pt'))\n","\n","test_loss, test_acc = evaluate(model, test_loader, criterion)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Test Loss: 0.368 | Test Acc: 83.91%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E7HqnuDS2cv5","colab_type":"code","colab":{}},"source":["def predict_sentiment(model, sentence):\n","    model.eval()\n","    tokenized = [tok for tok in sentence.split()]\n","    indexed = [vocab_to_int[t] for t in tokenized]\n","    length = [len(indexed)]\n","    tensor = torch.LongTensor(indexed).to(device)\n","    tensor = tensor.unsqueeze(1)\n","    tensor=tensor.reshape(1,-1)\n","    length_tensor = torch.LongTensor(length)\n","    pred = model(tensor)\n","    prediction = torch.sigmoid(pred)\n","    return prediction.item()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dRCqqx0L2uB7","colab_type":"code","outputId":"46bd5ff2-e719-4fef-ec3c-8d7c5196658e","executionInfo":{"status":"error","timestamp":1584286869900,"user_tz":-60,"elapsed":588185,"user":{"displayName":"Daniel Cui침as V치zquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["predict_sentiment(model, \"this film is terrible\")\n"],"execution_count":24,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-0bb95957f4fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"this film is terrible\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-23-5d2618d665fa>\u001b[0m in \u001b[0;36mpredict_sentiment\u001b[0;34m(model, sentence)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlength_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'text_lengths'"]}]},{"cell_type":"code","metadata":{"id":"cXcy5gKE2vZQ","colab_type":"code","colab":{}},"source":["\n","predict_sentiment(model, \"this film is great\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FKHkDLdq3t_W","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}