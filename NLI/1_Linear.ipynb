{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Linear.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMZJ+T5S/yZ7JYkZvfo3aog"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"lCcZ_7ZNu3j7","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torchtext import data\n","from torchtext import datasets\n","\n","import random\n","import numpy as np\n","\n","import time\n","\n","\n","SEED = 1234\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","TEXT = data.Field(tokenize = 'spacy', lower = True)\n","LABEL = data.LabelField()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hSVPejKNvBS3","colab_type":"code","colab":{}},"source":["train_data, valid_data, test_data = datasets.SNLI.splits(TEXT, LABEL)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"napqNhbhvIcP","colab_type":"code","outputId":"8663f624-673f-4c6e-fa53-8e3ce87c9e72","executionInfo":{"status":"ok","timestamp":1579440855616,"user_tz":-60,"elapsed":293499,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["print(f\"Number of training examples: {len(train_data)}\")\n","print(f\"Number of validation examples: {len(valid_data)}\")\n","print(f\"Number of testing examples: {len(test_data)}\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Number of training examples: 549367\n","Number of validation examples: 9842\n","Number of testing examples: 9824\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vbWm-DCWwd6p","colab_type":"code","outputId":"a2d18ab2-1c94-4cda-eaf0-9203a804aaf8","executionInfo":{"status":"ok","timestamp":1579440855617,"user_tz":-60,"elapsed":293479,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["print(vars(train_data.examples[0]))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{'premise': ['a', 'person', 'on', 'a', 'horse', 'jumps', 'over', 'a', 'broken', 'down', 'airplane', '.'], 'hypothesis': ['a', 'person', 'is', 'training', 'his', 'horse', 'for', 'a', 'competition', '.'], 'label': 'neutral'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pgp12J_ywhOu","colab_type":"code","colab":{}},"source":["MIN_FREQ = 2\n","\n","TEXT.build_vocab(train_data, \n","                 min_freq = MIN_FREQ,\n","                 vectors = \"glove.6B.300d\",\n","                 unk_init = torch.Tensor.normal_)\n","\n","LABEL.build_vocab(train_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9FFd69DJwk-2","colab_type":"code","outputId":"8a7c58c1-c860-4d05-90dd-bd626a237493","executionInfo":{"status":"ok","timestamp":1579440861374,"user_tz":-60,"elapsed":299199,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Unique tokens in TEXT vocabulary: 23566\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5xWvEOAVzAyy","colab_type":"code","outputId":"6fe01be8-3874-44c0-fc33-2546f8fa12ec","executionInfo":{"status":"ok","timestamp":1579440861375,"user_tz":-60,"elapsed":299186,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["print(TEXT.vocab.freqs.most_common(20))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[('a', 1438991), ('.', 962558), ('the', 534692), ('in', 407296), ('is', 373543), ('man', 266236), ('on', 235904), ('and', 206363), ('are', 199114), ('of', 192428), ('with', 169236), ('woman', 137630), ('two', 122259), ('people', 121154), (',', 114331), ('to', 113972), ('at', 98656), ('wearing', 81024), ('an', 80212), ('his', 72467)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yP5ygU2zzDqd","colab_type":"code","outputId":"6ab9c9bc-750b-4ff8-e420-f8204bcde24f","executionInfo":{"status":"ok","timestamp":1579440861376,"user_tz":-60,"elapsed":299167,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(TEXT.vocab.itos[:10])\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['<unk>', '<pad>', 'a', '.', 'the', 'in', 'is', 'man', 'on', 'and']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u5H5IF0azFou","colab_type":"code","outputId":"092006ac-15cd-444d-bcb3-5483e807fa4d","executionInfo":{"status":"ok","timestamp":1579440861377,"user_tz":-60,"elapsed":299151,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(LABEL.vocab.itos)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['entailment', 'contradiction', 'neutral']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l0lOQ85KzHrs","colab_type":"code","outputId":"8484289c-d3c2-4977-a4e0-0339da344e46","executionInfo":{"status":"ok","timestamp":1579440861378,"user_tz":-60,"elapsed":299137,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(LABEL.vocab.freqs.most_common())\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[('entailment', 183416), ('contradiction', 183187), ('neutral', 182764)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r3xNSX6GzJ3w","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 512\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","    batch_size = BATCH_SIZE,\n","    device = device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vakr__zezMfX","colab_type":"code","colab":{}},"source":["class NLISum(nn.Module):\n","    def __init__(self, \n","                 vocab_size, \n","                 embedding_dim,\n","                 hidden_dim,\n","                 fc_layers,\n","                 output_dim, \n","                 dropout, \n","                 pad_idx):\n","        \n","        super().__init__()\n","        \n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n","        \n","        self.translation = nn.Linear(embedding_dim, hidden_dim)\n","        \n","        fcs = [nn.Linear(hidden_dim * 2, hidden_dim * 2) for _ in range(fc_layers)]\n","        \n","        self.fcs = nn.ModuleList(fcs)\n","        \n","        self.fc_out = nn.Linear(hidden_dim * 2, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, prem, hypo):\n","\n","        #prem = [prem sent len, batch size]\n","        #hypo = [hypo sent len, batch size]\n","        \n","        embedded_prem = self.embedding(prem)\n","        embedded_hypo = self.embedding(hypo)\n","        \n","        #embedded_prem = [prem sent len, batch size, embedding dim]\n","        #embedded_hypo = [hypo sent len, batch size, embedding dim]\n","        \n","        translated_prem = F.relu(self.translation(embedded_prem))\n","        translated_hypo = F.relu(self.translation(embedded_hypo))\n","        \n","        #translated_prem = [prem sent len, batch size, hidden dim]\n","        #translated_hypo = [hypo sent len, batch size, hidden dim]\n","        \n","        hidden_prem = translated_prem.sum(dim = 0)\n","        hidden_hypo = translated_hypo.sum(dim = 0)\n","            \n","        #hidden_x = [batch size, hid dim]\n","        \n","        hidden = torch.cat((hidden_prem, hidden_hypo), dim = 1)\n","\n","        #hidden = [batch size, hid dim * 2]\n","            \n","        for fc in self.fcs:\n","            hidden = fc(hidden)\n","            hidden = F.relu(hidden)\n","            hidden = self.dropout(hidden)\n","        \n","        prediction = self.fc_out(hidden)\n","        \n","        #prediction = [batch size, output dim]\n","        \n","        return prediction\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Qb0LHCdzPGJ","colab_type":"code","colab":{}},"source":["INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 300\n","HIDDEN_DIM = 300\n","FC_LAYERS = 3\n","OUTPUT_DIM = len(LABEL.vocab)\n","DROPOUT = 0.25\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","MODEL='gru'\n","\n","if MODEL=='linear':\n","  model = NLISum(INPUT_DIM,\n","               EMBEDDING_DIM,\n","               HIDDEN_DIM,\n","               FC_LAYERS,\n","               OUTPUT_DIM,\n","               DROPOUT,\n","               PAD_IDX)\n","elif MODEL=='gru':\n","  model = NLIRNN(INPUT_DIM,\n","                'gru',\n","                EMBEDDING_DIM,\n","                HIDDEN_DIM,\n","                FC_LAYERS,\n","                OUTPUT_DIM,\n","                DROPOUT,\n","                PAD_IDX)\n","elif MODEL=='lstm':\n","  model = NLIRNN(INPUT_DIM,\n","                'lstm',\n","                EMBEDDING_DIM,\n","                HIDDEN_DIM,\n","                FC_LAYERS,\n","                OUTPUT_DIM,\n","                DROPOUT,\n","                PAD_IDX)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q7WaQ0rUzSCq","colab_type":"code","outputId":"889d52c3-a374-4f00-d321-fccfbc9d56e0","executionInfo":{"status":"ok","timestamp":1579440861795,"user_tz":-60,"elapsed":299503,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["def init_weights(m):\n","    for name, param in m.named_parameters():\n","        nn.init.normal_(param.data, mean=0, std=0.1)\n","        \n","model.apply(init_weights)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NLIRNN(\n","  (embedding): Embedding(23566, 300, padding_idx=1)\n","  (translation): Linear(in_features=300, out_features=300, bias=True)\n","  (rnn): GRU(300, 300)\n","  (fcs): ModuleList(\n","    (0): Linear(in_features=600, out_features=600, bias=True)\n","    (1): Linear(in_features=600, out_features=600, bias=True)\n","    (2): Linear(in_features=600, out_features=600, bias=True)\n","  )\n","  (fc_out): Linear(in_features=600, out_features=3, bias=True)\n","  (dropout): Dropout(p=0.25, inplace=False)\n",")"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"nygvW-Kkz9NQ","colab_type":"code","outputId":"d4491027-290c-4436-b6de-2795c735dca9","executionInfo":{"status":"ok","timestamp":1579440861798,"user_tz":-60,"elapsed":299493,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The model has 8,785,503 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xSXcqGiB0AAo","colab_type":"code","outputId":"b886e746-31ca-414b-815a-f526bab5cded","executionInfo":{"status":"ok","timestamp":1579440861799,"user_tz":-60,"elapsed":299483,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pretrained_embeddings = TEXT.vocab.vectors\n","\n","print(pretrained_embeddings.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([23566, 300])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tn_ol6Qj0V7t","colab_type":"code","outputId":"d4793972-f5fe-4972-a30a-d5f9ec2fab98","executionInfo":{"status":"ok","timestamp":1579440861799,"user_tz":-60,"elapsed":299470,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["model.embedding.weight.data.copy_(pretrained_embeddings)\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.1117, -0.4966,  0.1631,  ..., -1.4447,  0.8402, -0.8668],\n","        [ 0.1032, -1.6268,  0.5729,  ...,  0.3180, -0.1626, -0.0417],\n","        [-0.2971,  0.0940, -0.0967,  ...,  0.0597, -0.2285,  0.2960],\n","        ...,\n","        [-0.2149,  0.0846, -0.2949,  ...,  0.2379,  0.4804, -0.3348],\n","        [-0.2983, -0.2664, -0.0631,  ..., -0.1577,  1.0438, -0.6433],\n","        [ 0.3580, -0.0304,  0.3355,  ...,  0.0703, -0.5158,  0.1819]])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"VnvFshr109eV","colab_type":"code","outputId":"8293e117-a5fa-4826-9459-50b8ceb0daeb","executionInfo":{"status":"ok","timestamp":1579440861800,"user_tz":-60,"elapsed":299456,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n","\n","model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n","model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","print(model.embedding.weight.data)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [-0.2971,  0.0940, -0.0967,  ...,  0.0597, -0.2285,  0.2960],\n","        ...,\n","        [-0.2149,  0.0846, -0.2949,  ...,  0.2379,  0.4804, -0.3348],\n","        [-0.2983, -0.2664, -0.0631,  ..., -0.1577,  1.0438, -0.6433],\n","        [ 0.3580, -0.0304,  0.3355,  ...,  0.0703, -0.5158,  0.1819]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"erNNuMqD1Jq4","colab_type":"code","colab":{}},"source":["model.embedding.weight.requires_grad = False\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"13zeN9nj1OIe","colab_type":"code","outputId":"9b2541ff-be3e-4036-daa4-34f0f2e06c1c","executionInfo":{"status":"ok","timestamp":1579440861801,"user_tz":-60,"elapsed":299428,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(f'The model has {count_parameters(model):,} trainable parameters')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The model has 1,715,703 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0GC5W4c71Vkg","colab_type":"code","colab":{}},"source":["optimizer = optim.Adam(model.parameters(),lr=1e-4)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"03ceWWUu1Xit","colab_type":"code","colab":{}},"source":["criterion = nn.CrossEntropyLoss()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8BYsdqs51ZC4","colab_type":"code","colab":{}},"source":["model = model.to(device)\n","criterion = criterion.to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IQ8vJGrm1aZJ","colab_type":"code","colab":{}},"source":["def categorical_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n","    correct = max_preds.squeeze(1).eq(y)\n","    return correct.sum() / torch.FloatTensor([y.shape[0]])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UwYCMu2h1b5T","colab_type":"code","colab":{}},"source":["def train(model, iterator, optimizer, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.train()\n","    \n","    for batch in iterator:\n","        \n","        prem = batch.premise\n","        hypo = batch.hypothesis\n","        labels = batch.label\n","        \n","        optimizer.zero_grad()\n","        \n","        #prem = [prem sent len, batch size]\n","        #hypo = [hypo sent len, batch size]\n","        \n","        predictions = model(prem, hypo)\n","        \n","        #predictions = [batch size, output dim]\n","        #labels = [batch size]\n","        \n","        loss = criterion(predictions, labels)\n","                \n","        acc = categorical_accuracy(predictions, labels)\n","        \n","        loss.backward()\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i4lWFAIB1lW7","colab_type":"code","colab":{}},"source":["def evaluate(model, iterator, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.eval()\n","    \n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","\n","            prem = batch.premise\n","            hypo = batch.hypothesis\n","            labels = batch.label\n","                        \n","            predictions = model(prem, hypo)\n","            \n","            loss = criterion(predictions, labels)\n","                \n","            acc = categorical_accuracy(predictions, labels)\n","            \n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sxxoCfOa1o41","colab_type":"code","colab":{}},"source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jEBm4fXW1qkA","colab_type":"code","outputId":"15b2b36b-6f11-4a56-a671-b485855dac93","executionInfo":{"status":"ok","timestamp":1579443268756,"user_tz":-60,"elapsed":695418,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":527}},"source":["N_EPOCHS = 10\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","    \n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'tut1-model.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Epoch Time: 1m 6s\n","\tTrain Loss: 0.536 | Train Acc: 78.59%\n","\t Val. Loss: 0.751 |  Val. Acc: 67.75%\n","Epoch: 02 | Epoch Time: 1m 6s\n","\tTrain Loss: 0.529 | Train Acc: 78.96%\n","\t Val. Loss: 0.748 |  Val. Acc: 67.80%\n","Epoch: 03 | Epoch Time: 1m 8s\n","\tTrain Loss: 0.522 | Train Acc: 79.31%\n","\t Val. Loss: 0.739 |  Val. Acc: 68.49%\n","Epoch: 04 | Epoch Time: 1m 9s\n","\tTrain Loss: 0.514 | Train Acc: 79.63%\n","\t Val. Loss: 0.742 |  Val. Acc: 68.10%\n","Epoch: 05 | Epoch Time: 1m 10s\n","\tTrain Loss: 0.507 | Train Acc: 80.01%\n","\t Val. Loss: 0.748 |  Val. Acc: 67.72%\n","Epoch: 06 | Epoch Time: 1m 10s\n","\tTrain Loss: 0.501 | Train Acc: 80.33%\n","\t Val. Loss: 0.744 |  Val. Acc: 68.17%\n","Epoch: 07 | Epoch Time: 1m 10s\n","\tTrain Loss: 0.493 | Train Acc: 80.68%\n","\t Val. Loss: 0.754 |  Val. Acc: 67.75%\n","Epoch: 08 | Epoch Time: 1m 10s\n","\tTrain Loss: 0.487 | Train Acc: 81.00%\n","\t Val. Loss: 0.761 |  Val. Acc: 67.20%\n","Epoch: 09 | Epoch Time: 1m 11s\n","\tTrain Loss: 0.481 | Train Acc: 81.29%\n","\t Val. Loss: 0.755 |  Val. Acc: 67.98%\n","Epoch: 10 | Epoch Time: 1m 9s\n","\tTrain Loss: 0.473 | Train Acc: 81.64%\n","\t Val. Loss: 0.751 |  Val. Acc: 68.16%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rn207dTi1tXm","colab_type":"code","outputId":"ab23147f-3bef-42c2-a07d-4addecc61035","executionInfo":{"status":"ok","timestamp":1579443292009,"user_tz":-60,"elapsed":1518,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test_loss, test_acc = evaluate(model, test_iterator, criterion)\n","\n","print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test Loss: 0.751 |  Test Acc: 67.86%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JpchxDYq41QK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}