{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BiLSTM.ipynb","provenance":[],"authorship_tag":"ABX9TyNLol7nEqM1S82UhmZLxlyq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"96FQmh62h3Qc","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torchtext import data\n","from torchtext import datasets\n","\n","import random\n","import numpy as np\n","\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xXQ0mv4Vh_pq","colab_type":"code","colab":{}},"source":["SEED = 1234\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wwHzg4IuiDkZ","colab_type":"code","colab":{}},"source":["TEXT = data.Field(tokenize = 'spacy', lower = True)\n","LABEL = data.LabelField()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jsEavI6riGJN","colab_type":"code","outputId":"a690569b-7d01-42fa-8063-3f3d98819770","executionInfo":{"status":"ok","timestamp":1586346922142,"user_tz":-120,"elapsed":82320,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["train_data, valid_data, test_data = datasets.SNLI.splits(TEXT, LABEL)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["downloading snli_1.0.zip\n"],"name":"stdout"},{"output_type":"stream","text":["snli_1.0.zip: 100%|██████████| 94.6M/94.6M [00:17<00:00, 5.35MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["extracting\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZHO3UHsYiHvm","colab_type":"code","outputId":"8d946555-2d6f-4526-e96c-2131f47dc44e","executionInfo":{"status":"ok","timestamp":1586346922144,"user_tz":-120,"elapsed":65305,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["print(f\"Number of training examples: {len(train_data)}\")\n","print(f\"Number of validation examples: {len(valid_data)}\")\n","print(f\"Number of testing examples: {len(test_data)}\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Number of training examples: 549367\n","Number of validation examples: 9842\n","Number of testing examples: 9824\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"08__fbS6iJee","colab_type":"code","outputId":"7d9c9ca2-b26e-4820-daef-ba7ae3489de8","executionInfo":{"status":"ok","timestamp":1586346922145,"user_tz":-120,"elapsed":64965,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["print(vars(train_data.examples[0]))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{'premise': ['a', 'person', 'on', 'a', 'horse', 'jumps', 'over', 'a', 'broken', 'down', 'airplane', '.'], 'hypothesis': ['a', 'person', 'is', 'training', 'his', 'horse', 'for', 'a', 'competition', '.'], 'label': 'neutral'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GzTIMzr3iLTn","colab_type":"code","colab":{}},"source":["MIN_FREQ = 2\n","\n","TEXT.build_vocab(train_data, \n","                 min_freq = MIN_FREQ)\n","\n","LABEL.build_vocab(train_data)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CxM3dYojiNVi","colab_type":"code","outputId":"3e8fef58-e57b-4a2d-98b0-9078f0f9b8ed","executionInfo":{"status":"ok","timestamp":1586346928029,"user_tz":-120,"elapsed":70191,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Unique tokens in TEXT vocabulary: 23566\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NwfyAhY4iO8L","colab_type":"code","outputId":"2c33b83c-e336-44ba-c6eb-5d085e915bac","executionInfo":{"status":"ok","timestamp":1586346928030,"user_tz":-120,"elapsed":69835,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["print(TEXT.vocab.freqs.most_common(20))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[('a', 1438991), ('.', 962558), ('the', 534692), ('in', 407296), ('is', 373543), ('man', 266236), ('on', 235904), ('and', 206363), ('are', 199114), ('of', 192428), ('with', 169236), ('woman', 137630), ('two', 122259), ('people', 121154), (',', 114331), ('to', 113972), ('at', 98656), ('wearing', 81024), ('an', 80212), ('his', 72467)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gex6xpkWiQOf","colab_type":"code","outputId":"da2c50ea-2b76-4907-9b96-fc92c799d534","executionInfo":{"status":"ok","timestamp":1586346928031,"user_tz":-120,"elapsed":69453,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(TEXT.vocab.itos[:10])\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['<unk>', '<pad>', 'a', '.', 'the', 'in', 'is', 'man', 'on', 'and']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w2gOhm5IjDIV","colab_type":"code","outputId":"63b92f80-e59d-42ea-9652-8c7b84d06a48","executionInfo":{"status":"ok","timestamp":1586346928032,"user_tz":-120,"elapsed":69083,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(LABEL.vocab.itos)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['entailment', 'contradiction', 'neutral']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ayrdLW14jGn6","colab_type":"code","outputId":"c10d04b5-7475-4e0f-bb31-c151970c7152","executionInfo":{"status":"ok","timestamp":1586346928032,"user_tz":-120,"elapsed":68724,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(LABEL.vocab.freqs.most_common())\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[('entailment', 183416), ('contradiction', 183187), ('neutral', 182764)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BTGPKZnojI1P","colab_type":"code","outputId":"ff47d978-cc63-449d-a67c-41905d0f17f2","executionInfo":{"status":"ok","timestamp":1586346928033,"user_tz":-120,"elapsed":68372,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["BATCH_SIZE = 512\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","    batch_size = BATCH_SIZE,\n","    device = device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T9irkbt4jKu8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vHqxHcnWjMro","colab_type":"code","colab":{}},"source":["class NLIBiLSTM(nn.Module):\n","    def __init__(self, \n","                 input_dim, \n","                 embedding_dim,\n","                 hidden_dim,\n","                 n_lstm_layers,\n","                 n_fc_layers,\n","                 output_dim, \n","                 dropout, \n","                 pad_idx):\n","        \n","        super().__init__()\n","                                \n","        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)\n","        \n","        self.translation = nn.Linear(embedding_dim, hidden_dim)\n","        \n","        self.lstm = nn.LSTM(hidden_dim, \n","                            hidden_dim, \n","                            num_layers = n_lstm_layers, \n","                            bidirectional = True, \n","                            dropout=dropout if n_lstm_layers > 1 else 0)\n","        \n","        fc_dim = hidden_dim * 2\n","        \n","        fcs = [nn.Linear(fc_dim * 2, fc_dim * 2) for _ in range(n_fc_layers)]\n","        \n","        self.fcs = nn.ModuleList(fcs)\n","        \n","        self.fc_out = nn.Linear(fc_dim * 2, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, prem, hypo):\n","\n","        prem_seq_len, batch_size = prem.shape\n","        hypo_seq_len, _ = hypo.shape\n","        \n","        #prem = [prem sent len, batch size]\n","        #hypo = [hypo sent len, batch size]\n","        \n","        embedded_prem = self.embedding(prem)\n","        embedded_hypo = self.embedding(hypo)\n","        \n","        #embedded_prem = [prem sent len, batch size, embedding dim]\n","        #embedded_hypo = [hypo sent len, batch size, embedding dim]\n","        \n","        translated_prem = F.relu(self.translation(embedded_prem))\n","        translated_hypo = F.relu(self.translation(embedded_hypo))\n","        \n","        #translated_prem = [prem sent len, batch size, hidden dim]\n","        #translated_hypo = [hypo sent len, batch size, hidden dim]\n","        \n","        outputs_prem, (hidden_prem, cell_prem) = self.lstm(translated_prem)\n","        outputs_hypo, (hidden_hypo, cell_hypo) = self.lstm(translated_hypo)\n","\n","        #outputs_x = [sent len, batch size, n directions * hid dim]\n","        #hidden_x = [n layers * n directions, batch size, hid dim]\n","        #cell_x = [n layers * n directions, batch size, hid dim]\n","        \n","        hidden_prem = torch.cat((hidden_prem[-1], hidden_prem[-2]), dim=-1)\n","        hidden_hypo = torch.cat((hidden_hypo[-1], hidden_hypo[-2]), dim=-1)\n","        \n","        #hidden_x = [batch size, fc dim]\n","\n","        hidden = torch.cat((hidden_prem, hidden_hypo), dim=1)\n","\n","        #hidden = [batch size, fc dim * 2]\n","            \n","        for fc in self.fcs:\n","            hidden = fc(hidden)\n","            hidden = F.relu(hidden)\n","            hidden = self.dropout(hidden)\n","        \n","        prediction = self.fc_out(hidden)\n","        \n","        #prediction = [batch size, output dim]\n","        \n","        return prediction"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-AyMPeh0jSXp","colab_type":"code","colab":{}},"source":["INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 300\n","HIDDEN_DIM = 300\n","N_LSTM_LAYERS = 2\n","N_FC_LAYERS = 3\n","OUTPUT_DIM = len(LABEL.vocab)\n","DROPOUT = 0.25\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","model = NLIBiLSTM(INPUT_DIM,\n","                  EMBEDDING_DIM,\n","                  HIDDEN_DIM,\n","                  N_LSTM_LAYERS,\n","                  N_FC_LAYERS,\n","                  OUTPUT_DIM,\n","                  DROPOUT,\n","                  PAD_IDX).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vWgKLWmDjUdk","colab_type":"code","outputId":"a128117e-d4df-48ac-d743-172a4e13db9f","executionInfo":{"status":"ok","timestamp":1586346938487,"user_tz":-120,"elapsed":77002,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The model has 15,096,903 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vMIhcA5FjWqO","colab_type":"code","colab":{}},"source":["optimizer = optim.Adam(model.parameters())\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"je_IyZPhjdS-","colab_type":"code","colab":{}},"source":["criterion = nn.CrossEntropyLoss().to(device)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BPWDaZ6OjepS","colab_type":"code","colab":{}},"source":["def categorical_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n","    correct = max_preds.squeeze(1).eq(y)\n","    return correct.sum() / torch.FloatTensor([y.shape[0]])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cpRoIC2ejgX6","colab_type":"code","colab":{}},"source":["def train(model, iterator, optimizer, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.train()\n","    \n","    for batch in iterator:\n","        \n","        prem = batch.premise\n","        hypo = batch.hypothesis\n","        labels = batch.label\n","        \n","        optimizer.zero_grad()\n","        \n","        #prem = [prem sent len, batch size]\n","        #hypo = [hypo sent len, batch size]\n","        \n","        predictions = model(prem, hypo)\n","        \n","        #predictions = [batch size, output dim]\n","        #labels = [batch size]\n","        \n","        loss = criterion(predictions, labels)\n","                \n","        acc = categorical_accuracy(predictions, labels)\n","        \n","        loss.backward()\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oXJdhIvYjiaz","colab_type":"code","colab":{}},"source":["def evaluate(model, iterator, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.eval()\n","    \n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","\n","            prem = batch.premise\n","            hypo = batch.hypothesis\n","            labels = batch.label\n","                        \n","            predictions = model(prem, hypo)\n","            \n","            loss = criterion(predictions, labels)\n","                \n","            acc = categorical_accuracy(predictions, labels)\n","            \n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sWrch9v9jkkQ","colab_type":"code","colab":{}},"source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_eZuK4wKjmSi","colab_type":"code","outputId":"60314bda-d232-4559-c244-16fae5db5d87","executionInfo":{"status":"ok","timestamp":1586349591599,"user_tz":-120,"elapsed":846830,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":425}},"source":["N_EPOCHS = 8\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","    \n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'tut1-model.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Epoch Time: 5m 30s\n","\tTrain Loss: 0.791 | Train Acc: 64.58%\n","\t Val. Loss: 0.696 |  Val. Acc: 71.00%\n","Epoch: 02 | Epoch Time: 5m 31s\n","\tTrain Loss: 0.649 | Train Acc: 72.90%\n","\t Val. Loss: 0.629 |  Val. Acc: 74.15%\n","Epoch: 03 | Epoch Time: 5m 32s\n","\tTrain Loss: 0.590 | Train Acc: 75.91%\n","\t Val. Loss: 0.593 |  Val. Acc: 75.83%\n","Epoch: 04 | Epoch Time: 5m 30s\n","\tTrain Loss: 0.544 | Train Acc: 78.08%\n","\t Val. Loss: 0.571 |  Val. Acc: 76.74%\n","Epoch: 05 | Epoch Time: 5m 31s\n","\tTrain Loss: 0.507 | Train Acc: 79.78%\n","\t Val. Loss: 0.570 |  Val. Acc: 77.40%\n","Epoch: 06 | Epoch Time: 5m 31s\n","\tTrain Loss: 0.474 | Train Acc: 81.31%\n","\t Val. Loss: 0.564 |  Val. Acc: 77.85%\n","Epoch: 07 | Epoch Time: 5m 33s\n","\tTrain Loss: 0.443 | Train Acc: 82.66%\n","\t Val. Loss: 0.558 |  Val. Acc: 78.28%\n","Epoch: 08 | Epoch Time: 5m 30s\n","\tTrain Loss: 0.412 | Train Acc: 84.02%\n","\t Val. Loss: 0.568 |  Val. Acc: 78.54%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2BoioGbIjqYj","colab_type":"code","outputId":"e693ebca-547f-4965-dcc3-26867203c602","executionInfo":{"status":"ok","timestamp":1586349592002,"user_tz":-120,"elapsed":411,"user":{"displayName":"Daniel Cuiñas Vázquez","photoUrl":"","userId":"11552885780691803973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# model.load_state_dict(torch.load('tut1-model.pt'))\n","\n","test_loss, test_acc = evaluate(model, test_iterator, criterion)\n","\n","print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test Loss: 0.577 |  Test Acc: 77.64%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VVWvzu_KpDXI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}