{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pL-4p0EGtnh5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WoalaFrUt1ja"
   },
   "outputs": [],
   "source": [
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12321,
     "status": "ok",
     "timestamp": 1580985630230,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "J0yNY5wGt3au",
    "outputId": "b5edf5ca-7c1a-4c9f-d97b-9941e016adfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
      "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n",
      "Collecting de_core_news_sm==2.1.0\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.1.0/de_core_news_sm-2.1.0.tar.gz (11.1MB)\n",
      "\u001b[K     |████████████████████████████████| 11.1MB 1.8MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: de-core-news-sm\n",
      "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.1.0-cp36-none-any.whl size=11073065 sha256=6d33953b32005021e9e1ea2b525b44a3f6ccacd9c295e38cb27910fac2a20b14\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mmk2eff2/wheels/b4/8b/5e/d2ce5d2756ca95de22f50f68299708009a4aafda2aea79c4e4\n",
      "Successfully built de-core-news-sm\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-2.1.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('de_core_news_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
      "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
      "You can now load the model via spacy.load('de')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en\n",
    "!python -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9m4usxXQt5Gp"
   },
   "outputs": [],
   "source": [
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YVBFuOEUt6tL"
   },
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WcRvCbRCt_5F"
   },
   "outputs": [],
   "source": [
    "SRC = Field(tokenize = tokenize_de, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24435,
     "status": "ok",
     "timestamp": 1580985657871,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "4swHi4oduBkp",
    "outputId": "ba152882-d60a-44cb-c3f2-0669d6b37a74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading training.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 755kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading validation.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 231kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading mmt_task1_test2016.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 165kB/s]\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), \n",
    "                                                    fields = (SRC, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k9YHHRMjuC0v"
   },
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23785,
     "status": "ok",
     "timestamp": 1580985658423,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "Ajh1OfkquEmD",
    "outputId": "40c19494-c6aa-4aa9-d7f6-ce3653e4ccff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5o_FcEtOuHIv"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z7nf4Pi1uJAP"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
    "        \n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        \n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "                \n",
    "        #outputs = [src len, batch size, hid dim * num directions]\n",
    "        #hidden = [n layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
    "        #outputs are always from the last layer\n",
    "        \n",
    "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
    "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
    "        \n",
    "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
    "        #  encoder RNNs fed through a linear layer\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
    "        \n",
    "        #outputs = [src len, batch size, enc hid dim * 2]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lB8gda7ruLJB"
   },
   "outputs": [],
   "source": [
    "class Attention_old(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Parameter(torch.randn(dec_hid_dim))\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        #repeat encoder hidden state src_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #hidden = [batch size, src len, dec hid dim]\n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
    "        \n",
    "        #energy = [batch size, src len, dec hid dim]\n",
    "        \n",
    "        energy = energy.permute(0, 2, 1)\n",
    "        \n",
    "        #energy = [batch size, dec hid dim, src len]\n",
    "        \n",
    "        #v = [dec hid dim]\n",
    "        \n",
    "        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
    "        \n",
    "        #v = [batch size, 1, dec hid dim]\n",
    "                \n",
    "        attention = torch.bmm(v, energy).squeeze(1)\n",
    "        \n",
    "        #attention= [batch size, src len]\n",
    "        \n",
    "        return F.softmax(attention, dim=1)\n",
    "\n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        #repeat decoder hidden state src_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #hidden = [batch size, src len, dec hid dim]\n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
    "        \n",
    "        #energy = [batch size, src len, dec hid dim]\n",
    "\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        \n",
    "        #attention= [batch size, src len]\n",
    "        \n",
    "        return F.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TY5pPcSHuNFJ"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "             \n",
    "        #input = [batch size]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "        \n",
    "        a = self.attention(hidden, encoder_outputs)\n",
    "                \n",
    "        #a = [batch size, src len]\n",
    "        \n",
    "        a = a.unsqueeze(1)\n",
    "        \n",
    "        #a = [batch size, 1, src len]\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        \n",
    "        #weighted = [batch size, 1, enc hid dim * 2]\n",
    "        \n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        \n",
    "        #weighted = [1, batch size, enc hid dim * 2]\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "        \n",
    "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
    "            \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        \n",
    "        #output = [seq len, batch size, dec hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
    "        \n",
    "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        #output = [1, batch size, dec hid dim]\n",
    "        #hidden = [1, batch size, dec hid dim]\n",
    "        #this also means that output == hidden\n",
    "        assert (output == hidden).all()\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden.squeeze(0), a.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KnbLQRm8uPgJ"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
    "        \n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "                \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden state and all encoder hidden states\n",
    "            #receive output tensor (predictions) and new hidden state\n",
    "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oww2LmYJuRoL"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 495,
     "status": "ok",
     "timestamp": 1580987074274,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "Eo7ORYrguTQ5",
    "outputId": "b2e782e1-3791-4a6d-849e-d36da412df9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7855, 256)\n",
       "    (rnn): GRU(256, 512, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): GRU(1280, 512)\n",
       "    (fc_out): Linear(in_features=1792, out_features=5893, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1580987075332,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "y3MDTRKHuVD-",
    "outputId": "11f6741a-bca0-4885-d6a7-1cd0ba3eeaed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 20,518,917 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UXb0lBjuXBK"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3zmcBZVjuYR2"
   },
   "outputs": [],
   "source": [
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CC93gtKMuZ7x"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k203nFhPueoQ"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nZMKi1EmugLr"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 839006,
     "status": "ok",
     "timestamp": 1580987919914,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "jvLhaTnBuhkP",
    "outputId": "f71ade3a-8fbe-4876-a7c2-439dfdac4c71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 1m 22s\n",
      "\tTrain Loss: 5.064 | Train PPL: 158.262\n",
      "\t Val. Loss: 4.979 |  Val. PPL: 145.257\n",
      "Epoch: 02 | Time: 1m 24s\n",
      "\tTrain Loss: 4.235 | Train PPL:  69.076\n",
      "\t Val. Loss: 5.038 |  Val. PPL: 154.183\n",
      "Epoch: 03 | Time: 1m 23s\n",
      "\tTrain Loss: 3.689 | Train PPL:  40.017\n",
      "\t Val. Loss: 3.898 |  Val. PPL:  49.322\n",
      "Epoch: 04 | Time: 1m 23s\n",
      "\tTrain Loss: 3.097 | Train PPL:  22.127\n",
      "\t Val. Loss: 3.576 |  Val. PPL:  35.736\n",
      "Epoch: 05 | Time: 1m 24s\n",
      "\tTrain Loss: 2.677 | Train PPL:  14.541\n",
      "\t Val. Loss: 3.354 |  Val. PPL:  28.612\n",
      "Epoch: 06 | Time: 1m 23s\n",
      "\tTrain Loss: 2.355 | Train PPL:  10.538\n",
      "\t Val. Loss: 3.264 |  Val. PPL:  26.154\n",
      "Epoch: 07 | Time: 1m 23s\n",
      "\tTrain Loss: 2.065 | Train PPL:   7.882\n",
      "\t Val. Loss: 3.241 |  Val. PPL:  25.555\n",
      "Epoch: 08 | Time: 1m 23s\n",
      "\tTrain Loss: 1.869 | Train PPL:   6.483\n",
      "\t Val. Loss: 3.241 |  Val. PPL:  25.552\n",
      "Epoch: 09 | Time: 1m 24s\n",
      "\tTrain Loss: 1.680 | Train PPL:   5.364\n",
      "\t Val. Loss: 3.278 |  Val. PPL:  26.534\n",
      "Epoch: 10 | Time: 1m 24s\n",
      "\tTrain Loss: 1.545 | Train PPL:   4.688\n",
      "\t Val. Loss: 3.255 |  Val. PPL:  25.907\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), '/content/gdrive/My Drive/Colab Notebooks/seq2seq/torch-model_temp1.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1212,
     "status": "ok",
     "timestamp": 1580987929488,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "SDFilh7vunOd",
    "outputId": "663542be-f9b1-4898-91ad-61faaed96e9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 3.213 | Test PPL:  24.847 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/content/gdrive/My Drive/Colab Notebooks/seq2seq/torch-model_temp1.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pe46WEH6wnNx"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_RGpdYM2wqFh"
   },
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
    "\n",
    "    model.eval()\n",
    "        \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('de')\n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "        \n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    \n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor)\n",
    "        \n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "\n",
    "    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
    "    \n",
    "    for i in range(max_len):\n",
    "\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs)\n",
    "\n",
    "        attentions[i] = attention\n",
    "            \n",
    "        pred_token = output.argmax(1).item()\n",
    "        \n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "    \n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1aCkl-3Dw0io"
   },
   "outputs": [],
   "source": [
    "def display_attention(sentence, translation, attention):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
    "    \n",
    "    cax = ax.matshow(attention, cmap='bone')\n",
    "   \n",
    "    ax.tick_params(labelsize=15)\n",
    "    ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
    "                       rotation=45)\n",
    "    ax.set_yticklabels(['']+translation)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1580987992887,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "0iskHzkOw3kI",
    "outputId": "3160342d-587b-48b2-f623-18cead43d2bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = ['ein', 'asiatischer', 'mann', 'und', 'eine', 'blonde', 'frau', ',', 'die', 'händchen', 'halten', ',', 'im', 'freien', ',', 'ein', 'mann', 'im', 'hintergrund', 'sieht', 'zu', '.']\n",
      "trg = ['asian', 'man', 'and', 'blond', 'woman', 'holding', 'hands', 'outdoors', ',', 'man', 'in', 'background', 'watches', '.']\n"
     ]
    }
   ],
   "source": [
    "example_idx = 120\n",
    "\n",
    "src = vars(train_data.examples[example_idx])['src']\n",
    "trg = vars(train_data.examples[example_idx])['trg']\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 493,
     "status": "ok",
     "timestamp": 1580987995035,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "cU9RZgZ5w5eM",
    "outputId": "045b5a14-6513-43f7-9ed9-3458efea434d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted trg = ['asian', 'man', 'and', 'woman', 'blond', 'woman', 'holding', 'hands', ',', 'man', 'man', 'in', 'the', 'background', 'watches', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
    "\n",
    "print(f'predicted trg = {translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 938,
     "status": "ok",
     "timestamp": 1580987979790,
     "user": {
      "displayName": "Daniel Cuiñas Vázquez",
      "photoUrl": "",
      "userId": "11552885780691803973"
     },
     "user_tz": -60
    },
    "id": "5q2fF3eAw7UK",
    "outputId": "909a3427-4936-4286-e96c-53f3380763b5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm8AAAJ5CAYAAAD4udcOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_attention(src, translation, attention)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qe2Q2WrEOhN7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOBTEzSIzf71ymWTGFxfDkO",
   "collapsed_sections": [],
   "name": "Seq2seq_Bahdanau1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
